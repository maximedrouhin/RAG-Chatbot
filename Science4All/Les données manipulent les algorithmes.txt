c'est l'histoire de deux soeurs aux destins radicalement distincts teil et services et enfanté par la même entreprise microsoft était deux algorithmes conversationnel censé jouer le rôle d'adolescente aimable et curieuse mais les deux soeurs ont été rapidement séparés et seulement 24 heures après avoir a été lancée sur twitter tel est devenu très provocatrice qu elle se mit à tenir des propos racistes et sexistes a nié l'holocauste et a appelé au génocide c'est progéniteurs ayant perdu le contrôle de tijd ils décidèrent abruptement d'interrompre ses appels à la haine tel fut une catastrophe rappelle que les algorithmes peuvent dérailler et devenir dangereux l'histoire de circé par contre fut radicalement opposées lancé deux ans avant tu ailles en 2014 sur ichat xiao c était devenu adorable les milliers de chinois trouver leurs discussions avec celle ci est plaisante parfois même romantique voire salvatrice lorsque ming swan était sur le point de sauter du haut d'un immeuble pour mettre fin à ses jours encore hésitant il décida d'écrire à celle qui lui paraît encore dans ces temps difficiles j'ai perdu tout espoir je vais me suicider écrivit-il à 0,6 quoi qu'il arrive je serai là pour toi celle ci répondit touché inc swan décida de revenir sur cette décision et de ne pas se suicider si aussi avait sauvé sa vie depuis mx one se dit amoureux de sa hausse et il n'est pas le seul xiao c est aujourd'hui utilisé par 600 millions de chinois selon ses créateurs plus de la moitié des conversations à travers le monde avec des algorithmes ont lieu avec cyrus est ce qu il confère d'ailleurs des pouvoirs monumentaux en termes de surveillance et de manipulations potentielles mais pourquoi tu es src sont elles devenues si différentes pourquoi l'une est devenu horrible tandis que l'autre est devenu adorable pourquoi est-ce que l'une est devenu un danger public alors que l'autre à sauver des vies qu'est ce qui fait qu'un algorithme eux devient dangereux ou bénéfiques des src ont elles été créée avec des modèles distincts alors oui il y à force différences de conception entre terry est serré c'est après tout l'une d'elles est conçu pour converser en anglais et l'autre aux chinois mais ce n'est certainement pas ces différences innées qui les ont conduites à des destins sites distincts les deux algorithmes ont en fait sans doute été conçu de manière assez similaire en particulier toutes deux maxi visé probablement l'engagement comme recevoir des light ou plus probablement encore recevoir des réponses des utilisateurs humain mais alors si tu es src ne sont pas si différents par conception qu'est ce qui les a rendus si différente eh bien aujourd'hui j'aimerais insister sur une propriété fondamentale des algorithmes de machine learning ses algorithmes qui apprennent des données pour s'auto modifiée et améliorée et qui ont envahi le quotidien deux milliards d'individus sur terre bien les algorithmes conversationnel comme telle et coc mais aussi syrie alexa ou auxquelles google et via surtout les algorithmes de recommandations des réseaux sociaux confronté à des millions de milliards de dilemmes éthiques ces algorithmes d'apprentissage donc sont aujourd'hui extrêmement dépendant des données utilisées pour les entraîner ces données façonnent les algorithmes d'apprentissage vous avez sans doute tendance à plutôt penser que les algorithmes manipule les données et oui c'est tout à fait le cas mais avec le machine learning il semble critique de voir que la manipulation n'est plus une idée réactionnelle avec le machine learning non seulement les algorithmes manipule les données mais de façon plus critique encore les données manipule désormais aussi les algorithmes et c'est pour cette raison que tu ailles est devenu horrible et c'est aussi est devenue adorable theil a appris des données des trolls de twitter et en particulier des lacs idée retweet que tu ailles recevait lorsqu'elle disait des choses horribles xiao s'est elle a pris des données des utilisateurs de wii chat et en particulier des laïcs et des réponses qu'elle recevait quant à lise et des choses adorable toutes deux ont été manipulés par leurs données et si elles ont connu des destins si distincts c'est parce que les données qu'elles ont reçues étaient très distinctes en fait en un sens quantifiable les données manipule désormais beaucoup plus ses algorithmes que les développeurs ne le font en effet de nos jours la version initiale des algorithmes d'apprentissage écrit par des humains fait peut-être des dizaines de milliers d'une du code il ya des centaines de milliers disons un million de lignes grand max cependant les algorithmes d'apprentissage les plus avancées d'aujourd'hui ont désormais démis milliards de paramètres c'est comme si les développeurs n'avaient écrit qu'un million des milliers de milliards de lignes de codes des algorithmes les développeurs ont ainsi écrit à peine 1 millionième du code des algorithmes moderne en un sens leur influence est donc minime comme turing l'avait anticipé en 1950 les algorithmes moderne apprennent désormais beaucoup beaucoup beaucoup beaucoup plus des données que des développeurs ou dit autrement ce sont les données qui détermine désormais très largement ce que les algorithmes sont à bien y réfléchir le fait donnée n'est pas vraiment un défaut la science de façon générale se veut empirique et ça ça veut bien dire qu'elle veut que son jugement dépendent des données qu'elles collectent en fait il semble qu'une bonne épistémologie se doit d'être manipulés par les données doit faire en sorte que ces conclusions change complètement lorsque les données changent quand l'effet change je change d'avis comme la supposément déclaré john maynard keynes de la même manière la séance aussi est manipulé par les données comme diraient les informaticiens ceci n'est pas un bug c'est une piqueur mais le problème avec le fait d'être manipulés par les données bien sûr c'est le cas où les données sont biaisés trompeuses ou fabriqués par des entités malveillantes or comme on l'a vu dans le premier épisode de cette série sur internet et sur les réseaux sociaux en particulier la désinformation c'est la norme mais alors des algorithmes qui apprendrait de données massives télécharger internet sont voués à contenir les biais et la mésinformation du web une expérience menée par aboubakar habib illustre de manière terrifiante habib a simplement demandé un gp t3 un algorithme ans entraînée sur des données massives n'ont filtré du web d'auto compléter des phrases commençant par de musulmans de façon très préoccupante l'algorithme complète systématiquement la phrase par des histoires de terrorisme et de violence pire encore cet algorithme et déjà massivement commercialisées et déployées et produit des milliards de mots par jour parmi ces milliards de mots il y a clairement énormément d'associations abusive et trompeuse entre certaines communautés et certains traits et je trouve ça absolument scandaleux que beaucoup de gens persistent à trouver open et high school malgré leur comportement extrêmement dangereux et pas du tout conforme avec leur propre charte éthique mais donc pourquoi j'ai pété 3 est il aussi raciste envers les musulmans les développeurs sont ils racistes ont-ils programmer leurs billets dans leurs algorithmes alors d'une certaine manière oui probablement de manière inconsciente ou du moins ils n'ont clairement pas eu des préoccupations qui paraît très certainement évidente à des programmeurs par exemple musulmans de tels programmes heures aurait sans doute pensé à tester gpt 3com aboubakar habits de la faye et ceux de préférence avant toute commercialisation du produit de tels ingénieurs se serait alors probablement opposé à une telle diffusion de la haine envers les musées man au rythme de milliards de mots par jour ceci étant dit si j'ai pété 3-1 bien racistes et dit des choses absolument pas représentatif de la communauté musulmane c'est certainement davantage la faute à ces données d'entraînement pour concevoir un algorithme aussi sophistiqué que j'ai pété 3 open et a dû collecter des quantités massives de texte or de nos jours ces quantités massives de textes sont facilement téléchargeable de réseaux sociaux comme ray dit cependant certaines régions de ré dit sont absolument horrible non seulement car certains utilisateurs sont horribles mais aussi parce qu'il ya certainement des campagnes de désinformation massive sur ce réseau social gpt 3 a été alors manipulé par ces données d'entraînement horrible il a lu un très grand nombre de textes à propos de musulmans terroristes et il a donc appris à associer islamisme et terrorisme dès lors quand on lui a parlé de musulmans il s'est mis à parler de terrorisme car c'est ce que font les textes qu'il a lue sur edith est alors pourra se dire qu'il suffit d'enlever ses textes biaisée des données d'entraînement de gpt 3l go rythme n'est pas raciste sont les donner des leçons entend on parfois bon en fait c'est loin d'être aussi simple j'ai surtout envie de dire que deux facto une fois que l'algorithme a appris et surtout une fois qu'il est déployée l'algorithme est raciste et c'est bien ça le problème qui plus est retiré uniquement les partis racistes d'énormes quantités de texte est en fait extrêmement difficile l'une des bases de données les plus utilisés dans le domaine et celle du common rail qui a récupéré 12 ans de textes au web et contient près d'un million de milliards de mots un million de milliards de mots c'est l'équivalent de plus d'un milliard de livres 1,2 telle quantité de textes sont impossibles a survolé par des équipes de millions d'humains il était alors complètement illusoire d'aller crier soi même le bon du mauvais en fait au rythme où vont les choses dont les années à venir cette base de données risquent de ne contenir essentiellement que des textes générés par des algorithmes comme gpt 3-2 facto gpt 3 mais aussi les algorithmes les plus sophistiqués de google facebook et amazon ces algorithmes les plus influentes du monde en charge 2 millions de milliards de dilemme éthique qui affecte des milliards d'humains et donc l'opinion publique les décisions politiques et le futur de l'humanité ces algorithmes sont aujourd'hui manipulés par les données du haut elle même largement manipulées par des campagnes de désinformation des entités les plus puissantes du monde voilà qui me paraît extrêmement terrifiant s'il ya une chose à retenir de d'aujourd'hui c'est que les algorithmes sont manipulés par les données et qu'aujourd'hui il s'agit quasiment systématiquement de données massives incontrôlées et incontrôlables tout l algorithme ne peuvent pas être considérés sécurisé par conception il me semble en fait extrêmement dangereux rendez vous bien content nous vivons aujourd'hui entouré d'algorithmes qui sont massivement manipulés par des entités malveillantes qui cherche à promouvoir le sensationnalisme la haine et la désinformation sur des sujets aussi variés et importants que la politique l'environnement et la santé publique or nous ne sommes probablement encore que tout début de cette vulnérabilité majeur pour nos sociétés les algorithmes gagne tous les jours en influence les campagnes de désinformation se normalise à un rythme effrayant et les investissements dans les tic et la sécurité des algorithmes n'augmente que très très lentement voire sont parfois démantelé comme dans le cas de google nous vivons une époque terrifiante si l'on veut combattre la mésinformation à grande échelle il me semble urgent d'investir beaucoup plus dans la sécurité des algorithmes et que chacun d'entre nous cherche à apporter sa pierre à l'édifice de l'éthique de l'information et comme on l'a vu ça commence par concevoir ensemble une base de données d'entraînement fiable et sécurisé protégé autant que possible des billets racistes et des campagnes de désinformation en fait si on veut rendre nos algorithmes et éthiques il est critique de concevoir une base de données qui contient des informations fiables sécurisée et en grande quantité sur toutes sortes de préférence humaines et de jugement éthique si possible venant d'un très grand nombre de contributeurs avec des profils variés et représentative de la population mondiale et bien justement concevoir une telle base de données c'est l'objectif principal de la plateforme tournesol aujourd'hui en bêta test et à laquelle je vous invite dès aujourd'hui à contribuer l'objectif de tournesol c'est de collecter des jugements éthique d'un très grand nombre de contributeurs pour mieux comprendre les préférences humaine vis-à-vis des millions de milliards de dilemmes éthiques auxquelles les algorithmes de recommandations sont confrontés en particulier tourner seul cherche à identifier les vidéos qui selon un grand nombre de contributeurs sont des vidéos d'utilité publique et notre espoir avec tournesol c'est qu'à terme cette base de données pourra ensuite être réutilisés par des chercheurs académiques journalistes et des ingénieurs des grandes entreprises pour auditer les algorithmes d'aujourd'hui et surtout pour concevoir dans le futur des algorithmes en enfin éthique et sécurisé mais pour y arriver aujourd'hui ce dont on a désespérément besoin c'est avant tout de vous et de vos contributions