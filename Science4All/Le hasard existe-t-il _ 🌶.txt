en 1687 newton publiait les lois de la gravité et montera qu'elle prédisait les trajectoire elliptique des planètes autour du soleil ou presque il réussit à démontrer cela dans le cas où la planète était le seul objet à orbiter autour du soleil on parle de système à deux corps cependant quand ils cherchent à appliquer les mathématiques de la gravité à des systèmes à trois corps ou au système solaire tout entier il tomba alors sur un os il fut incapable de déduire la stabilité du système solaire de ses propres équation pour newton de tels calculs et est surhumain il fallait la présence d'un grand horloger un dieu pour remettre régulièrement le système solaire en ordre et préserver l'élégance et la perfection des corps célestes il aura fallu tout un siècle pour qu'un grand génie défi enfin cette intuition de newton et ce génie c'est pierre simon laplace la place la place développe pas une théorie du calcul perturbe hâtif pour suggérer que système solaire n'avait nul besoin d'un grand horloger pour préserver son ordre les lois de la mécanique et de la gravité suffisait à expliquer l'ordre des cieux d'ailleurs selon la légende napoléon bonaparte aurait dit à la place newton a parlé de dieu dans son livre j'ai parcouru le vôtre et je n'ai pas trouvé son nom une seule fois ce à quoi la place aurait alors rétorqué citoyens premier consul je n'ai pas eu besoin de cette hypothèse alors si cette légende est sans doute fausse la place semblait alors avoir néanmoins fait basculer la philosophie naturelle vers une vision mécanistiques du monte en montrant que les lois de newton était suffisante à la mécanique du monde la place introduisit un déterminisme radical et contre intuitif dans son essai philosophique sur les probabilités pierre simon laplace écrivit ainsi une intelligence qui un instant donné qu'on ne traite toutes les forces dont la nature est animée et la situation respective des êtres qui la composent si d'ailleurs elle était suffisamment vaste pour soumettre ces données allen lise embrasserait dans la même formule les mouvements des plus lourds encore de l'univers et ceux du plus légères atone rien ne serait incertain pour elle et l'avenir comme le passé serait présent à ses yeux cette intelligence est ce que l'on appelle désormais un démon de la place selon la place le démon de la place saurait prédire tous le futur à partir d'une connaissance du présent de l'univers car l'état présent de l'univers détermine son futur en ce sens l'univers est déterministe et alors on pourrait se demander pourquoi est-ce que la place défend le déterminisme dans un essai philosophique sur les probabilités bien pour en savoir plus je vous invite à lire ce frais de twitter que j'ai écrit à ce sujet pour la place les probabilités ne sont pas là pour décrire des phénomènes fondamentalement aléatoire de notre monde elles sont là pour décrire l'étendue de notre ignorance et ça c'est un peu le fondement philosophique du pays via nice mme devrait d'ailleurs peut-être plutôt renommée de probabiliste l'appelation quoi qu'il en soit au début du 20e siècle le déterminisme la place tien triompha en physique qu'il s'agisse des lois de l'électromagnétisme ou de la relativité générale d'einstein la physique semblait défendre unanimement une vision purement mécanistiques et déterministe de notre univers selon cette vision le présent détermine le futur et puis voir les bizarreries de la mécanique quantique en particulier pour expliquer des phénomènes comme les fentes de young la radioactivité ou l'airé spectrale il semblait utile d'invoquer les lois des probabilités vous avez peut-être ainsi entendu dire que en mécanique quantique un électron et généralement dans une superposition d'états physique et que lorsqu'on mesure disons la position de l'électron cette superposition s'effondre pour donner lieu à une unique position de l'électron mais plus étrange encore cette position de l'électron semble fondamentalement aléatoire elle varie d'une répétition de l'expérience à l'autre et selon la mécanique quantique la position future de l'ailé on semble indéterminée par l'état physique présent de l'univers ou plutôt ça c'est l'interprétation dit de copenhague de la mécanique quantique car elle fut promue par le physicien danois niels bohr pour qui il suffisait de faire des théories prédictive et il n'était pas nécessaire de philosopher outre mesure sur le réalisme de nos théories étrangement cette interprétation de niels bohr contraste beaucoup avec l'interprétation de copenhague est telle qu elle est le plus souvent enseigner et vulgariser aujourd'hui ou des physiciens affirment parfois sans hésitation que la mécanique quantique prouvent que le monde n'est pas déterministe ya des jours j'aimerais vraiment interdire l'utilisation du mot prouvé par les scientifiques d'autant qu'il existe des interprétations de la mécanique quantique qui elles sont déterministe par exemple la théorie de long deux pilotes de baume de brogues est une théorie physique parfaitement déterministe et qui fait les mêmes prédiction que l'interprétation de copenhague sur l'ensemble des expériences physiques testé à ce jour donc dire que la mécanique quantique prouvent que le monde n'est pas déterministe c'est allait vraiment vite en besogne en fait seulement 49% des experts adopté interprétation de copenhague de la mécanique quantique on est donc très très très loin d'un consensus scientifique et qui plus est la plupart des autres interprétations de la mécanique quantique et semble même déterministe ou du moins compatible avec le déterminisme bref l'existence d'un hasard fondamental c'est un sujet complexe sur lequel les plus grands experts de la planète sont en désaccord mais il ya pire la découverte de la théorie du chaos rend la question de l'existence d'un hasard fondamental encore plus complexe dans les années 60 les mathématiciens se sont rendus compte que des systèmes déterministe très simples comme disons le jeu de la vie de conway avait des comportements extrêmement sophistiqués des comportements qui semblent aléatoires ainsi un système purement déterministe peut largement semblait aléatoire y compris aux yeux de la physique cette théorie du chaos suggère en particulier que l'intuition limitée du physicien et probablement un bien mauvais guide pour déterminer si le hasard existe vraiment de manière fondamentale au mieux le physicien ne peut que dire que ces modèles les plus utiles invoque le hasard mais selon le proverbe bayésiens tous les modèles sont faux en fait si on veut savoir si le hasard existe vraiment de façon fondamentale il convient certainement de d'abord mieux comprendre l'épistémologie c'est à dire la façon de transformer des données en savoir or comme on l'a vu dans les deux derniers épisodes toutes les données semblent en fait équivalente à une longue suite de 0 et de 1 on avait même estimé que l'ensemble de toutes les données auxquelles une conscience humaine aura eu accès dans sa vie aux présentes probablement autour d'un téraoctet soit mais milliards 2 0 et 2 1 ok imaginons que je vous donne maintenant accès à 1000 milliards 2 0 et 2 1 ça fait un peu beaucoup donc disons mille 0 et 1 pour commencer déterminer si le monde et déterministe ça reviendrait à se demander si cette suite 2000 0 et 2 1 a été générée par du hasard est ce que vous voyez comment faire cela peut-on vraiment inférées de nos données sensorielles l'existence du hasard le premier à s'être posé sérieusement cette question semble être le logicien père martin 9 en 1966 et à en croire une équipe et dia c'est même le seul à être parvenu à donner un sens rigoureux à la notion de hasard fondamentale ou en fait pour aujourd'hui je ne vais pas expliquer exactement la notion introduite par martin hoff que j'ai d'ailleurs déjà expliqué avec teva blanchard dans cette vidéo au lieu de cela je veux insister sur l'aspect philosophique derrière la proche de martin 9 avec même une perspective un peu plus générale donc je m'excuse auprès des puristes et des fans inconditionnels de martynov bref l'astuce de martin hoff fut de remarquer que l' inverse le hasard semble être la régularité or si je prends le mou régularité au sens littéral il revient à l'existence de règles sous jacente hors une règle ou du moins une règle de calcul c'est finalement un algorithme ou pour martine 9 le hasard était ce qui ne peut pas s'expliquer par le calcul par exemple la suite 1 2 4 8 16 32 et ainsi de suite n'a rien d'aléatoire au sens de martin 9 parce qu'il existe un algorithme très simple pour la généré cet algorithme est par exemple l'instruction qui dit prends le dernier nombre est multiplié par deux c'est le succès prédictifs de cet algorithme très simple qui nous amène à dire que cette suite n'est pas aléatoire de la même manière la suite 1 1 0 1 0 0 1 0 0 0 1 0 0 0 0 1 0 0 0 0 0 et ainsi de suite c'est une suite qui elle non plus n'a rien d'aléatoire au sens de martin hoff et je vous laisse réfléchir à comment la générés avec un algorithme très simple mais alors le problème si on suit les pas de martin 9 c'est que tout de suite finie paraît non aléatoire en effet une suite finie peut être générés par un algorithme très simple qui se contentent de réciter les chiffres de la suite par ailleurs si la suite finie était vraiment aléatoire alors il faut s'attendre à ce qu'il soit possible que par chance elle soit égale à une suite très prévisible comme celle dont on a parlé plus tôt en fait le hasard de martin 9 n'a de sens que pour les suites infinie or nous autrement ne pouvons pas lire les suites pinaire infini à cause de nos limites cognitives et d'ailleurs si l'on en croit la thèse de church turing les ordinateurs non plus dès lors force est d'admettre que la notion de hasard fondamentale ne peut pas être déduite par une épistémologie qui se fonde sur une quantité finie de données et comme j'ai tendance à penser que seules de telles épistémologie sont pertinentes pour nous autres humains mais aussi pour les machines j'ai envie de dire que la notion de hasard fondamental n'a simplement pas sa place en épistémologie se posait la question de l'existence de hasard fondamentale s'est posé une question au sujet de laquelle on semble garantie de ne jamais pouvoir faire de progrès bon qui plus est on peut se demander si l'existence d'un hasard fondamentale a vraiment une utilité quelconque typiquement on se pose souvent la question du rapport entre les licences d'un art fondamental et le libre arbitre mais à bien y réfléchir une décision qui ne serait due à un hasard fondamental ça ne serait sans doute pas vraiment du libre arbitre typiquement aussi mes décisions étaient durs un art fondamental devrait forcément suivre les lois du hasard comme la loi des grands nombres fiq en fait me comprendrait énormément dans mon libre arbitre d'ailleurs je ne sais pas si c'est rassurant ou non mais nous autres humains sont en fait très mauvais pour générer un pur hasard en fait martynov démontra même que même si on dispose d'une suite infinie de données il est impossible de décider avec une machine de turing si la suite on tient un hasard fondamentale le hasard fondamentale est incalculable bref le hasard fondamentale semble être une notion veine mais alors la théorie des probabilités certes elle vraiment à quelque chose clairement si l'objectif des probabilités et de décrire un art fondamental j'ai envie de dire qu'il s'agit en effet d'une théorie vaines cependant au lieu de disserter sur un concept à la fois incalculable et peu utile on peut plus raisonnablement suivre les pas de la place la place est noté que la théorie des probabilités et remarquablement efficace pour décrire notre ignorance et notre connaissance dans ce cadre ce qui importe n'est plus le hasard fondamentale ce qui importe c'est l'incertitude due aux limites de nos connaissances et ça c'est un hasard qu'il est bel et bien possible de dompter est urgent de maîtriser et pour cela il est indispensable de s'immerger dans le monde fantastique régie par les lois des probabilités l'anr fois on avait estimé la taille d'une vie humaine à quelques téra octets et docteur d'état fait remarquer que dans ce terrain était il ya plusieurs sources d'informations différentes certaines viennent de la vue d'autres de l'odorat ou autres encore et se demandent s'il faut pas aussi en prendre en compte l'origine de ses sources et est ce que les métadonnées qui vont étiqueté du coup l'origine des sources ne représente pas finalement beaucoup d'informations mais la réponse est en fait non si vous regardez par exemple sur votre ordinateur les différents fichiers musiques vidéos ou autres en fait dire si un fichier est un fichier musique autres c'est juste une extension de poing mp3 en fait un peu plus que ça avec des en-têtes de fichiers mais toujours est il que l'origine en fête ou là nature de la source d'information est généralement facile à décrire en quelques beats d'information seulement et surtout cette quantité d'informations est beaucoup plus faible que le contenu lui-même de l'information qu'ils soient visuelles ou autre ainsi lorsqu'on inclut en plus les métadonnées en fait la quantité totale d'information d'une vie humaine ne change pas beaucoup elle reste de l'ordre du téraoctet nick l'homme habillé on lui demande si le côté in et n'a pas été négligé par la vidéo précédente en particulier est ce que finalement l'information à travers l'adn ne compte pas lui aussi en fait oui oui ça compte énormément mais on peut également estimer la quantité d'informations qui vient par exemple de l'adn la dnc pour un corps mince et 3 milliards de lettres qui correspond donc à quelque chose de l'ordre du gigaoctet or un gigaoctet c'est un millième de toute l'expérience de vie d'un humain qu'on a calculé l'anr fois et donc non ça ne change pas du tout l'ordre de condor de l'ensemble des données qui correspondent à une vie humaine je rebondis sur cette réflexion puisque du coup elle est très intéressante pour faire différence entre l'aïe qui est l'hymne est d'une certaine manière selon nos estimations il ya un rapport milles entre les deux ce qui suggère que la qui est de servir beaucoup plus important que l'ine ont bien sûr ce n'est pas tout à fait le cas puisque si on a un algorithme stupide et qu'on lui donne beaucoup beaucoup de données en fait ça ne suffira pas à faire de cet algorithme stupide un algorithme puissant donc ce n'est pas juste une question de quantité c'est aussi une question de qualité quelque part mais à cela j'ai aussi envie de rajouter que ce qui est vrai a dominé est également vrai de l'acquis la qualité des données informationnel est tout aussi important que la qualité des données qui décrivent l'algorithme qui est suivi par notre cortex cérébral colligées fait la remarque que les algorithmes sont beaucoup moins bon aujourd'hui que les bébés pour comprendre les données auxquelles ils ont accès et à ce sujet je vous recommande vivement les excellents cours de 5 cela ce domaine aux cages de france c'est vraiment absolument fascinant d'un membre c'est très balisé en plus alors ce qui est important de voir c'est que la coopération que faith and then dans son livre que je n'ai pas lu en train de spéculer sur le contenu du livre mais je devine que la distinction que ferrer stanislas dehaene est en train bébés d'aujourd'hui est un algorithme d'aujourd'hui - a priori les bébés du passé et de demain vont pas beaucoup changé mais par contre les algorithmes le ont énormément évolué au cours des mêmes deux dernières années donc c'est dire que quand on compare bébé algorithmes faut faire attention avec l algorithme on utilise comme point de comparaison en particulier il ya pas mal de raisons de penser au repos notamment vers les travaux de georges tenenbaum qui est d'ailleurs beaucoup cité par stanislas de haine lorsque les algorithmes qui font ce qu'on appelle du belize anis mili hiérarchique on finira pas en parler dans cette série en fait on a des algorithmes qui sont très capables d'apprendre dans énormément de contextes différents des modèles très généraux pour ensuite à mieux comprendre les données donc il se pourrait que des algorithmes suffisamment parisien est en fait les mêmes capacités que les bébés et de leurs sons en croit la case de torture et ne peut imaginer très raisonnablement que cela finira par être le cas puisqu'il n'y a aucune raison que le cortex cérébral humain soit la manière optimale d'analysé des données et j'espère que vous avez aimé cette vidéo et que vous avez senti l'importance des vidéos précédentes et de raisonner en termes d'information et de flux d'informations finalement si on veut répondre à des questions comme l'existence du hasard fondamental c'est certainement la preuve la plus fiable pour y arriver la chose très important que l'on a vu dans cette vidéo ici c'est qu'il semble avoir un lien assez finement talent iii algorithmes et probabilités et c'est un lien qui va grandement talent pour avancer vers ce que j'ai appelé le puritanisme dans mon livre est avant d'en arriver aux purs balsamique en fait va être utile de mieux comprendre l'informatique théorique les fondements de l d'eau et inique et la prochaine fois on va parler justement d'un des aspects les plus intrigants de l'algorithmique puisque je vais vous parler d'un an mystérieux qui contient tous les secrets des mathématiques mais qu'on ne peut pas calculer si vous avez aimez cette vidéo pensez à la ligue avec mon cal partager conseils aux abonnés pourront compter sur l'épisode merci aux supporteurs dont et j'espère que nous serons là la prochaine fois bref vous voyez que le hasard le plus total peut parfois faire naître des formes parfaitement déterminé que ce soit la trajectoire en ligne droite dans ce premier exemple où que ce soit le cercle dans ce deuxième exemple pourvu qu'on le regarde de suffisamment loin le hasard fait émerger des formes inéluctable indécise où elle martine le décret bradshaw aucun essai that we should considère nord de cette ville tess base de cette phase effective test.com piotta voltaire