lundi prochain il y a le match France- Belgique qui va avoir lieu à 18h l'euro 2024 et la question que je vous pose c'est est-ce qu'il faut parier sur la victoire de la France les côtes selon Unibet sont à 1,87 pour une victoire de la France 3,22 pour un match nul et 4,6 pour la Belgique ça veut dire que si vous misez 1 € sur la victoire de la France et que la France gagne vous gagnez 187 en fait vous gagnez 87 centimes puisque vous avez payé 1 € pour pouvoir jouer et donc la question que je vous pose c'est lequel de ces paris est un Paris gagnant sachant ce que l'on peut savoir à l'état actuel c'est-à-dire quel est le Paris qui maximise l'espérance de gain avant d'aller plus loin je précise que les jeux d'argent peuvent provoquer des addictions très dangereuses qui peuvent mettre des vies en danger prenez soin de ne parer que des moutants raisonnables et d'accompagner vos proches qui pourraient être victimes de ces addictions plus généralement à ce sujet je vous recommande vivement cet excellent documentaire d'Arté qui appelle à réguler beaucoup plus drastiquement le marketing prédateur des géants des paris sportifs notamment qui abusent des mêmes ressorts psychologiques que les réseaux sociaux et les machines à sous notamment et en fait ce qui va m'intéresser aujourd'hui ce n'est pas tant s'il faut jouer de l'argent mais plutôt comment utiliser les mathématiques pour prédire les résultats probables des matchs de football et en particulier pour identifier les paris qui peuvent être gagnants en espérance c'est-à-dire en gros des pareils qui à la longue finiront par nous faire gagner de l'argent on va parler en particulier de playful ai un site web lancé par des amis à savoir Lucas Mestre et Victor Christophe tous deux diplômés de l'EPFL et dont la recherche a produit des modèles mathématiques à l'état de l'art de la recherche pour estimer la probabilité de différentes issues des matchs de football comme on en reparlera leur site effectue en permanence des prédictions paisiennes sur l'issue des prochains matchs de football mais surtout comme on va le voir ces mathématiques trouvent des applications bien au-delà des paris sportifs ils sont par exemple au cœur de la recherche sur l'alignement des modèles de langage et de Cell sur la démocratie numérique notamment celle du projet tournesol d'ailleurs il y a un an j'ai annoncé sur Twitter notre découverte d'une structure mathématique merveilleuse et bien comme on va le voir cette structure est au cœur de l'apprentissage des préférences humaines mais aussi donc de la prédiction du niveau des équipes de football à 2024 pour comprendre comment fonctionne playful ai on va faire un détour vers un autre problème celui d'établir un classement des joueurs d'échec la difficulté c'est que le niveau d'une joueuse ne s'observe pas directement il ne s'observe que comparativement au niveau d'autres joueurs contre lesquels la joueuse a gagné ou perdu comme l'explique très bien David de sens étonnante dans une de ses dernières vidéos dans les années 1960 le chercheur harpad hello a proposé un nouveau système aujourd'hui appelé le système Hello pour évaluer les niveaux des joueurs à partir de données comparatives en bref après chaque match le vainqueur va gagner des points au dépend du perdant et ce nombre de points gagnés va dépendre des évaluations des niveaux des deux joueurs ainsi si vous êtes un très bon joueur d'échec avec un score ho de 2000 et si vous battez un joueur médiocre comme Tibao alors vous ne gagnerez pas beaucoup de points à l'inverse si vous battez un joueur dont le score Ho est de000 alors vous gagnerez pas mal de points enfin si vous battez un joueur à priori très supérieur à vous comme Magnus Carlson alors vous gagnerez énormément de points de façon plus précise chaque score ho x va être associé à une puissance px qui est égale à 10^ x/ 400 ce qui est important à noter c'est que cette puissance va augmenter exponentiellement avec le score x maintenant si vous avez un score ho égal à X et si vous battez un adversaire dont le score Ho est égal à y alors le nombre de points que vous allez gagner sera la puissance de y divisé par la somme des puissances des deux joueurs c'est-à-dire P y / par px + Py on voit bien avec cette formule que si x est bien plus grand que y ce qui correspond au cas où vous battez Tibo alors P2X va être beaucoup beaucoup plus grand que P2 y et vous allez du coup gagner très très très peu de points à l'inverse si vous battez un joueur de votre niveau autrement dit si x est de même ordre que y alors vous gagnerez autour d'un demi-point enfin si vous battez quelqu'un qui est bien meilleur que vous selon le score ho alors vous gagnerez presque un point complet et notez que si vous per alors la quantité de points que vous perdez ne sera pas Py divis par px + Py ce sera px divis par px + Py histoire de bien rendre les calculs symétriques entre les deux joueurs particulier si vous perdez contre Magnus cararson assurez-vous vous allez pas perdre beaucoup de points et alors vu que le nombre maximal de points que vous pouvez gagner dans une partie est égal à 1 d'après notre définition vous vous dites peut-être que si votre score hello est actuellement de 2000 alors même en battant Magnus Carson vous allez pas gagner tant de points que cela en fait il va vous falloir gagner presque 1000 1000 parties contre des joueurs du niveau de Magnus Carson pour atteindre son score hello et 1000 parties bah ça fait quand même pas mal de parties à jouer et bien en pratique le CO peut tenir compte de cela en multipliant le nombre de points gagnés par un facteur K qui est typiquement plus grand pour un joueur qui a peu joué et donc dont le score Ho est a priori mal estimé en fait ce facteur K est intimement lié au dilemme innovation sécurité dont je vous ai parlé dans une vidéo précédente et en terme baisien c'est même plus encore lié au dilemme biais variant qui correspond à une vidéo encore un peu plus vieille et ce qui va encore plus nous intéresser aujourd'hui c'est qu'en terme d'apprentissage statistique le facteur k correspond exactement au learning rate de la descente de gradient lorsqu'on cherche à minimiser la vrai semblance des données dans un modèle probabiliste ça risque d'être compliqué ne partez pas tout de suite on va détailler ça en 1952 les statisticiens Ralph Bradley et Milton Terry propose un modèle probabiliste de l'issue d'un match à partir du niveau des adversaires ce modèle est très simple la probabilité qu'un joueur de niveau x batte un adversaire de niveau y est donné par px div par px + Py où px croit exponentiellement avec X on a vu que dans le cas du ho on a px est égal à 10^ X / 400 mais on peut imaginer de façon plus générale une fonction px de la forme px est égale à e^ TX où le paramètre t va typiquement définir l'échelle des scores mais maintenant contrairement au score ho dans le modèle de bradetterie x et y vont pe être des scorses inconnus qu'on va estimer sans faire d'hypothèse en amant sur leur valeurs notamment sur les valeurs calculées jusque-l quand on a un modèle probabiliste comme cela avec des paramètres inconnus qui permettent de faire des prédictions probabilistes sur des résultats observés il est courant de chercher à estimer ces paramètres en question en sélectionnant ceux qui rendent les données observées aussi vraisemblables que possible concrètement tu fais comment notre cas il s'agit de sélectionner les scores des différents joueurs qui maximisent la vraissemblance des données sachant les résultats des matchs entre les participants les scores qui maximisent cette vraissemblance sont tout simplement appelés les maximums de vraissemblance en supposant que les résultats des différents matchs sont indépendants la vraieemblance des résultats observés sachant les scores XI des différents joueurs I est égal au produit des P divis par pi + PJ pour tous les matchs entre un joueur I et J ou I est le vainqueur du match et bien sûr dans cette équation Pi est comme vous l'imaginez P de Xi c'est-à-dire la puissance du joueur i sachant que son score est égal à XI alors d'un point de vue mathématique manipuler des multiplications comme celle-là c'est toujours un peu compliqué et donc il y a une astuce usuelle qu'on va appliquer qui consiste à utiliser le logarithme parce que le logarithme va transformmer cette mulpication en somme notre problème est alors équivalent à maximiser la log vraissemblance qui est égale à la somme des log de PI divis par pi + PJ et pour maximiser une telle quantité on va chercher à annuler les dérivées par partiel par rapport au score XI si on prend un unique terme log de PI divis par pi + PJ et si on exploite le fait que Pi est de la forme e^ t x XI on obtient une dérivée par rapport à XJ est égal à PJ divis par pi + PJ autrement dit on obtient exactement l'opposé des points que I gagne après sa victoire contre J dans le système Loo au facteur k prè bah oui en fait ce calcule de la dérivée d'un terme de la quantité à maximiser et le fait d'ajouter cette dérivé aux paramètres qu'on cherche à estimer un facteur k près c'est exactement ce que propose l'algorithme de descente de gradient stochastique qui est vraiment le moteur de l'apprentissage des réseaux de neuron et ça sachant notamment les propriétés de cette fonction de vraissemblance dont on peut notamment montrer qu'elle est une fonction concave des scores des différents joueurs ça garantit le fait que asymptotiquement quand les joueurs ont fait suffisamment de parties les scores calculés par cette descente de gradient stochastique convergeront vers le maximum de vraissemblance N C manière on vient de justifier le système ho avec des fondements probabilistes en particulier cette interprétation probabiliste des scores ho permet de justifier la cohérence de statistique observée dans les simulations que David a faite dans sa vidéo c'est dingue non en fait le lien entre machine learning et classement Ho est même plus fin que cela encore puisque en pratique dans le cadre du classement de la Fédération internationale des échecs la mise à jour des scores hello ne se fait pas juste après un match mais plutôt après un tournoi qui correspond à une suite de match et ça ça corresond corespond exactement à une descente de gradients stochastiqu avec des gradients stochastiques estimés par batch de données bon je vais pas expliquer exactement ce que ça signifie cette histoire de batch mais sachez que c'est extrêmement standard en machine learning notamment pour exploiter la capacité de calcul paralysé des cartes graphiques et donc pour accélérer les calculs de descente de gradient stocastique donc c'est pas juste des principes abstraits l'avantage toutefois d'avoir un approche vraiment probabiliste plutôt que juste le classement ho qui ne reste qu'une approximation du raisonnement probabiliste c'est qu'on pourra être beaucoup plus efficace dans l'estimation des niveaux des joueurs avec moins de données en terme statistiqu on dit qu'on aura une meilleure complexité d'échantillonnage pour un nombre fixé de résultats de match observés on aura une estimation plus juste des niveaux des différents joueurs en particulier si une très bonne joueuse joue ses premiers matchs officiels alors ses premières victimes risquent de perdre beaucoup de points car ils perdent contre une joueuse qui a alors un très mauvais score ho mais au fur et à mesure que le score ho de la très bonne joueuse sera mieux estimé alors les autres joueurs qui perdront contre elle perdront moins de points le moment de la défaite influe alors sur le score des joueurs et ça ça paraît extrêmement injuste et bien ça c'est un artefact du classement ho et ça n'arriverait pas si on prenait l'approche probabiliste c'est-à-dire si à tout moment on calculait le maximum de vraissemblance pour calculer les scores des différents joueurs par ailleurs l'approche probabiliste permet de corriger d'autres anomalies comme le fait que les scores hlo des joueurs de Chess.com semblent surévaluer par rapport au Scor ho attribué par la Fédération international des échecs à partir des matchs hors ligne tout ça a priori à cause de phénomèn subtiles d'inflation de score dû notamment à l'arrivée d'un grand nombre de nouveaux joueurs on a d'ailleurs un phénomène similaire entre le hlo des joueurs français et celui des joueurs russes mieux encore si on met une casquette maintenant pleinement païsienne on peut faire mieux que le maximum de vraissemblance et inclure des a prioris pour estimer les niveaux probables des joueurs qui ont joué très peu de matchs mais au sujet duquel on a d'autres informations qui n'ont pas été répertorié dans les données mieux encore la distribution à postériori sur les niveaux des différents joueurs nous renseigne sur l'incertitude qu'il faut avoir sur le niveau estimé des différents joueurs sachant les données limitées qu'on a à son sujet bref l'approche probabéiste est bien meilleure sur de nombreux aspects elle a toutefois un défaut de taille elle requiert des calculs qui sont plus difficiles à comprendre pour les joueurs en particulier votre score pourrait évoluer sans que vous n'ayez joué par exemple si celle qui vous a battu a ensuite battu des joueurs beaucoup plus forts que vous ce qui pousse le modèle probabiliste à interpréter votre défaite différemment en fait la beauté du ho c'est surtout qu'il est remarquablement simple à comprendre votre score n'évolue qu'après un match il augmente si vous avez gagné il décroit sinon et le changement de score est lié à la différence de niveau entre le perdant et le gagnant pour estimer les niveaux des différentes équipes de football de l'euro 2024 l'équipe de playful ai ne s'est clairement pas attardé sur cette explicabilité ils ont préféré avoir des estimations nation aussi baisienne que possible c'est pourquoi ils sont partis du modèle de Bradl terie qu'ils ont ensuite adapté pour peaufiner les prédictions des matchs notez que de plus playful ai tientent compte du fait que le niveau d'une équipe évolue au cours du temps clairement l'équipe de France des Mbappé Griezmann et chuini n'est pas la même que celle des Gourcuf toualan et Escudé c'est une autre époque je ne rentre pas dans les détails de comment cette évolution est prise en compte mais ce qu'il faut bien voir c'est que le modèle de Bradley Terry peut naturellement être utilisé comme une pièce d'un puzzle plus large qui modélise un bien plus grand nombre de considérations pertinentes à l'estimation des niveaux des équipes de football en particulier même si ce n'est pas finalement le modèle qu'ils ont adopté pour playful ai Lucas Mestre Victor Christophe et leur directeur de thèse Mathias grossgluser avaient précédemment considéré un modèle selon lequel le niveau d'une équipe était la somme des niveaux des joueurs selon ce modèle il ne s'agit plus d'estimer ce que vaut une équipe il s'agit d'estimer le niveau des footballeurs pour en déduire le niveau des équipes le gros avantage de cette approche c'est qu'elle permet d'exploiter les résultats des matchs des clubs qui sont beaucoup plus nombreux pour ensuite évaluer le niveau des équipes nationales malheureusement cette approche a aussi quelques défauts en premier lieu elle requiert beaucoup plus de calcul car il y a beaucoup beaucoup beaucoup de joueurs de football un truc chouette c'est que des astuces à base de méthodes de noyau ou kernel method en anglais peuvent être utilisé pour courtcircuiter l'estimation des niveaux individuels des joueurs et obtenir des estimations avec moins de calcul surtout le plus gros problème avec cette méthode c'est qu'elle nécessite de collecter les informations à propos des joueurs qui ont participé aux différents matchs malheureusement ces données sont souvent déficientes ou difficiles d'accès et c'est en fait vraiment là que le bas blesse en fait pour être honnête j'espérais initialement faire une vidéo sur le GO du football le meilleur joueur de tous les temps en espérant que le modèle de Lucas Victor et Mathias m'aiderait à fournir à tout moment une quantification du score du meilleur joueur du monde exactement comme on le fait aux échecs malheureusement cette difficulté d'accéder à des données et à des puissances de calcul a rendu mon ambition un peu caduc mais passons on peut maintenant utiliser le modèle de Lucas et Christophe playful pour essayer de répondre à la question initiale de cette vidéo est-ce qu'il faut parler sur une l'cttoire de la France bien la France a une probabilité de 39 % d'après le modèle de de battre la Belgique donc c'est associé à une côte de 1,87 donc ça ça veut dire quoi ça veut dire que avec une probabilité 39 % vous allez gagner 1,87 et vous êtes sûr quoi qu'il arrive de perdre 1 € puisque c'est l'euro que vous jouez et donc ça ça vous fait une espérience de gain de 27 de Mo- 27 centimes ça veut dire que si vous répéter les paril du genre vous allez perdre à chaque fois autour de 27 centimes pas top maintenant on peut se demander ce qui se passe maintenant si vous pariez pour un match nul pour une victoire de la Belgique pour un match nul donc si vous fait 3,22 FO 7ette fois une probabilité de match nul qui d'près le model est égale à 0,31 tout ça moins le 1 € que vous devez jouer pour pouvoir participer et là c'est un Paris qui est presque nul vous perdez quand même 0,1 centime à priori en espérance euh à chaacun de ses pareils par contre maintenant si vous pariez sur la Belgique et bien en pariant sur la Belgique vous avez 4,6 avec une probabilité cette fois de 0,3 donc 30 % et avec l'euro que vous perdez à chaque fois et ça ça vous fait une espéence de gain de 38 centimes donc c'est quand même assez ouf si vous faites confiance au modèle de Luca et euh et Victor euh bah vous devez parler sur la Belgique et avec la Belgique non seulement vous avez une espérriance de positive mais en plus à priori assez nettement positive bien sûr ça veut pas dire que dans ce cas la Belgique va gagner vous allez gagner beaucoup d'argent c'est veut dire que d'après le modèle de Lucas et Victor si vous répétez des paris de la sorte vous devriez avoir gagneré de l'argent en espérance alors encore une fois prenez tout ça avec des pincettes mais si vous vraiment des paris sportifs en particulier des problèmes d'addiction qui viennent avec les paris sportifs c'est des choses qui peuvent vraiment mettre des vies en danger la dernière chose que je voulais vous montrer par rapport à playf c'est que on on voit sur leur site non seulement si enfin les probabilités de victoire des différentes équipes mais également une évolution des performances des équipes à travers le temps donc ça correspondait au modèle qui était dynamique à travers le temps que j'ai mentionné un petit peu rapidement un peu plus tôt dans la vidéo et vous voyez qu'en fait pendant longtemps la France était supérieure à la Belgique en fait le la meilleure équipe de France d'après ce graphe et ben en fait c'était plus équipe de France des années 2000 et quelques donc avant 2002 la France éit archifavorite la Coupe du Monde 2022 mais depuis il un énorme creux autour des années 2009 dans la Coupe du Monde 2010 mais en plus ensuite c'est reparti vers le haut mais vous voyez que la Belgique aussi est assez forte et même en 2020 même 2018 a été à priori plus forte que la France d'après le modèle bon après c'est chaque match forcément de l'É mais vous voyez que plus récemment la Belgique a a pas mal perdu et c'est ça qui fait que la France est favorite contre la Belgique mais la France a également beaucoup perdu au cours des de la dernière année et c'est pour ça que le match est en tout cas d'après PF plus indécis que ce que les côtes de unibibet peuvent laisser penser le modèle de bradatterie a récemment suscité énormément d'intérêt notamment dans le cadre de ce que les bigtech appellent le problème de alignement des modèles de langage en particulier dans ce cadre on demande à des juges humains de comparer différentes réponses possibles d'un modèle de langage pour ensuite le modifier et le pousser à préférer certaines formes de compléion de texte alors historiquement l'approche annoncée en fanfare par open ai lors du lancement de chat GPT a été nommé reinforcement learning with human feedback notamment suite à des travaux de Google et Open ai de 2017 qui ont ensuite été complété dans un article de 2020 en gros l'idée de ces approches est de modéliser les juges humains par une fon fonction qui assigne un score à chaque réponse de che GPT ce score va typiquement être une fonction linéaire d'une représentation vectorielle de la réponse autrement dit on représente la réponse par une suite de nombres et on suppose que le score de la réponse est une somme pondérée de la suite des nombres il s'agit ensuite de déterminer les coefficients de la fonction linéaire c'est-à-dire la valeur positive ou négative d'avoir un grand nombre dans chacune des cases de la représentation vectorielle ou dit autrement on va estimer la contribution de chaque coordonnée au score de la réponse un peu comme on cherchait à estimer le niveau des différents joueurs des équipes de football c'est limpide non en fait pour ceux qui ont l'habitude de faire de l'apprentissage des préférences humaines ce dispositif est loin d'être si révolutionnaire que ce que le marketing sur puuissant d'Open peut laisser croire il y a trop souvent une tendance dans les organisations qui développent des algorithmes génératifs à survendre leurs travaux et à ignorer ceux des autres notamment parce que ces organisations font des profits énormes grâce au buzz qu'ell génèent alors que en pratique dans les nombreuses entreprises clientes avec qui j'ai échang le retour d'expérience est davantage que la valeur commerciale de ces algorithmes génératifs est en fait loin d'être aussi incroyable dès lors qu'il faut faire plus que simplement pondre des codes basiques ou dès lors que la fiabilité des informations générées par ces algorithmes est un tempant soit peu importante en fait côté recherche l'énorme littérature scientifique sur l'élicitation et l'apprentissage des préférences humaines n'a pas attendu la recherche sur l'alignement d'Open ai pour développer des solutions d'ailleurs si on prend le temps d'y réfléchir un petit peu on se rend compte que les IA les plus puissantes et les plus lucratives des bigtech à savoir les algorithmes de ciblage publicitaire et les algorithmes de recommandation sont déjà obsédés depuis bien longtemps par les préférences humaine et elle cherche constamment à prédire ce qui vous plaira en exploitant notamment massivement des modèles de Bradley Terry et les jugements comparatifs des internut en considérant typiquement que si vous cliquez sur une option c'est celle qui vous attire le plus parmi celles qui vous ont été proposées bref méfiez-vous de la hype surtout d'entreprise comme open a don l'influence du marketing sur le monde académique est en fait énorme il est tellement grand que même moi je me sens obligé de rajouter l'expression reinforcement learning with human feedback dans mes articles de recherche car clairement cela augmente drastiquement la probabilité que l'article soit accepté et oui le comité de relecture scientifique fait que moi aussi je relaie le marketing d'Open ey dans mes publication scientifique pour espérer passer le filtre de la revue par les paires qui restent des humains qui eux aussi sont fortement exposés à ce marketing pas top top mais surtout là où les travaux d'Open ai sur le reinforcement learning with human feedback ont vraiment étaé très largement survendu c'est qu'on a découvert seulement après coup que le cœur de l'alignement des chatbots le gros du travail de dressage des algorithmes de langage réside en fait ailleurs notamment dans le fameux préprompt dont Monsieur fi vous a excellemment bien parlé et dont beaucoup de chercheurs ont identifier les énormes limites en terme de sécurité pour s'en rendre compte il suffit de taper LLM jailbreaking ou prompt injection sur votre moteur de recherche favorie qui a non pas dter doc Doo bien sûr quoi qu'il en soit des chercheurs de Stanford ont par la suite montré que le reinforcement learning with human feedback est en fait équivalent à une approche peut-être plus simple en tout cas plus directe qu'ils ont appelé le direct preference optimization qui consiste à voir les jugements comparatifs des juges humains comme des votes directement sur les paramètres du modèle de langage ainsi lorsqu'on dit qu'on préfère une réponse a à une réponse B on dit finalement qu'il faut tourner les paramètres de l'algorithme de sorte qu'il se metent à produire plus souvent la réponse a que la réponse B et bien cette intuition est en fait parfaitement formalisable notamment à travers un mode mod de bradterie paramétré par les paramètres de l'algorithme en question autrement dit l'alignement des réseaux de neurones il s'agisse d'un modèle de langage ou d'uneia de recommandation ce n'est finalement pas beaucoup plus qu'un modèle baisien paramétré de Bradley Terry avec un a priori fourni par le modèle pré-entraîné là le le plus compliqué c'est d'arriver à suivre le rythme dit plus simplement en disant que vous préférez une réponse a à une réponse B vous ne faites rien d'autre que fournir une sorte de résultat d'un match entre A et B et la mécanique de bras de l'éée surtout quand il est paramétré permet de modifier automatiquement les algorithmes pour coller davantage à vos préférences intuitivement en mettant sur le banc les paramètres qui jouent à votre défaveur et en mettant sur le terrain les paramètres qui vont dans votre sens il y a un an je partageais sur Twitter la joie intense d'une découverte mathématique que mon ami Julien Fageot et moi avion fait en cherchant à généraliser le modèle de bradlterie pour tenir compte de jugements comparatifs quantitatif concrètement une victoire 7-0 nous dit un peu plus sur la différence de niveau entre les équipes que le simple fait qu'il y ait eu une victoire mais alors ne pourrait-on pas exploiter cette information sur la différence de but pour peaufiner notre estimation des niveaux des équipes ça serait top ce problème est au cœur de tournsol où les jugements des contributeurs sont des comparaisons quantitatives entre vidéos dans la mesure où il y a un slider qui peut-être déplacé presque continuement de gauche à droite et c'est donc rapidement devenu l'un des nombreux problèmes fondamentaux de notre projet et il me semble plus largement au cœur de tout projet de démocratie numérique en effet si on veut que les citoyens votent il va falloir définir des mode d'expression c'est ce qu'on appelle dans le jargon le problème de l'élicitation des préférences pour des raisons notamment de facilité de calcul j'ai initialement opté pour un modèle quadratique qu'on appelle aujourd'hui dans le code de tournesol le modèle hookien en référence au ressort à énergie potentielle quadratique du modèle du physicien Robert hook ce qui est mieux que rien mais on s'est rendu compte par la suite que ce modèle peut justifier théoriquement avait de surcroix de nombreuses mauvaises propriétés en particulier pour des raisons que je vous épargne aujourd'hui il pouvait arriver que en accroissant le jugement comparatif entre deux vidéos on en venait à décroître le score de la vidéo jugée plus positivement clairement cette propriété était fortement indésirable elle poussait même des contributeurs de tournesol à éviter de mettre des jugements extrêmes alors c'était mon cas clairement il fallait un modèle plus solide théoriquement j'ai alors ressorti de mes tiroirs un vieux modèle que j'avais initialement considéré sans toutefois avoir su démontrer qu'il avait les propriétés escomptées et j'ai ensuite eu la chance de pouvoir en parler à Julien et pour être honnête la merveilleuse structure mathématique dont je parle dans mon tweet c'est en fait surtout Julien qui l'a découverte non seulement Julien a démontré que mon modèle avait la propriété de monotonie qui dit que si on rend une comparaison davantage favorable à a contre B alors ça va nécessairement améliorer le score de a et décroître celui de B mais surtout Julien a démontré que mon modèle faisait partie d'une famille plus générale qu'on a ensuite appelé modèle de bradléérie généralisé dont tous les membres avaient cette propriété de monotonie qui plusit de façon très satisfaisante cette famille contient le modèle classique de Bradley Terry mais il y a mieux pour toute cette famille dont les membres sont paramétrés par une loi de probabilité qu'on appelle la loi racine et donc c'est une famille assez complexe on a néanmoins la garantie que la logessemblance sera toujours convexe et même souvent calculable explicitement grâce à de délicieuses connexions avec la théorie des fonctions génératrices de cumulant qui ont été précédemment étudiés pour de tout autres raisons par d'autres chercheurs c'est simple hein c'est juste des maths et ça ça va garantir que des algorithmes très simples comme la descente de gadiion stocastique vont être capable de calculer rapidement les maximum de vraissemblance d'un modèle de bradlterie généralisé ou mieux encore le maximum du postérieur baisien et oui parce qu'en ajoutant un a priori baisien gausien à la log vraessemblance on peut même avoir davantage de propriété désiraable encore comme le fait que pour une sous-famille de la famille de bradterie généralisé le maximum du Post urs baisien et lipsit résilient à des jugements erronés B c'était un peu compliqué en gros ce que je veux dire c'est que sur internet ça arrive souvent de faire des erreurs grossières dans les comparaisons comme par exemple confondre à gauche et à droite et pour chaque erreur de la sorte on a la garantie que l'impact de l'erreur sur les calcul des scores va être limité oui c'est possible en tout cas la découverte de cette structure mathématique merveilleuse avec toutes ces belles propriété ça a vraiment été pour moi l'un des grands tempsforts de l'année 2023 et j'y vois une contribution importante à la recherche sur l'apprentissage des préférences humaines et je ne suis pas le seul grâce aux contributions ensuite de Sadek faratkan et d'Oscar vilmo on a écrit un article de recherche sur le sujet et j'ai le grand plaisir de vous dire que notre article de recherche a été accepté à publication dans la prestigieuse conférence académique triple ai 2024 en tout cas côté tournesol on s'est rapidement précipité pour ajouter cette découverte mathématique aux algorithmes qui agragege les jugements des contributeurs pour ensuite identifier les vidéos qui selon ces contributeurs sont les meilleurs à commandé massivement parmi toutes les vidéos publiées sur Youtube de façon plus générale tout projet de démocratie numérique est inéluctablement confronté au problème de l'espace de parole des citoyens dans les scrutins classiques cet espace est extrêmement limité puisqu'il correspond à ne choisir qu'un candidat politique parmi une poignée d'alternative à l'inverse sur les réseaux sociaux notamment cet espace est rapidement chaotique puisque les citoyens peuvent produire des thades interminables qu'il va être extrêmement difficile d'agréger en une décision collective à prendre surtout si on veut faire ça de manière transparente et explicable des méthodes alternatives d'expression semistructuré semblent requises c'est ce que proposent notamment les plateformes police make.org et les community notes sur Twitter où les participants peuvent émettre de courtes propositions et évaluer les propositions des autres avec des jugements directs à coup de like et de dislike voilà des formes de délibération beaucoup plus structurées et faciles à analyser et qui permettent néanmoins d'entrer beaucoup plus dans la complexité que les scrutins classiques cependant on pourrait vouloir explorer des propositions plus complexes notamment celles qui ne tiennent pas en 140 caractères et on pourrait par ailleurs avoir des jugements plus subtils que juste dire bien ou pas bien et bien d'une certaine manière c'est précisément ce que propose tournosol les propositions considérées sont les vidéos YouTube qui en fait à bien y réfléchir contient chacune des narratives sous-jacents avec différentes justification plus ou moins solide tournesol propose ainsi d'évaluer ses différentes propositions et plutôt qu'un simple like ou dislike on demande donc des comparaisons quantitatives entre les propositions qu'on analyse avec un modèle généralisé de brasterry c'est puissant hein cependant il est très loin d'être clair que cette élicitation des préférences par comparaison quantitative de vidéos YouTube soit la meilleur des formes d'expression possies en particulier nombre de contributeurs au projet nous ont suggéré d'avoir un système de notation car celui-ci pourrait être plus simple à utiliser voilà qui correspond à un vieux débat dans le domaine faut-il préférer les jugements direct comme sur IMDB ou comparatif comme sur tournesol et bien trouve qu'on a récemment fait des progrès dans ce débat que je vous détaillerai une autre fois mais intuitivement si ce qui nous intéresse c'est de discerner les tops vidéos parmi les excellentes vidéos et de ne jamais recommander les vidéos bof alors une combinaison judicieuse de jugement direct et de jugement comparatif semble en fait être l'optimal en particulier les jugements direct semblent très utile pour drecommander mais les jugements comparatifs semblent plus utiles pour recommander le very best mais tout ça on en reparlera sans doute une prochaine fois l'une des grandes joies des mathématiques c'est de créer des passerelles qui unifient des sujets a priori extrêmement distants j'espère que dans cette vidéo j'ai pu vous faire sentir cela en étudiant les comparaisons le modèle de braslterie et ses généralisations font le pont entre un grand nombre de disciplines de l'évaluation des niveaux des joueurs d'échec au paris sportif en passant par l'apprentissage des préférences humaines avec des applications fondamentales pour la la démocratie numérique en particulier les modèles de bradlet terie se sont retrouvés au cœur d'initiative de démocratie numérique comme les excellents projets webild pour la gouvernance collaborative du don de nourriture et ces variantes appliquées à l'éthique des voitures autonomes ou au dons de rein et j'aimerais tellement pouvoir vous dire qu'un grand nombre de grandes équipes travaillent d'arrache-pied pour aller beaucoup plus vite beaucoup plus loin dans la recherche sur les fondements mathématiques mais aussi philosophique psychologique et sociologique d'une démocratie numérique sécurisée et satisfaisante malheureusement à l'heure même où la haine triomphe à travers le monde avec une montée terrifiante de l'autoritarisme et de la corruption je vous dois bien avouer que les moyens de recherche alloués à ces sujets d'intérêt public sont aujourd'hui minimes surtout en comparaison des moyens monumentaux alloués aux algorithmes génératifs par le privé et par la recherche publique lesquels sont en fait beaucoup plus simples à intégrer dans des applications malveillantes à commencer par les arnaques en ligne la désinformation et peut-être surtout le cyberhcèlement via des deep fak pornographiques j'ai juste envie de vomir en tout cas le projet tournesol va malheureusement être ralenti notre association à but non lucratif n'ayant pas sur récolter des fonds suffisants j'ai été contraint de licencier le seul employé de tournesol qui est pourtant une personne fantastique et absolument brillante tournesol va ainsi redevenir un projet entièrement bénévole avec des contributeurs dévoués qui comme moi développont ce projet et effectuant des découvertes scientifiques uniquement sur notre temps libre quelques heures par semaine clairement si l'on veut vraiment combattre efficacement la haine la corruption et la désinformation il va nous falloir beaucoup beaucoup beaucoup plus d'aide et vous pouvez aider ah bon vous pouvez aider financièrement avec des dons à l'association ou en nous aidant à effectuer des demandes de subvention vous pouvez aussi aider techniquement en contribuant au code libre et open source ou en collaborant avec nous sur des sujets de recherche et puis vous pouvez nous aider directement en fournissant des jugements sur la plateforme qui aideront la communauté à identifier davantage de contenu d'intérêt public et qui nourriront la base de données publiqu pour attirer les chercheurs vers les sujets de démocratie numérique plutôt que vers la hype des algorithmes génératifs enfin vous pouvez nous aider en promouvant le projet tournesol autour de vous dites à vos proches de participer interpellez les influenceurs et les journalistes et exigez que la démocratie numérique devienne un sujet central une réponse indispensable au déclin globalisé des démocraties et à la montée de l'autoritarisme comme on en parle en long en large et en travers dans notre livre la dictature des algorithmes on a désespérément besoin de vous pour avancer la recherche sur l'élicitation et l'apprentissage des préférences des citoyens et pour proposer une solution de gouvernance démocratique de l'espace informationnel de sorte à empêcher le contrôle de cet espace par des milliardaires devenus surpuissants par des partis politiques et des ingérances étrangères devenu extrêmement haineuses et par un cybercrim toujours plus rentable