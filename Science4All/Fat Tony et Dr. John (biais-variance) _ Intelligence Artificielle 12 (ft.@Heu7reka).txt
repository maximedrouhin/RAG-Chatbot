non mais tu vois bien ce que je veux dire c'est quand même hyper bizarre c'est quoi tu devrait poser la question à l'est c'est plutôt son domaine ouais c'est vrai qu'il est plus intelligent toi je vois pas pourquoi je perds mon temps ok les j'ai lu le livre the black swan de nassim taleb que tu conseiller dans une de tes vidéos j'ai été particulièrement intrigués par le débat entre fat tony et dr john tu peux me rafraîchir la mémoire c'est quoi déjà ces débats imagine que je te dise que cette pièce n'est absolument pas truqué mais qu'après huit ans et elle est toujours tombé surface quelle est la probabilité pour que cette même pièce tombe sur piles ou 9e lancé ah oui ça me rappelle quelque chose tu sais qu'en fait c'est une question vraiment fascinante et absolument non trivial d'ailleurs si je me souviens bien fat tony dr dionne ont des réponses très différentes ce qui est intéressant c'est que c'est un peu des réponses stéréotypées qui devra peut-être décrire les deux personnages ça permet de mieux visualiser le débat ok alors fait tony c'est un trader de brooklyn très riche pas si gros que ça c'est juste un surnom mais c'est vrai que même si tous ces costumes sont taillés sur mesure en italie quand ils les portent on a quand même un peu l'impression que ça vient de chez celio c'est un bon vivant il adore manger faire la fête il a commencé tout en bas de l'échelle un boulot administratif dans une banque à wall street mais il a vite été promu à tony il n'est pas bardé de diplômes mais il comprend les gens il sait leur parler il sait négocier c'est un charmeur et un embrouilleur c'est le genre de mec qui peut faire un scandale à l'aéroport juste histoire de se faire surclasser et voyager en première quand il est devenu trader le succès a été presque immédiat et pour le moment enfin la chance a toujours été de son côté alors que dr john c'est un peu le cliché du bon élève exactement il a une formation d'ingénieur avec un doctorat en ingénierie électrique il travaille aujourd'hui dans une compagnie d'assurances il est plutôt grand mince habile dans le new-jersey donc pas loin de chez sony mais dans un appartement beaucoup plus petit et sobre dr john est en fait un grand calculateur un maître du temps sa vie est réglée comme du papier à musique consomme que ce dont il a besoin et il met un point d'honneur à toujours choisir le meilleur rapport qualité prix il prend son travail très au sérieux comme une maîtrise les statistiques et la programmation informatique docteur john est employé par une société d'assurances pour calculer et conseillers l'entreprise dans la gestion de ces risques financiers et du coup les réponses des deux personnages correspondent bien à leur personnalité selon dr john chaque lancer est indépendant les mille ans et précédents n'ont aucune incidence sur ce qui va se passer maintenant il est donc une chance sur deux pour que la pièce donc sur piles cette fois ci mepha tony n'est pas du tout d'accord selon lui ça sent le truc pas clean il est quasiment sûr que la pièce va encore tomber surface bah oui de son point de vue j'ai beau avoir précisé que la pièce n'était pas truqué il ne me connaît pas pour lui les huit lancers précédent qui tombe tout surface ça montre qu'une seule chose je suis un gros arnaqueurs et le jeu est forcément un truc et donc la pièce va probablement tomber encore surface bon alors entre l'intuitif anthony et le calculateur dr john qui a raison et qui a tort bon alors je me suis un peu trop de ce que dit l aide ma la réponse de taleb tient quand même en 300 pages mais en gros docteur john se trompent parce qu'ils attachent une trop grande importance aux modèles théoriquement pour une pièce non truquées ya effectivement une chance sur deux obtenir pile ou face les lancers précédents n'ont aucune importance cela dit un modèle fait nécessairement des hypothèses simplificatrices qui seront un jour violet et rendront le modèle il efficace par exemple on considère que les paramètres des différents lancé vont varier de façon aléatoire la pièce n'est jamais lancé à la même hauteur avec la même force et n'est jamais rattrapé au même niveau mais peut-être qu'avec beaucoup d'entraînement les paramètres ne sont pas si aléatoire que ça en fait quand on y réfléchit si on répète l'expérience à l'infini il est très improbable que la fréquence des piles soit exactement un demi d'ailleurs il ya des chercheurs qui ont testé les lancers de pièces et qui ont découvert qu'une pièce environ 51 % de chance de tomber sur le même côté que son côté original au moment du lancer et si tu t'entraînes et à contrôler le lancer de ta pièce battue pourrait peut-être arriver à faire en sorte que la pièce tombe deux fois sur trois surfaces ok donc du coup c'est vraiment fait tonique a raison et ben non massy si dr john à tort c'est forcément que c'est fade tonique a raison en fait ils ont tous les deux raison et tort fa tony se trompent parce qu'ils attachent trop d'importance aux huit lancers précédent il réagit au bruit plutôt qu'à la tendance s'il n'ya pas de tricherie que la pièce n'est pas truquée et que personne ne maîtrise des paramètres des lancers alors huit phases de suite c'est pas si improbable que ça est en fait une chance sur 256 pour que ça arrive huit lancers successifs c'est pas suffisant pour complètement disqualifié le modèle wi une chance sur 256 s'est pas beaucoup mais ça arrive à peu près tous les 256 cas alors bien sûr si je prenais une pièce à l'instant et que devant vos yeux et pour la première fois je répétais 8 face de suite alors là ça serait super étonnant mais il ne faut pas oublier le biais de sélection dont on a parlé la dernière fois il ya de bonnes chances pour qu'on soit interpellé par ces huit phases de suite précisément parce que ces huit faces de suite c'est un cas rare ok mais alors si j'avais eu 99 fois phase de suite au lieu de huit là ça aurait pas pu être le hasard ouais voilà là ça commence à faire beaucoup c'est à dire le cas que taleb décrit dans son bouquin le modèle qui suppose que le lancer parfaitement 50/50 nous dit que 99 face de suite bien que possible ne peut arriver qu'une fois tous les 6 34 10 puissance 29 essais ouais alors là le coût des puissances tu m'excuses des sables absolument rien dire pour moi tu prends toute la population de la planète 7 milliards d'individus tu les fais lancer des pièces à raison de 80 19 lancers toutes les dix secondes pendant 28 millions de milliards d'années une fois terminé tu regarde l'ensemble des essais et tu trouvera sûrement un seul essai pour lequel on aura obtenu 99 fois face à la suite à dakar à ce moment là tu t'en vas tu pas un tu dis juste qu'il ya super super pas beaucoup de chance on comprend par contre avec lui lancé seulement ya un doute en fait le débat entre faty tony dr john est l'un des grands problèmes récurrents en machine learning d'un côté na dr john qui fait de l'odeur fitting que l'on appelle aussi de l'asu d'interprétation et de l'autre on a fax tony qui fait de lover fitting ou de la surinterprétation en gros ou sous interprète quand on ne colle pas assez aux données est on sûr interprète quand on ne colle pas assez au modèle et c'est encore une fois le fameux juste milieu qui nous sommes en effet on parle du dilemme biais variance ce dilemme prend la forme de l'équation erreur au carry est égal à bien au carré plus varens a oui on va parler de cette équation la wii et pour bien la comprendre je vais devoir détailler donc accroche toi imaginons que l'on cherche à estimer la probabilité pékin a lancé tombe surface pour cela on va collecter un jeu de données d qui va typiquement correspondre aux résultats de huit lancers et on va ensuite utilisé ces données pour faire une estimation q2 des de la probabilité est une des ses notre estimation p c'est la vraie probabilité si on ne s'est pas trompé on devrait voir qu 2d et galp et oui du coup on peut mesurer la qualité de notre prédiction par le carré de l'erreur c'est à dire qu de des mois le tout au carré mais pour mesurer la qualité de notre prédiction il faut bien se rendre compte que les données d qui sont collectés sont aléatoires en général elles vont être assez représentative et nous permettre de bien apprendre mais parfois on peut avoir un échantillon étrange ce qui peut nous conduire à mal à prendre ah oui genre comme quand on a eu 8 face à la suite exactement le dilemme biais variance nous propose alors de mesurer la qualité de notre prédiction en prenant de la moyenne des carrés des erreurs c'est à dire l'espérance depuis 2d - p au carré ou cette espérance est prise quand des suit la loi de paix et alors là si du bien tout suivi c'est ce que tu as appelé le carré de l'erreur oui c'est ça et bien sûr dans l'idéal il faudrait que ce carré de l'erreur soit aussi petit que possible ok mais du coup est ce qu'on trouve le biais et la variance dans tout ça le dilemme biais variance permet d'identifier deux sources d'erreurs d'un côté on peut faire des erreurs parce que notre algorithme donne constamment des mauvaises prédictions quelles que soient les valeurs de d c'est ce que l'on appelle le biais de la prédiction et on le définit comme l'écart entre la moyenne des prédictions est la vraie valeur de paix comme cherché à estimer dans notre cas le biais donc l'espérance de q2 des moins la valeur de paix ok donc ça c'est le biais au carré dans ton équation oui et de l'autre côté on peut faire des erreurs parce que d'un jeu de donner à l'autre notre algorithme apprend tout et son contraire et du coup forcément pour au moins certains jeux de données d il fait des erreurs c'est ce que l'on appelle la variance de l'apprentissage il est égal à la variance de q2 des camps d essuie la loi imposée par la vraie probabilité paix et sas accroissons à cette grosse formule que voici qui est donc formellement de l'espérance du carré de l'écart à la moyenne donc là je suis chaud on retombe sur l'équation erreur car il ya le biais carré plus variance et on a deux sources d'erreurs le biais mon algues ont fait de la merde parce qu'il n'est pas assez précis la variance mont elgon fait de la merde parce que certains jeux de données sont bizarres et du coup on apprend mal exactement et ces deux sources d'erreurs sont parfaitement illustré par nos deux personnages le problème de dr jones et le biais et celui de fat tony c'est la variance est ce qu'on pourrait pas avoir un petit exemple numérique juste pour être sûr ok imaginons que je me suis entraîné toute ma vie si bien que maintenant j'arrive à lancer la pièce pour qu'elle tombe surface avec probabilité deux tiers ici aussi dr john va se planter dans sa prédiction oui et on peut quantifier à quel point il se plante on a vu que sa prédiction était toujours un demi quelles que soient les données observées ainsi pour dr john q est toujours égal à 1,2 me mais du coup le biais des dr john est égal à l'espérance de q - paix ou qu est égal à 1,2 me et paix est égale à deux tiers si vous fait un demi - deux tiers qui est égal à - 1 6e en revanche la prédiction de dr john ne souffre d'aucune variance puisque sa prédiction ne varie pas avec les données d du coup la variance de dr john est égal à zéro en utilisant maintenant le théorème bien variance on voit que l'erreur au carré de dr clown est égal à moins d'un sixième au carré + 0 ce qui nous fait un 36e et donc son erreur et la racine carrée 2-1 36e qui est égal à 1 6e autrement dit la prédiction de dr john sera typiquement une distance de 0,28 cent soixante-sept de la vraie valeur de pays et ça c'est mal pour le savoir on va le comparer à l'erreur de facto ni la prédiction de tony elle va dépendre des résultats des lancers supposons que je vous montre 8,2 me lancer alors le nombre des deux fois que la ps va tomber surface reste un nombre aléatoire mais si j'ai deux chances sur trois de tomber surface alors des as plus de chances d'être proche de 8 que 2 0 en fait des va suivre une loi binomiale de paramètres huit le nombre de lancers et deux tiers la probabilité de tomber surface autrement dit on à l'équation de la loi binomiale la probabilité que des gars là qu'a été gala cas parmi n p puissance qu'à 1 - p puissances ennemies cas si je remplace par des valeurs numériques ça me fait qu'à puissance 8 x 2 puissance qu'à diviser par trois patients suite bon ça fait une grosse équation nous on peut voir les valeurs numériques voilà un graphique qui reprend les probabilités de voir plusieurs fois face à paraître après huit lancés par exemple il ya 3,9 pour cent de chance de n'avoir que des faces mais seulement 0,015 % de chance de n'avoir que des piles en gros dés qu'on va avoir des données d qui vont illustrer des cars théoriquement rares facto n'y va avoir tendance à faire une mauvaise estimation de paix en effet pour formaliser tout ça supposons que fat stone y colle parfaitement aux données empiriques autrement dit supposons qu'ils prédisent que la probabilité de phase soit égal à la fréquence empirique des faces du coup la prédiction de file tony est qu 2d est égal à des / n l'avantagent de cela c'est qu'en moyenne fait toni va prédire espérances de q2 des qui est égal à l'espérance de dédit et par huit ça comme l'espérance d'une soi mais la somme des expériences ça nous fait parfois m / rennes qui est égal ap on dit que la prédiction de tony elles n'ont guère aisée puisque le biais de tony est égal à l'espérance de sa prédiction - la valeur de paix et ça c'est égal à zéro et ça c'est cool du coup ça montre que facto niemeier non non pas forcément parce que le problème de fat tony c'est la variance de sa prédiction 7 variance est égale à la variance 2d / l et ça après quelques calculs cela ne fait p x 1 monte / l quand on remplace n par huit et paix par deux tiers n'obtient alors variance de tony est égal à 2/9 / 8 et ça c'est égal à 1 36e du coup l'erreur de tony qui est égale à la racine carrée du bien au carré plus la variance c'est la racine carrée 2 0 + 1 sur 36 qui est égal à 1 6e me wade comme dr john cox j'ai fait exprès de prendre ces chiffres au final face tony et dr john font aussi bien l'un que l'autre ok j'ai rien compris aux calculs mais je pense comprendre le problème dr john est complètement rigide il veut voir que le modèle et du coup sabia son analyse d'un autre côté fatto ni il veut voir que les données donc qui peut se mettre après dire tout et n'importe quoi en fonction de ce qu'ils observent exactement et dans notre cas les deux problèmes sont aussi graves l'un que l'autre mais du coup est ce qu'on peut faire mieux que docteur john et facto ni week typiquement faudra quelque chose d'intermédiaire entre la rigidité du dr john et la surinterprétation de facto ni il faudra un estimateur à la fois légèrement biaisé et légèrement variant et ça c'est le cas par exemple de la loi de succession de la place là il y aurait beaucoup de choses à dire sur le sujet notamment parce qu'elle a des fondements assez bayésiens un bail et quoi à 6 pas le temps d'expliquer aujourd'hui bon mais sinon c'est toi de la place c'est quoi la loi de succession de la place dit alors de prédire q2 des est égale 1 des puces 1 / une puce de et l'erreur de la place sera alors de 0,37 ce qui est mieux que les 0 160 7 de dr john et fat sony mine de rien ça fait quand même 20% de mieux et ça peut faire d énormes différencie des milliards sont en jeu ah ouais c'est cool et du coup pourquoi on n'utilise pas tout le temps la loi de la place ba pour commencer parce que c'est pas la prédiction optimal et oui la prédiction optimale ces études est égal ap bah oui tout bêtement on a alors bière est égal à variance est égal à erreur est égal à zéro mais bien sûr toute la difficulté du dilemme bien variance c'est qu'on ne connaît pas et pire parce que l'on ne connaît pas paix y compris après coup il était impossible non seulement de prédire la performance d'une prédiction mais il est aussi très compliqué de juger la performance d'une prédiction y compris après coup mais alors du coup je suis plus sûr de rien a en fait c'est même pire encore mais accroche toi ça va être mais tu as le truc compliqué c'est que rien qu en invoquant le dilemme biais variance on est déjà en train d'introduire un biais de notre façon de penser puisque les dilemmes bien variance va typiquement présupposés qui lie à une variable paix à connaître qui sera une sorte de vérité fondamentale sauf que ce n'est pas clair que l'existence de cette vérité fondamentale soit vrai a il y aura tellement plus à dire mais je vais m'arrêter là pour aujourd'hui alors récapitulons le problème dont on vient de parler c'est celui de la généralisation à partir d'exemples qui est un problème classique non seulement en finance et en statistiques mais aussi en machine learning en particulier c'est un problème à la fois pour nous autres humains et pour les intelligences artificielles on a vu que les erreurs dues à la généralisation se décompose en deux types d'erreurs d'un côté le biais et de l'autre la variance le bien c'est lorsque notre modèle d'apprentissage est trop rigide et ne s'adaptent pas suffisamment aux données c'est ce qui arrive quand on fait trop confiance à certains modèles on appelle ça l'honneur fille team ou la soupe d'interprétation al'inverse la variance c'est lorsque l'on sort beaucoup trop du cadre des modèles et que l'on cherche trop à coller aux données observées c'est typiquement ce qui se passe quand on observe le cours de bourse toutes les 5 minutes et qu'on réagit assez moindre fluctuation alors qu'on a choisi une stratégie d'investissement sur le long terme on appelle ça lover phishing ou la surinterprétation le problème c'est que diminuer le biais conduit souvent augmenter la variance et vice versa faut donc trouver un juste milieu entre ces deux extrêmes tout en sachant que la mesure du billet et la variance implique la connaissance d'une loi paix qu'on cherche justement à prendre donc qu'on ne connaît pas et dont on n'est même pas sûr qu'elle existe bref analyser des données que ce soit pour une machine ou pour un humain c'est pas simple j'espère que vous avez aimé cette collaboration avec gilles de la chaîne eurêka si vous connaissez pas allez voir c'est absolument génial celui qui fait ce que j'adore avec les vidéos de gilles c'est que à chaque fois il précise très bien la limite des modèles qui considèrent et l'étendue de l'ignorance que ça sous entend généralement après une vidéo d'oreca on comprend beaucoup mieux comment les choses fonctionnent mais on comprend aussi et surtout beaucoup mieux ce que l'on ne peut pas comprendre étant donné l'état actuel des connaissances notamment en finance et en économie voilà je pense que ça réflexe excellent qui à oreca et que devra avoir peut-être plus de youtuber savoir précisé le fait qu' il ya plein de choses qu'on ne sait pas et insisté sur l'étendue de notre ignorance est en tout cas j'espère que cette vidéo vous a permis de sentir à quel point c'était compliqué d'avoir une réponse au final une question si simple car lens et de pièces et que c'est ouvert mais d'imaginer que en pratiquant finance tout est beaucoup plus compliquée encore dernière fois que j'avais proposé de participer à un sondage où j'avais eu pose exactement le problème de la pièce alors j'avais fait à la fois des statistiques sur google forme également sur youtube et voici les résultats c'est à peu près les mêmes dans les deux cas en gros 80% d'entre vous sont dr john sellar vous fait confiance encore en modèle il dit que la pièce est non seulement nous truqué mais également non biaisée au moment du lancer et donc que la probabilité d'un face reste 0.5 y en a aussi parmi vous qui sont plus fat tony c'est ce qu'ils ont à me tout à droite qui correspond à dire que la probité 1 face au 9e lancé est égal à 1 j'aurais tendance à dire que ces deux réponses 05 l'oim sont pas très bonnes parce que d'une certaine manière on s'attend à quelque chose qui est plutôt entre les deux en tout cas le dilemme biais variance nous pousse à penser quelque chose qui est entre les deux et y en a effectivement 7% parmi nous qui ont peut-être senti venir ce problème du dilemme biais variance et qui ont mis entre 0,5 et 1 jeudi on a aussi quelques uns parmi vos qui ont mis tout à gauche 0 1 0 je sais pas si c'est parce que vous avez mal lu les noms séjour a tendance à dire que ce qui est vraiment à gauche là c'est vraiment pas une réponse en soutien ça ne paraît pas très pertinent bon après entre 0,5 et 1 quelle est la bonne réponse alors là je crois vraiment disserter mais pendant des heures et des heures à écrire tout un livre sur le sujet c'est vraiment je pense une question fondamentale est absolument fascinante que de déterminer quelle est la probabilité qu'il faudrait assignés à ce 9e face dans cette suite de lancer il y aurait énormément de choses à dire notamment les eaux gerville réache alias paradoxe il écrit notamment ce livre de paradoxes renversant en probabilité dans lequel il parle notamment d'une publication de d'alembert c'est une vidéo qui a fait à ce sujet qui est d'une certaine manière je pense une meilleure réponse encore que la loi de succession de la place mais pour vous expliquer pourquoi il faudrait que je rentre dans les détails du mécanisme heureusement ça prendrait un peu pas mal de temps sinon la fin on a surtout parlé du biais de la surinterprétation et en particulier les vues composition bidouiller statistiques pour faire dire à peu près tout et n'importe quoi c'est ici que comme le roi des singes ça correspond aux proverbes motion qui est absolument fondamental qu'il faut retenir qui dit que si on torture les chiffres il vous avons ce que vous voulez il ya aussi cette fameuse citation attribuée à benjamin disraeli qui dit qu il existe trois types de mensonges les mensonges les mensonges maudit et les statistiques et en effet quand on parle de sacy qu'il faut faire vraiment très très gaffe surtout si lui un biais de sélection de la statistique en question et ça en pratique quand vous lisez une statistique est en 11e un journal ce que vous voulez ce sera forcément une statistique choisi par l'auteur de l'article et c'est souvent pour que ça étant le sens de son message adrien le x demande aussi du coup ça veut dire qu'il ne faut pas faire confiance aux statistiques en tout cas faut pas faire confiance aveuglément en tout cas aux statistiques qui vous sont rapportés par quelqu'un qui a un parti pris et qui a choisi cette statistique pour défendre son parti pris cependant cette méfiance envers les statistiques ne veut pas dire qu'il faut accepter les autres méthodes non statistique fait bien souvent quand on utilise autre chose que statistiques c'est encore plus facile d'avoir tout un argumentaire qui va défendre telle ou telle position en fait de façon plus générale ce qui est important de voir à travers le biais de la surinterprétation c'est que ce biais n'est pas du tout spécifique à l'analyse de données ou aux statistiques en tout cas avec des chiffres classique de façon plus générale ce biais de sur interprétations il intervient à tous moments qui font le gros problème des anecdotes c'est que lorsqu'on vous raconte l'anecdote elle soit ont été sélectionnés parmi tout un ensemble d'anecdotes imaginables pour pouvoir défendre une position plutôt qu'une autre le biais de surinterprétation correspondra à donner trop d'importance à cette anecdote alors que ces anecdotes s'explique généralement très bien par le hasard et le fait qu'il y ait un biais de sélection qui a sélectionné les cales plus étrange parmi toutes les anecdotes qui ont eu lieu j'insiste encore sur ça parce que je pense que ce biais de la surinterprétation c'est un énorme problème dont beaucoup d'analystes et malheureusement à l'école les très peu enseignée voir j'ai bien peur qu'à l'école bien souvent on favorise le la surinterprétation de beaucoup de choses et notamment je me souviens de pas mal de cours de français où j'avais l'impression qu'on faisait quand même dire pas mal de choses à des textes que ces textes ne voulait pas forcément dire j'ai l'impression qu'il ya quand même pas mal de travail de sur interprétations au moment de l'analyse de texte en tout cas en cours de français en tout cas c'est mon impression est à la limite c'est pas tant le prenne le problème c'est surtout que nous encourager à faire ce travail de sur interprétations sans jamais nous parler des dangers de la surinterprétation j'ai quand même pas mal l'impression qu'il ya pas mal de cours à l'école ou en fait on apprend à faire de la surinterprétation sans jamais nous signaler le danger de la surinterprétation ce qui pourrait amener du coup l'éducation à nous conduire à surinterpréter tout plein de choses et ça pourrait peut-être à être l'une des explications au fait que la croyances au paranormal soit en fait corrélée avec le niveau d'études sont les jo qui ont fait plus d'études croit plus au paranormal en tout cas c'est ce qu'affirme henry broc dans cette interview sur la tronche en biais du coup moi je serais vraiment d'avis qu'en cours de français notamment on étudie ce biais de surinterprétation par exemple en lisant des textes modernes par exemple des articles de journaux et on essayait de comprendre qu'elle était par exemple les intentions de l'auteur et quels sont les billets de surinterprétation qu'a pu faire un auteur d'un article de journal plutôt que d'être dans une certaine posture de l'admiration des auteurs de textes ça serait bien d'avoir un regard assez critique sur les auteurs des textes de façon assez générale je pense bon voilà je sens que je me tapais une vague de critiques de professeur de français mais bon je pense que c'est vraiment un débat à avoir parce que je pense que les conséquences de surinterprétation sont absolument dramatiques aujourd'hui le semble qu'il s'agit d'une des principales causes cette bipolarisation qu'on peut avoir immergé sûrement sur le web avec les fils turbulents et tout ça est malheureusement il ya très très peu d'éducation aux dangers de la surinterprétation plutôt aux gones de shia sbaï 42 et rémy père pour remarquer que le biais de sélection des données qui vont être ensuite analysées par les algorithmes est un énorme problème de société aujourd'hui et d'ailleurs j'ai envie de dire que c'est vraiment pas spécifique aux algorithmes typiquement si les données sont biaisées et objets observe une certaine différence entre une certaine classe d'individus une autre classe d'individus dans les performances de tel ou tel truc on pourra avoir un algorithme qui apprend du coup quelque chose qu'on pourrait qualifier de racisme tout cas un organe algorithme qui distingue les gens en fonction par exemple de leur apparence physique et bien cette problématique est vraiment devenu un problème de recherche en tant que tel de savoir qu'est ce qu'on veut vraiment que les algorithmes face à ce qu'on veut des alcools qui ignorent ce genre de bien vous voyez que ces questions en fait sont très très très publiées elles sont en fait pas du tout spécifique aux machines comme apparemment gilles dowek semble avoir dit dans une conférence les humains à travers notamment le biais de sur interprétations sont aussi victimes de ce genre de guerre voire plus encore que les machines sauf que on a tendance à plus tolérer le racisme par les humains que le racisme par les machines bref comme le dit rémi père est saisie d'une grande question philosophique et poétique à laquelle vous n'aurez pas encore de réponse satisfaisante tout cas pas de réponse qui fasse consensus rafael cruz co demande s'il s'agissait vraiment d'une question dover fitting la vidéo précédente parce que souvent lover fitting on la prend en tout cas dans les cours de machine learning comme étant dans le cadre typiquement de l'apprentissage superviser ou lorsqu'on cherche à trop à coller aux données on a du coup une fonction qui se généralise mal à dézoner qu'on n'a pas encore observé on en reparlera d'ailleurs la semaine prochaine en effet su permis d'extraire la définition de l'odeur fitting de ce cadre formel visuel on voit en quoi parce que je pense que le problème de l'eau d'heure fitting et de la surinterprétation est un problème beaucoup plus générale que ce simple cadre de l'apprentissage superviser il me semble que on peut vraiment dire que le problème de façon très générale c'est d'interpréter des trucs des fluctuations statistiques comme ayant un sens qui doit être expliqué et être exploitée pour faire des prédictions et le truc c'est que pour pouvoir expliquer ces fluctuations statistiques il faut à ce moment là à faire intervenir des modèles beaucoup plus sophistiqué c'est sont généralement ces règles trop sophistiqué qui se généralise mal et des données n'ont observé et si on considère que leur footing c'est ça c'est considérer des modèles trop sophistiqué pour l'expliquer en fait ce qui n'est que du hasard eh bien on est vraiment dans le cadre de loire fitting notamment dans le cas de spéculation puisque à ce moment là on a des milliers de jeux de données donc d'élite et des dizaines de milliers de données mais le nombre de corrélation qu'on va étudier est en fait très très très grande de l'ordre du million du coup en fait on a beaucoup plus de paramètres d'une certaine manière que l'on utilise que de données et de façon très générale quand on a beaucoup plus de paramètres que de donner on risque fort d'utiliser ces paramètres supplémentaires pour pouvoir interpréter des trucs qui en fait ne sont que du hasard la grosse difficulté de lover fitting notamment dans le cas de spiros connection c'est que lorsqu'on ne donne que la corrélation qui est significative on a l'impression qu'on n'a pas considéré toutes les corrélations qui ont été étudiées par le modèle ces mêmes problèmes en fait qu'on a dans le cadre d'apprentissage superviser c'est le fait d'avoir choisi une règle qui semble bien expliqué et donnait alors qu'en fait il y avait beaucoup de règles qui expliquait également assez bien les données et en particulier si on changeait un tout petit peu les données alors on sélectionnerait d'autres modèles ou d'autres corrélation dans le cas d'espèce corrélation et du coup on augmenterait énormément la variance de notre apprentissage et de nos prédictions bref tout ça pour dire que je pense que le problème de la surinterprétation c'est absolument pas limité à un cadre formel on a l'habitude d'étudier en machine learning c'est vraiment un problème beaucoup plus fondamentale que cela et qu'il faut absolument que l'on soit conscient de ce problème notamment dans la vie courante où on exposer a énormément d'informations qui ont été sélectionnés à partir de données très bruitée en particulier la conséquence très importante à avoir en tête de tout ça c'est la conclusion qui est donnée par linux citrix à savoir le fait que à cause du biais de la surinterprétation et internes ce biais de sélection de données qui ont l'air significative une fois qu'on les a sélectionnés qu'on les a sortis du coup du contexte d'apprentissage ou de façon plus générale c'est le fait que deux personnes qui sont en fait quasiment d'accord initialement mais qui vont légèrement penché d'un côté légèrement de l'autre vont finir par être exposé assez rapidement des données qui vont uniquement aller dans leur sens et du coup vont finir par diverger du coup deux personnes qui sont parfaitement intelligente parfaitement rationnel tout ce que vous voulez peuvent finir si elles sont victimes du biais de la surinterprétation par avoir des avis complètement divergents je pense que ce phénomène est absolument crucial à comprendre dans le monde d'aujourd'hui j'espère qu'ils avaient mais cette vidéo la prochaine fois on va continuer à parler de lover fitting et on va notamment se poser la question de comment lutter optimalement contre cette horreur fitting contre launder fitting également comment essayer de trouver le fitting optimale comme on l'appelle tout vous invite à y réfléchir de vous-même d'ici là si vous avez aimé cet épisode spécial de l'ikea le commentaire de partage et pensez à vous abonner pour autant les futurs épisodes merci au type erp l'ordre et j'espère que vous serez là la prochaine fois tous ces problèmes viennent complexifier l'argumentation de ricardo et s'il est certain qu'un modèle économique doit simplifier les choses tous les économistes ne sont pas d'accord sur les variables que l'on peut considérer comme négligeable et qui peuvent effectivement être retirés des équations