De nos jours, avec les technologies modernes il est tentant de croire que les machines finiront par savoir et savoir faire tout ce que l'humain sait et sait faire. on l'a vu dans l'épisode précédent, les machines nous surpassent dans de plus en plus de domaines. et pourtant la plupart d'entre nous persistons à penser que l'intelligence humaine est une spécificité humaine. Et pour justifier nos propos, on a tendance à ressortir plus ou moins toujours les mêmes arguments. Donc pour aujourd'hui je vous propose d'étudier cinq arguments classiques qui cherchent à prouver la place privilégiée de l'intelligence humaine dans l'univers. Argument 1:  les machines n'auront jamais de conscience. J'ai une conscience dans le sens où j'ai une expérience subjective de ce que je vis et c'est dur d'imaginer qu'une machine pourra un jour posséder une telle conscience. Oh la la y aurait beaucoup de choses à dire sur le sujet. Euh... Thibault qu'est ce que tu fais là ? Bah tu parles de philosophie donc j'arrive. Génial. Donc dis moi quel est le problème avec l'argument de la conscience. D'abord faudrait distinguer si on parle de conscience phénoménale ou de conscience d'accès. Ah oui, t’en a parlé dans une de ces vidéos, et si j'ai bien suivi, la conscience phénoménale, c'est l'expérience subjective de ce que je vis, et de sentir la douleur quand je me pince la joue. oui. Et le problème avec la conscience phénoménal, c'est que par définition il semble qu'elle ne puisse pas être étudiée objectivement mais seulement subjectivement. Les seules douleurs, les seules expériences conscientes que je puisse connaître, ce sont... les miennes. Pourtant tu pourrais imaginer mes expériences conscientes, non ? Si je me cogne avec une raquette tu dois pouvoir imaginer ma douleur. Tout ce que je peux faire, c'est imaginer ce que je ressentirai à ta place. Autrement dit, je ne fais qu'imaginer ma douleur dans ta situation. Mais c'est peut-être correct : on peut supposer que nos consciences phénoménales sont similaires. En effet, mais ce n'est qu'un postulat absolument invérifiable. Ce postulat semble plutôt légitime dans la mesure où on est proches biologiquement, et on peut supposer que c'est notre biologie qui produit notre conscience, mais ça ne doit pas nous faire oublier que, en réalité, je n'ai pas plus accès à ta conscience phénoménale qu'à la conscience phénoménale d'une chauve-souris ou de mon monstre vert. Ou d'une machine. Donc, si je comprends bien, l'argument : "les machines n'auront jamais de conscience phénoménale", c'est pas très pertinent puisque je pourrais tout aussi dire que toi, tu n'as pas de conscience phénoménale. En effet, je m'avoue bien incapable de te le prouver. Et donc il n'y a pas lieu d'en attendre davantage des machines : bien sûr qu'elles ne pourront pas plus que moi te prouver qu'elles ont une conscience phénoménale. Ok, mais qu'en est-il de l'autre sens de la conscience : la conscience d'accès ? La notion de conscience d'accès est moins mystérieuse. Pour savoir si le contenu d'une perception, par exemple, est conscient au sens de la conscience d'accès, il suffit que le sujet soit capable de rapporter ce contenu, en le décrivant, par exemple. C'est aussi simple que ça. Et quand on étudie la cognition, on se rend compte que beaucoup, beaucoup, de contenus mentaux, bien qu'étant traités dans le cerveau, passent sous le radar de la conscience d'accès. En effet, l'intelligence humaine analyse toutes les données sensorielles en temps réel, c'est à dire des gigaoctets de données par seconde et beaucoup, beaucoup, de ces données doivent être filtrées et immédiatement supprimées pour ne pas pourrir nos disques durs de données massives sans intérêt. C'est une façon de décrire ce qui se passe, en effet. La conscience d'accès, en gros, c'est une capacité à surveiller, sélectionner, mettre en commun et utiliser de façon contrôlée les contenus mentaux issus des différents systèmes qui tournent dans notre cerveau. Et en cela c'est une fonction cognitive, une fonction cognitive qui se laisse étudier objectivement et qu'il serait tout à fait envisageable d'implémenter dans une machine, ça n'a rien d'inimaginable. En fait la conscience d'accès semble même indispensable à l'intelligence, tout comme l'inconscience d'accès, c'est à dire le traitement d'informations rapidement rendu inaccessible, semble indispensable à l'intelligence humaine. Argument 2 : Les machines n'auront jamais de volonté propre. Programmer, c'est donner des instructions. Or, les machines doivent être programmées. Du coup, les machines ne peuvent que suivre des instructions. Mais es-tu bien sûr toi-même de ne pas suivre les instructions d'un programme dont tu ignorerais tout ? Si j'agis de telle et telle façon dans telle et telle circonstances, on pourrait croire que c'est parce que mon système nerveux était programmé de telle sorte que, placé dans ces circonstances là, il produise ce comportement. Alors qu'imaginer le contraire, ça revient à postuler que nous seuls disposons d'une sorte de liberté magique qui nous permettrait de ne pas être soumis aux mêmes lois que le reste de l'univers. Ok, mais je n'ai pas vraiment l'impression de suivre un programme, moi ! Quand tu fermes un oeil, tu n'as pas l'impression qu'il y a une tache aveugle au milieu de ton champ visuel, et pourtant c'est le cas. Mais tu es programmé pour corriger automatiquement ce défaut de perception. Ah ouais, je vois. Mais les instructions de ce programme, tu n'y a pas accès et tu ne peux pas non plus le contrôler, ça relève de l'inconscient. Et c'est tout sauf un défaut : quand ma vessie est sur le point de déborder, je suis bien content d'avoir un programme qui me le signale, et me dit d'aller la vider. D'autre part si tu as l'impression de ne pas suivre un programme, c'est peut-être aussi parce que personne n'a écrit les instructions tu suis. Nous n'avons pas été programmés intentionnellement. Notre programme s'est écrit au fil de l'évolution et il est programmé pour se modifier lui-même au fil du temps Si je suis programmé à sentir l'envie de vider ma vessie quand celle-ci se remplit, ce n'est pas parce qu'un programmeur l'a encodé dans mon programme. C'est parce que la sélection naturelle a sélectionné les individus dont les programmes possédaient cette instruction. Bref, nous n'avons pas le même rapport avec la programmation des machines parce que, au départ, c'est nous qui les programmons intentionnellement, et nous sommes conscients des programmes qu'elles suivent. Alors, en effet pendant longtemps c'était comme ça que les ordinateurs étaient programmés. Mais avec l'avènement du machine learning et des algorithmes génétiques qui simulent une évolution darwinienne, les machines d'aujourd'hui sont de moins en moins le produit des intentions conscientes des programmeurs. Et si l'on implémentait une méta-cognition dans une machine pour simuler une conscience d'accès, il est probable que celle-ci n'aurait pas accès à toute sa cognition, et donc pourrait se sentir aussi "peu programmée" que nous. Pire encore, certains programmes auto-générés comme le deep learning sont aujourd'hui si complexes que leur contenu échappe très largement à leurs développeurs. Plus troublant encore : de nos jours on peut se demander si c'est vraiment nous qui disons aux machines que faire, ou si ce ne sont pas déjà les machines qui nous disent que faire, notamment via les systèmes de recommandations comme youtube ou netflix. Argument 3 : Les machines ne font pas d'erreurs. Errare humanum est ? Pas forcément. Errare etiam makina est. Hmmm t'es sûr de ton latin ? Oh, ok, excuse-moi Monsieur ec cetera ec cetera ec cetera Je suis inexcusable... Si nous ne faisons que suivre des programmes l'erreur peut tout bêtement venir des programmes que nous suivons. Je commets une erreur lorsque je vise un objectif mais la décision que je prends tend à plutôt m'éloigner de la réalisation de cet objectif. Par exemple, si je joue au go, mon but est d'avoir un maximum de territoires.Si je joue un coup faible, un coup qui me fait perdre du territoire, eh bien je commets une erreur. Et on peut transposer ça pour des machines. Un programme de jeu de go a finalement le même objectif que moi, gagner la partie en ayant plus de territoire que son adversaire. Et il va chercher à évaluer les différents coups possibles en vue d'atteindre cet objectif. Certes, aujourd'hui on peut avoir l'impression qu' AlphaGo, qui a battu les meilleurs joueurs humains du monde, ne commet pas d'erreurs, mais avant cela les programmes de go était assez nuls, et ils jouaient souvent des coups faibles, et pourtant ils avaient le même objectif de gagner la partie, ce qui revient à dire qu'ils commettaient des erreurs, finalement. On pourra objecter que ce n'étaient pas des erreurs, puisqu'ils ne faisaient que suivre des instructions. Mais dans ce cas, en quoi fais-je, moi, des erreurs lorsque je joue un mauvais coup au go, puisque de même on pourrait dire que c'est le coup que mon programme cérébral de jeu de go me déterminait à jouer dans ces circonstances. Bref, il est difficile de donner un sens à l'idée d'erreur qui ne s'applique qu'aux êtres humains même pour un cas aussi simple que : une erreur au jeu de go. Alors, parfois on parle d'erreur quand on est censé suivre un programme et qu'on échoue à ce faire. Et en pratique, ça, ça arrive aussi aux machines. Eh oui, les machines sont des objets physiques et du coup il peut avoir des perturbations physiques, des signaux par exemple qui vont d'un microprocesseur à l'autre. En fait, il y a même tout un champ de recherche en informatique qui s'appelle la tolérance aux fautes et qui devient de plus en plus important au fur et à mesure que nos systèmes informatiques deviennent de plus en plus complexes et aussi de plus en plus distribués à travers le monde, ce qui augmente le risque de perturbation des signaux. Argument 4 : Les machines manquent de créativité. C'est une idée assez répandue. Quand les machines auront achevé de prendre tous les vulgaires jobs mécaniques, nous, brillants êtres humains, pourrons enfin nous consacrer pleinement aux travaux créatifs. Ainsi, selon Etienne Klein, Albert Einstein aura écrit "Aucune méthode inductive ne peut conduire aux concepts fondamentaux de la physique, l'incapacité à le comprendre est la plus grave erreur philosophique de nombreux penseurs du XIXe siècle On a tendance à penser que des actes créatifs comme la peinture, la musique ou la poésie, sont ceux qui font la spécificité de l'humain. Sauf que des algorithmes sont tout à fait capables de produire des oeuvres qu'on pourrait tout à fait juger intéressantes, pourvu qu'on ignore qu'elles ont été créées par des algorithmes. Il suffit de faire un tour sur DeepArt ou sur DeepDream Generator pour s'en convaincre. Je vous renvoie vers les nombreux autres exemples dont on a parlé dans l'épisode 1. En fait, générer des nouveaux fichiers jpg, mp3 ou txt, pour une machine, c'est super facile. Et en plus elle est beaucoup plus productive que nous. En fait, ce qu'il manque aujourd'hui, c'est pas tant la créativité qu'une fonction d'évaluations esthétique qui lui permettrait de sélectionner les œuvres intéressantes dans son immense production, et une capacité à produire un discours expliquant son oeuvre... à se prendre pour un artiste pour ainsi dire. Oui parce que, au final, la créativité, ce n'est qu'une façon de sélectionner un objet parmi un ensemble très très très grand. Et dès aujourd'hui il existe bel et bien des façons, bien qu'imprécises, de juger approximativement de la qualité d'une oeuvre artistique. Et ce qui est vrai des arts est vrai des maths et de la physique aussi. D'ailleurs, les machines créent déjà tout plein de nouvelles maths et même de nouvelles preuves mathématiques, notamment via le logiciel Coq, et je vous renvoie vers les épisodes sur l'infini pour en savoir plus. Argument 5 : L'incomplétude de Gödel. Enfin, un dernier argument récurrent est celui avancé par le mathématicien Roger Penrose. Cet argument repose sur le théorème d'incomplétude de Gödel, et le fait que nous autres humains avons démontré l'existence de théorèmes vrais, mais qui n'ont pas de preuve. Or un ordinateur purement logique ne saura pas démontrer la vérité de ce théorème. Du coup, nous saurons toujours quelque chose qu'une machine purement logique ne saura jamais. Le problème avec ce raisonnement, c'est qu'il repose sur un contresens ou en tout cas une confusion sur la notion de démontrabilité. En particulier la démontrabilité d'un théorème n'est pas une notion absolue. Elle dépend toujours de l'ensemble des axiomes et des règles d'inférence que l'on accepte dans notre théorie mathématique. Et en gros, tout théorème indémontrable dans une théorie le sera dans une autre théorie. En fait, ce qu'a montré Gödel en gros, c'est que pour tout ensemble d'axiomes et de règles d'inférence qui permettent de construire au moins l'arithmétique on peut construire une formule G telle qu'on ne peut démontrer ni G, ni sa négation à partir de cet ensemble d'axiomes et de règles d'inférence. Voilà tout. C'est moins sexy, mais c'est aussi plus exact. Donc, si on programme une IA à faire de l'arithmétique, c'est-à-dire en gros, on la programme à déduire de façon mécanique des théorèmes à partir des axiomes de l'arithmétique. Cette machine en effet ne pourra jamais prouver le théorème d'incomplétude de Gödel, pour la simple raison que cette machine ne peut prouver que des théorèmes d'arithmétique, or le théorème d'incomplétude de Gödel n'est pas un théorème d'arithmétique, mais un théorème sur l'arithmétique. Et ce théorème n'est pas démontré dans l'arithmétique, mais dans la théorie qui étudie la théorie arithmétique, ce qu'on appelle du coup une métathéorie. Et si vous voulez formaliser complètement la démonstration de Gödel, il faudrait axiomatiser cette métathéorie dans une métamétathéorie et cetera... ET cetera. Pour plus de détails sur tout ça, je vous renvoie vers les épisodes 17 et 18 de la série sur l'infini. Si l'on restreint les IA dans le domaine mathématiques et à être des machines à produire des théorèmes à partir d'un ensemble d'axiomes et de règles d'inférence, l'objection serait pertinente. Mais on voit mal ce qui empêcherait de programmer une IA étudiant la métaarithmétique ou de façon plus générale les relations entre langage et métalangage. Bref, quand on étudie la logique on l'étudie souvent depuis l'extérieur et c'est pour ça que l'on arrive à conclure des choses comme ce que Gödel a conclu. Sauf qu'une machine peut aussi très bien faire ça. Alors, il reste une objection plus subtile qui s'appuie sur le théorème d'indécidabilité de Turing. Ce théorème dit qu'il existe des problèmes qu'aucune machine ne saura résoudre comme le problème de l'arrêt dont parle Passe-science. Alors oui une machine ne saura pas résoudre ce problème. Mais il est alors bien présomptueux de penser qu'un humain y arrivera et que la réponse de l'humain sera plus fiable que celle d'une machine. Bref, les arguments contre les capacités des machines à atteindre et à dépasser l'intelligence humaine sont en fait loin d'être solides. Alors, je comprends que cette conclusion ne vous plaise pas, puisqu'elle remet en cause notre place privilégiée dans le cosmos, et la morale des hooligans nous pousse à défendre les nôtres. Notre humanocentrisme a du mal à admettre que l'intelligence humaine ne soit peut-être pas si spéciale que ça. Alors que force est de reconnaître que quand il s'agit d'effectuer de longues divisions, les machines sont déjà bien plus intelligentes, ou du moins bien plus capable que nous autres humains. Notre humanocentrisme tend aussi à nous faire croire que le niveau humain d'intelligence représente une sorte de borne que l'intelligence artificielle peut tenter d'approcher certes, mais qu'elle ne dépassera pas vraiment. Sauf que ça n'est très probablement pas le cas. Le fameux match d'échecs Deep Blue contre Kasparov dans les années 90 a pu donner cette vision des choses d'un jeu quasi égal entre l'intelligence humaine et l'intelligence artificielle. Mais cette situation est assez exceptionnelle, et surtout de courte durée. Quelques années plus tard, les IA d'échec étaient déjà super intelligentes. Pareil pour le go. Aujourd'hui, AlphaGo, qui avait fait la une des journaux en 2016 est devenu un joueur de go moyen voire mauvais quand on compare à d'autres intelligences artificielles comme AlphaGo Zéro. Bref, si on arrive à produire une IA générale, il est difficile de croire qu'elle s'élèvera juste au niveau de l'intelligence humaine. Le jour où elle l'atteindra sera probablement la veille du jour où elle le dépassera d'aussi loin qu'AlphaGo Zéro dépasse tous les joueurs humains au jeu de go. Et c'est ce qui rend cette entreprise si vertigineuse. D'où notamment la crainte vis-à-vis d'une possible super intelligence. Néanmoins, même si on accepte le fait que l'intelligence n'est pas une spécificité humaine, il n'en reste pas moins qu'aujourd'hui en tout cas, produire une intelligence humaine dans une machine, ça reste bien difficile. Et ça, on en reparle la semaine prochaine La dernière fois, on a parlé des humains contre les machines, et on a vu que les machines et sont en train de nous surpasser dans de plus en plus de domaines et j'avais dit notamment que les machines sont déjà capables de faire beaucoup plus d'opérations par seconde par exemple cerveau humain, et Freak fait la remarque qu'en fait notre cerveau est capable de faire en fait beaucoup d'opérations inconscientes à chaque instant. Les capacités inconscientes du cerveau humain c'est vraiment un truc en fait incroyable qui dépasse très largement ce qu'on sait faire aujourd'hui avec des machines mais le multitasking en particulier je pense que c'est un truc que les ordinateurs font beaucoup beaucoup beaucoup mieux que nous. Quand on a notre téléphone ou notre ordinateur il y a tellement de calculs qui se passent derrière en background sans qu'on sache vraiment ce qui se passe et je parle même pas des Data Centers de Google qui traitent des milliards et des milliards d'opérations à chaque seconde, donc c'est vraiment pas comparable. Je pense qu'au niveau du multitasking, y a vraiment pas photo, les machines sont beaucoup beaucoup plus performante que le cerveau humain. Patrick Pichot fait la remarque que, certes les machines font des trucs mieux que nous, mais elles consomment aussi plus d'énergie, notamment il donne l'exemple d'AlphaGo qui consomme beaucoup plus d'énergie que le cerveau humain, ça c'est vrai, mais c'est un petit peu trompeur comme exemple puisque AlphaGo, on a mis toute notre puissance de calcul pour qu'il soit vraiment très très fort. La plupart des tâches effectuées par les machines sont en fait sans doute beaucoup plus efficaces que si elles étaient faites par le cerveau humain, je pense notamment à tout ce qui est gestion de travail administratif ou effectuer des longs calculs comptables par exemple des longues additions, ça pour les machines c'est juste quelques bits d'opérations donc ça va très très vite alors qu'un humain qui ferait ça, il faut compter toutes ses heures de travail et aussi toute la nourriture qu'il mange pour maintenir notamment son cerveau actif mais aussi tout son corps. À ce jeu là, je pense que les machines sont en fait bien plus efficace que l'humain. En fait, comme le fait remarquer Orion3227, je pense que ce dont les machines nous font vraiment prendre conscience, c'est à quel point en fait on n'est vraiment pas si exceptionnels, et que dans beaucoup de tâches que l'on fait, on commet beaucoup d'erreurs, on n'est pas très rapides, et finalement beaucoup de jobs humains sont loin d'être des truc exceptionnels. La dernière fois, je vous avais donné un exemple de Google qui était capable d'améliorer la résolution d'images très pixélisées et Jason Plawinski nous fait la remarque qu'en fait le travail de Google, qui date de mars 2017 pourtant, est en fait déjà obsolète. Il est devenu obsolète dès mai 2017 puisqu'en mai 2017, un truc basé sur des Generative Adversarial Networks (GANS), on en reparlera de tout ça, ont atteint des compétences absolument incroyables dans cette faculté à affiner la résolution des images pourtant très pixélisées et je pense surtout que ça montre à quel point ça va incroyablement vite dans ce domaine. Il y a énormément d'innovations, de nouveaux résultats qui apparaissent vraiment tous les mois, c'est vraiment un domaine complètement fou, et quand on se rend compte de la vitesse du progrès en intelligence artificielle ces mois ci qui est beaucoup plus grand que il y a un an pendant un mois et ben on commence à se dire que peut-être que dans un an ça va continuer à accélérer exponentiellement, et du coup c'est très très très difficile de prévoir l'état de l'IA dans un an ou deux. Et a fortiori encore plus dans 5 ou 10 ans. Enfin Romain Thibaud et Thibault Neveu ne sont pas d'accord avec mon osef sur la sémantique entre IA et machine learning, et il y a une bonne raison à cela, c'est que en fait historiquement l'intelligence artificielle incluait des trucs qui était pas du learning qui n'était pas de l'apprentissage des machines c'était plus des algorithmes. Mais en tout cas il y avait un sous-domaine de l'informatique qui était l'intelligence artificielle, qui développait ses propres algorithmes. Sauf que aujourd'hui ces techniques elles sont pas du tout à la pointe de ce qui se fait en intelligence artificielle et puis surtout, l'histoire, j'ai envie de dire osef au bout d'un moment il y a une époque où on pensait que pi était un nombre rationnel, je veux dire, l'état des connaissances évolue, et si on veut vraiment revenir aux origines intelligence artificielle, notamment à l'article de 1950 d'Alan Turing, eh bien on voit que dès cet articles de 1950, Turing parle déjà de machine learning et il explique très bien pourquoi le machine learning doit être une composante essentielle à tout algorithme intelligent. Et on reviendra d'ailleurs longuement sur cet article de Turing dans les épisodes à venir. J'espère que vous avez aimé cet épisode, en fait cet épisode est le premier d'une série de cinq épisodes où on va disséquer l'article de 1950 d'Alan Turing parce que cet article est juste merveilleux. La prochaine fois en particulier on va parler du test de Turing et je vais essayer de vous convaincre que l'idée de ce test est absolument génialissime, et semble vraiment correspondre à un test d'intelligence. Si vous avez aimé cet épisode, pensez à le liker, à le commenter, à le partager et pensez à vous abonner pour ne pas manquer les futurs épisodes. Merci au tippers pour leurs dons, et j'espère que vous serez là la prochaine fois. Si on n'arrive vraiment à créer une IA forte, son intelligence, ça va pas être l'intelligence d'un être humain il n'y a pas de raison c'est un petit peu comme si on imaginait : si on arrive à construire des objets qui volent, ça va voler aussi vite qu'un oiseau. En fait non si on arrive à construire des objets qui volent, ça va voler beaucoup beaucoup plus vite qu'un oiseau et c'est un petit peu la même chose avec une intelligence. Si on arrive à créer des objets qui vraiment sont intelligents au moins aussi intelligent que nous, ça va pas s'arrêter là. Il y a une possibilité de créer une intelligence vraiment vraiment très supérieure et le problème c'est que on peut concevoir des objets qui volent plus vite que des oiseaux, mais concevoir une intelligence qui est plus intelligente que l'intelligence avec laquelle on essaye de la concevoir, c'est très très compliqué. C'est pour ça que la super intelligent pose un problème qui est très particulier, qui est de dire : comment faire pour penser avec notre intelligence des êtres qui ont, qui auraient une intelligence extraordinairement supérieure. C'est un petit peu comme si des chimpanzés ou des grenouilles essayaient de réfléchir à ce que feraient des êtres humains...