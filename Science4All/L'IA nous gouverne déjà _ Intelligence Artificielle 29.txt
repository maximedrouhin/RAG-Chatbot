en 2013 une collaboration de chercheurs de lucie san diego de cornell et de facebook publie les résultats stupéfiants en modifiant légèrement l'algorithme de newsfeed de facebook ils ont affecté l'humeur d'une centaine de milliers d'individus jusque là on a parlé du problème de la morale d il ya de manière assez abstraite et vous avez peut-être eu l'impression qu'il s'agissait d'un problème pour les futures générations et bien aujourd'hui et dans les vidéos à venir on va voir que non le problème de la morale désir est un problème urgent qui a des conséquences majeures dès aujourd'hui en fait je vais même essayer de vous convaincre que ça fait déjà plusieurs années que l'entité la plus puissante du monde est unir alors ça peut paraître assez grandiloquent comme l'affirmation qu'est ce que peut bien signifier l'entité la plus puissante du monde eh bien je ne prétends pas qu'il s'agisse d'un concept rigoureux mais intuitivement une entité va avoir beaucoup de pouvoir si un petit changement dans son comportement a rapidement des conséquences très différentes et ça c'est crucial pour un conséquentialiste pour rappel le conséquentialiste mme est une philosophie morale qui considère que les actions moralement bonne sont celles qui conduisent à des conséquences désirable plus encore si une action à conduire une conséquence très désirable alors que toutes les actions alternatives conduisent à de très mauvaises conséquences alors effectuer l'action à sera un énorme devoir moral même si l'action a et coûteuse par ailleurs on peut rendre cette idée un peu plus formel imaginons que nous disposions d'une certaine ressources erp qui pourrait être le travail que l'on est capable de fournir ou la dépense énergétique de notre solution technologique ou le budget qu'on est prêt à dépenser supposons que plus on dépense de ressources r plus les conséquences morales sont désirables sauf que dépenser la ressource a aussi un coût individuel typiquement un travail et ça me fatigue et parfois j'ai juste envie de dormir dès lors on peut quantifier le devoir moral du conséquentialiste en regardant comment la dépense de la ressource r affecte les conséquences morales versus comment cette dépense additionnelle avec le coût individuel en maths on parlerait de la dérive et des conséquences par les ressources versus l'utilité marginale de la ressource lorsque la première dérivés est bien plus grande que la seconde en valeur absolue il s'agira alors d'un devoir moral important que de dépenser cette ressource et c'est pour ça que monsieur fille aime bien introduire l'idée d'un bout pour mettre en exergue nos devoirs moraux si l'effort ne consiste qu'à appuyer sur un bouton tout coût individuel disparaît alors et on est alors confronté à un dilemme purement moral et je vois envoie d'ailleurs versé nombreuses excellentes vidéo pour plus de détails ce type de raisonnement permet également de mieux prioriser les batailles moral sachant que nos ressources erp sont limitées selon le conséquentialiste mme il nous faut optimiser la gestion de nos ressources imaginons ainsi deux causes c1 et c2 et supposons qu'on dispose d'une unité de ressources additionnelles à investir pour savoir s'il vaut mieux investir dans ses seins ou ces deux il s'agit alors de comparer l'impact d'une unité de ressources sur la qos et 1 et celle sur la cause ces deux là où l'impact est plus important elle là où il faudra investir l'unité de ressources en question qui plus est selon le conséquentialiste il sera une faute morale que de l'investir mauvais endroit tout ceci peut sembler assez technique il peut sembler difficile d'arriver à des réponse univoque oui comme on en a déjà parlé avec monsieur fille être un conséquentialiste morale c'est très difficile ne serait ce parce qu'il faut être capable d'estimer les conséquences de nos actions mais comme le dirait john key mieux vaut une réponse approximative à la bonne question qu'une réponse exacte à la mauvaise question en particulier pour un conséquentialiste il s'agira d'un devoir moral préalable que de déterminer quelles sont les actions qui pour une unité de ressources données auront le plus d'impact bénéfique c'est d'ailleurs cette ligne qui a suivi le mouvement effective altruisme ou l'association guy noël qui cherche notamment à quantifier la bonne utilisation des dons par différentes charité j'en profite aussi pour vivement recommandé les excellents podcast anglophone de julia ghallef ou 2 et iphone os qui sont dans cet état d'esprit malheureusement pour les conséquences ya liste en pratique dans les débats moraux ce genre de calcul délicat et souvent très secondaire pouvoir inexistant et on a tendance à se contenter de confrontation de principes déontologiques bref pour un conséquentialiste si une idée a beaucoup de pouvoir c'est à dire si elle peut provoquer beaucoup de bien avec peu d'efforts alors il s'agira pour elle d'un devoir moral important que de faire cet effort est l inverse si on sait qu'une entité a beaucoup de pouvoirs mais n'effectuent pas cet effort alors il s'agira d'une priorité morale que d'encourager cette et à faire cet effort comme le dirait l'oncle de spider man de grand pouvoir implique de grandes responsabilités [Musique] alors ça c'est précisément le cas de ziad des géants du web en particulier lié à de newsfeed de facebook comme le montre d'ailleurs la publication de facebook ce que les chercheurs ont fait c'est d'abord choisir une métrique de la joie ou de la colère des postes facebook même si cette métrique n'est pas idéal on peut tout de même raisonnablement supposer que les individus dont les postes facebook sont plus joyeux sont aussi des individus plus voyons ensuite les chercheurs ont testé les effets d'un petit changement de l'ia en charge des news feeds sur l'humeur des utilisateurs facebook ils ont ainsi choisi 155 mille utilisateurs au hasard et ont divisé aléatoirement ses utilisateurs en trois groupes pour le groupe de contrôle n'ont pas changé liés à des news feeds pour le second ils ont dit à l'ia de promouvoir des postes joyeux et pour le troisième groupe ils lui ont dit de promouvoir des postes négative une semaine plus tard comme on pouvait peut-être aussi attendre les individus du second groupe se sont mis à éclair des postes plus joyeux tandis que ceux du troisième groupe se sont mis à écrire des postes plus négatif lié à de facebook avaient influencer l'humeur de centaines de milliers d'individus si les résultats sont bien statistiquement significatifs au sens de la paix va lui il faut toutefois rajouter que l'effet n'est pas énorme mais là encore ce n'est pas si surprenant on ne change pas complètement d'humeur d'une semaine à l'autre par contre on peut vraiment se demander ce qu'il en serait si ce changement de l'humeur des postes auxquels on est exposé durer plusieurs mois ou plusieurs années de façon plus générale s'il y a de facebook cherché à promouvoir la bonne humeur et disons les critiques constructives plutôt que les insultes et le hooliganisme politique il pourrait alors avoir un impact global et ainsi toucher non pas 100 noms peuvent ils n'ont pas un million mais des milliards d'individus et le plus remarquable c'est que ce changement de comportement de l'ia de facebook pourrait correspondre à un coût minime pour facebook bref pour le conséquentialiste liées à de facebook est un pouvoir énorme un pouvoir plus grand que celui de tous tu mens et de grand pouvoir implique de grandes responsabilités plus tard parce qu'il pense pas alors cet argument conséquentialiste vous choque peut-être vous vous dites peut-être que plutôt que de promouvoir les critiques constructives et la bonne humeur il y adeux facebook devrait être neutre sauf que la neutralité c'est un concept complexe mais surtout le problème avec cette approche c'est surtout que les utilisateurs de facebook préfère avoir un incident biaisé et du coup enlever toute personnalisation du newsfeed pourrait avoir un coup majeur pour facebook et pour les utilisateurs de facebook et ça en termes conséquentialiste c'est pas cool puisque ça serait au détriment des utilisateurs facebook mais en plus ça serait difficile de convaincre facebook qu'il s'agit là d'un gros devoir moral pour facebook puisque ça impliquerait également un énorme coût individuel bref en termes conséquentialiste la neutralité de facebook ne me semble pas forcément très justifiable même si je me trompe peut-être dans quelques conséquentialiste alors facebook on aime bien taper dessus ceci étant dit il me semble qu'il pourrait y avoir une il ya encore plus puissante que celle de facebook à savoir l'ia de youtube en particulier lia qui recommande telle ou telle vidéo à tel ou tel utilisateur on a tous fait l'expérience vous commencez par une vidéo random à 20 heures et vous enchaîner avec une autre vidéo et tout à coup il est 3h du matin et vous regardez maintenant un truc super bizarre et puis deux ans plus tard vous faites partie de communautés dont vous ne suspects et même pas l'existence deux ans plus tôt alors parfois cette spirale est pour le mieux et si vous êtes ici sur scène ce rôle vous connaissez sans doute l'incroyable communauté de vulgarisateur notamment autour du café des sciences mais comme vous le savez sans doute il ya aussi d'autres spirale - raisonnée qui peuvent conduire à toutes sortes de théories conspirationnistes paranormal ou pseudo scientifique ou encore à des idéologies extrémistes qui promeuvent la haine envers certains groupes sociaux les esthéticiens qui cherche à lutter contre la montée de ces mouvements pseudo scientifiques disent régulièrement qu'il est important pour eux d'être sur youtube pour occuper le terrain alors certes je pense perso qu'il faut en effet beaucoup plus de vidéos scientifique en quantité et en qualité sur youtube mais je pense aussi qu'il y a en fait déjà énormément de quantité et de qualité sur youtube dès lors pour occuper le terrain il faut il suffit que youtube promeuvent ces vidéos qui existe déjà pour la promotion de la rationalité et des sciences les créateurs notamment les nouveaux créateurs dont fait qu'un pouvoirs très limités le vrai pouvoir d' influence il appartient à lire de youtube si elle veut promouvoir une vidéo elle le peut comme personne d'autre d'ailleurs ce fut le cas de cinq forums si ma chaîne a maintenant la chance d'être vus par des dizaines de milliers parfois même des centaines de milliers d'entre vous c'est essentiellement grâce à lla de youtube qui le 20 juillet 2016 c'est tout est commise à promouvoir mes vidéos elle en a remis une couche le 14 novembre 2016 or de nos jours nous regardons plus de vidéos youtube que nous ne faisons de recherche sur google autrement dit il ya de youtube nous fournit bien plus de réponses que nous nous en faisons ainsi notre compréhension du monde est fortement biaisé parce que l'ia de youtube nous montre pour le meilleur comme pour le pire imaginez maintenant qu'il y ait un bouton devant vous si vous l'appuyer lié à cherchera alors à promouvoir les vidéo intelligente et raisonnée et à moins partager celles qui poussent à la haine et aux théories conspirationnistes est-ce que vous appuyez dessus avant de revenir vos questions quelques annonces je serai à paris le 30 juin avec monsieur fille on vous parlera de la mort dans un café parisien d'inscrire ces organisé par action française de transhumanisme et voilà on va essayer de défendre encore cette idée sur laquelle la mort c'est quand même un truc pas cool ça serait bien temps de pouvoir ne pas vieillir ça serait cool et j'annonce aussi que je serai au palais de la découverte le 7 juillet à 16h pour vous parler du démon de ceux qui connaissent un petit peu puisque c'est le chapitre 7 de mon livre ce sera notamment pour vous l'occasion de visiter le palais de la découverte notamment cette nouvelle section qui a été ouverte auprès des couleurs qui correspond à l'informatique la fois j'étais revenu sur l'épisode sur les cinq scénarios catastrophes causées par une intelligence artificielle zai de dos me fait remarquer que j'ai parlé uniquement de disto pied pas d'utopie et du coup la question qui se pose c'est est-ce que nos copies quand même assez possible ou presque des cures à une sur sa fille à deux niveaux humain on risque vraiment tous d'y passer alors tout d'abord assez intéressant de voir que notamment les scénarios 3 et 5 au début tout se passe bien et que tout finisse par bien se passer et que les maladies soient tous ce soit tout soigner que et bien les biens de base accès pour tous des humains et que on est même accès à à plein de vie associative en face tous les projets et fascinant qu'on a envie de faire et on développe de plus en plus de divertissement de plus en plus élaborées depuis n'ont plus besoin fun je pense qu'une utopie est tout à fait possible mais en mobilisant la question en fait ce serait plutôt de savoir est ce que une utopie ou en tout cas un monde qui ne disparaît pas est plausible et je dois bien dire que avant la d'avoir travaillé on peut sur ces dernières vidéos j'étais relativement confiante à ce danger mais il suffit de régler après ce sera vous est en fait en préparant ses vidéos je me suis rendu compte que le danger je l'avais largement sous-estimées évidemment il ya deux choses que je pense avoir vraiment sous estimé le premier c'est les tous les risques potentiels je pense qu'avec ces scénarios on voit bien qu'il ya beaucoup de beaucoup de risques beaucoup de causes possibles beaucoup de façons pour que les choses aillent mal aujourd'hui encore des milliards d'euros qui sont investis dans la recherche sur créer des robots juste pour tuer moi ça me fait vraiment flipper donc voilà il ya beaucoup de risques et je pense avoir sous-estimé largement c'est risquer un autre truc que je pense avoir sous-estimé c'est la probabilité qui les unit à deux niveaux humain dans un avenir pas si lointain certes j'ai tendance à penser avant ces vidéos que bon on avait plusieurs décennies devant nous du coup on peut peut vraiment prendre le temps de recherche bien pensé le problème mais si le problème est et dans 5 ans il ya des chercheurs en ia qui pensent que il pourrait avoir une ou deux niveaux humain dans cinq ans si le premier dans cinq ans on n'est pas du tout prêt n'aimait vraiment aujourd'hui je prenais vraiment absolument pas près qu'aujourd'hui s'il ya quelqu'un qui a les pieds tous les ingrédients en sciences artificiel aujourd'hui et qui est dans son coin et qui peut tester le truc c'est foutu parce que n'a rien de prêt donc c'est aussi celle qui est sous-estimée et qui a une probabilité qui est si j'en crois les experts on y re non négligeable qu'il y ait un truc de niveau humain dans un futur pas si lointain et si c'est le cas il est mineur on ne soit pas du tout près donc tout ça pour dire que rien n'est perdu je pense qu'il ya encore beaucoup de recherche qui peut de fait on peut avoir une structure beaucoup plus solide beaucoup plus robuste tolérantes aux fautes et auch n'a pas besoin d'une morale les yaks tueur parfaite selon lui pas du tout faut juste qu'elle soit juste suffisamment bien mais c'est un problème qui est déjà suffisamment difficile et qui est absolument pas du tout près d'être résolu tout cas c'est l'impression que j'en ai par laure et en lisant un peu de la recherche dans le domaine et voilà l'idée que ça pourrait arriver dans cinq ans ça me fait vraiment vraiment flippé du coup à j'aurais tendance à dire que c'est possible ça se passe bien mais il ya une probabilité très non négligeable que les choses se passent mal je pense mais pour finir sur une note un peu plus jovial se river fait remarquer que le cinquième scénario est finalement très proche de l'idée de la machine de musique dont me suffit à parler dans cette vidéo dont je regrette vivement la vidéo de monsieur fille et ça me fait penser à une interview d'andorre stenberg qui un philosophe au cultura open it in situ créé à oxford et qui parle de l'hypothèse du prime de fermi du paradoxe de fermi ce paradoxe il dit que voilà là c'est sûr qu'on voit rien qu'on ne voit pas de vire extraterrestre intelligente dans l'univers puisqu'a priori voilà quelques millions d'années près forcément s'il n'avait plusieurs univers y en a une qui serait apparu quelques millions d'années avant nous alors eu le temps de se développer et de devenir énorme et du coup on devrait l'avoir vu est une explication et qu'avant sa dorsale berck que je trouve assez amusante pas entièrement convaincante les thunder il lui même dit que lui attribue une probité de 10 % 10 % ce qui est négligeable c'est le fait que c'est toutes les civilisations de futures ont fini par comprendre que ils ont exploré un peu l'univers n'avait que l'univers était cool mais si on finit par comprendre que le truc le plus cool en fait donc explorer ce sont les univers virtuels ce sont des simulations ce sont les propriétés des puissances de calcul sur du jeu vidéo clé ça comme vous voulez mais que du coup pour pouvoir jouer pour pouvoir profiter de ça le plus longtemps possible il fallait faire des calculs qui ont un coût énergétique le plus faible possible hélas ce qui est intéressant c'est qu'il ya une loi de la physique qu'on appelle le principe de lindau qui dit que en fait le shaq calculs chaque opération qui ont effectué en fait ce serait une opération irréversible mais bon chaque opération à lison à un coût énergétique on perd un petit peu d'énergie à effectuer un calcul et ce qui est amusant c'est que l'énergie que l'on perd dépend de la température l'énergie en fait proportionnelle à température et ça ça veut dire que si on veut pouvoir faire beaucoup de calculs avec une énergie données il vaut mieux faire ce calcul à une température très basse or a priori comme en avait à cause de l'expansion de l'univers l'univers sera beaucoup beaucoup plus froid mais dispose ans trente fois plus froid dans un univers très très très très très éloigné du coup peut-être que la stratégie optimale pour une civilisation indienne qui veulent juste profiter du calcul autant que possible ce sera de figer un peu de se figer au fuji un peu la mémoire de ses habitants pendant tout l'âge de l'univers pendant des google d'année et après des google d'années ils pourront commencer à faire des calculs dans un univers qui sera une température de 10 puissance moins 3 montrant kevin quelque chose comme ça et grâce à cela ils pourront faire beaucoup beaucoup plus de calculs que s'il avait commencé les calculs dès aujourd'hui et ça ça expliquerait pourquoi les civilisations un alien cherche à nous avoir aucun impact dans l'univers d'aujourd'hui puisque avoir un impact dans l'univers d'aujourd'hui correspond à dépenser cette énergie en calcul dans un univers qui est encore relativement chaud y compris dans le vide interstellaire et du coup c'est pas du tout une stratégie optimale et donc si on peut imaginer que si toutes les civilisations aliens finissent par comprendre ça et du coup se prépare pour une une avenir pas très lointain elles chercheront du coup un avoir aucun impact sur l'univers très proche et cherchant le juste un agrégé un maximum de matière c'est conserver la matière est-ce que la matière et de l'énergie aussi proches que possible pour pouvoir une certaine venir dépenser cette matière dans quelques google jeune et je trouve ça assez fou comme pensée ouais pas forcément ultra réaliste mais pas forcément ultra débile non plus j'espère que vous avez aimé cette vidéo excelsa fait notamment réfléchir à la notion d'altruisme efficaces font ce qu on est beaucoup à vouloir que le monde se porte mieux qu'il ne se porte aujourd'hui mais pour pouvoir y arriver il y est important d'essayer de saisir d'identifier notamment les opportunités les façons de faire pour vraiment amélioré significativement le monde et pas pour avoir juste l'impression d'avoir fait une bonne action d'ailleurs toute la preuve de cette vidéo et est fortement influencée par l'excellent podcasts et issa zone hours que j'ai cru télé crochet binge écouter au cours des dernières semaines c'est vraiment vraiment excellent jeu 2 vivement si vous êtes à l'aise avec l'anglais je recommande très très très très vivement d'écouter ce podcast et ça va vous donner une perspective complètement différente sur les problèmes de société on se rend compte quand on écoute ce podcast qu'il ya des problèmes ultra chaud par exemple les robots autonomes tu as acquis smic sont vraiment flipper mais aussi d'autres problèmes comme par exemple la sécurité et en intelligence artificielle qui sont des sujets vraiment les gens d'haïti thousand words les gens interviewés notamment sont tous des experts qui ont énormément réfléchi à la question de l'altruisme efficace comment faire un maximum de biens en travaillant aujourd'hui de façon assez concrète est vraiment ce qu'il reçoit constamment de ces discussions mais vraiment quasiment à chaque fois c'est le problème de du danger de l'intelligence artificielle et c'est pour ça que je pense que c'est très très important si vous avez les compétences notamment si vous êtes à l'aise avec certaines notions techniques ou si vous êtes aussi à l'aise dans les relations si vous avez un réseau si vous êtes capable d'influencer les gens qui vont influencer les décisions je pense que c'est très important que si vous voulez fait en plus faire quelque chose de bien votre vie entre travail plutôt qu'avoir un travail où on va juste un employé classique et en fait on compterait une certaine manière par exemple à l'algorithme de youtube je sais juste maximiser le nombre de vues qui est un objectif qui est finalement pas si différent de maximiser les trombones si vous sentez une petite crise morale et vous dit peut-être essayer de faire des trucs davantage mieux écouter vraiment et qui s'attend à voir ses premiers pas puis s'ils voulaient vraiment hollande y vivent ou prendre il ya des carrières possibles dans ce genre de domaine souvent sa demande quelques sacrifices forcément individuellement notamment au niveau salarial mais il ya beaucoup de récompenses aussi puisque là vous aurez vraiment l'impression de contribuer à ce que l'on vive dans une meilleure société ce qui est je pense avec quelque chose d'assez haut rang on a besoin de beaucoup plus de main-d'oeuvre beaucoup plus de gens qui sont capables de bien réfléchir à ces problèmes est de fournir des solutions à tous ces problèmes si vous avez aimez cette vidéo pensez à la ligue et à la commenter à la partager pensez à vous abonner pour ne pas manquer les futurs épisodes version people power dont et j'espère que vous serez là la prochaine fois qu est ce qui est intéressant dans la proche conséquentialiste c'est que la question morale fondamentale n'est plus la question que dois-je faire mais la question que vous louez qu'elle l'objectif visons nous pour le monde sauf à