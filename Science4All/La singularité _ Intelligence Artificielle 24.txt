En 2005 le futuriste Ray Kurzweil publie un livre intitulé : "La singularité est proche" Depuis, le terme "singularité" s'est entouré de mysticisme avec un penchant catastrophiste à la Skynet et les robots humanoïdes à la Terminator qui vous détruire le monde ou un penchant utopiste qui prétend que tous nos problèmes seront résolus du jour au lendemain, de la faim dans le monde à l'éradication des maladies en passant par le contrôle des changements climatiques et la gestion optimisée et raisonnée des ressources. Sans compter l'augmentation des facultés humaines voire peut-être les fantasmes d'immortalité. Malheureusement ce genre de discussion a tendance à éveiller l'hooliganisme en nous, si bien que, quand on parle de singularité peu importe ce qu'on en dit , il y aura des gens, et même beaucoup de gens, qui vont tourner en dérision tout ce qu'on dit. Oui, je te vois toi qui a commencé à écrire un commentaire qui se moque d'une caricature de la vie que je n'ai pas encore exprimée. Du coup, avant de nous emballer à imaginer des futurs exotiques, utopistes ou catastrophistes, je vous invite à d'abord nous arrêter sur l'incroyable succession de prédictions ratées des plus grands intellectuels en vous narrant une brève histoire du passé du futurisme. L'histoire moderne de l'intelligence artificielle débute certainement avec l'article de 1950 d'Alan Turing dont on a déjà parlé dans les épisodes 2 à 7. Les années 50 puis 60 connurent ensuite une grande période d'optimisme et d'enthousiasme avec des chercheurs comme Marvin Minsky, John McCarthy et Claude Shannon ou encore Noam Chomsky et Ray Solomonoff Aaah, Solomonoff ! Minsky en particulier déclara en 1967 la chose suivante: "D'ici trois à huit ans, on aura une machine avec une intelligence générale d'un humain moyen." Cependant à la fin des années 60 et au début des années 70, les progrès ralentirent, le pessimisme augmenta et les investissements diminuèrent. Voilà qui était de mauvaise augure pour la recherche. Et en effet pendant les années 70, l'euphorie pour l'intelligence artificielle fut tournée en dérision. En 1974, le mathématicien Lighthill rendit un rapport sur l'état de l'intelligence artificielle au Royaume-uni, et n'hésita pas à conclure que le robot à tout faire est un mirage. Ce fut le premier hiver de l'IA ou "AI winter" Puis tout à coup au début des années 80, trois événements relancèrent l'enthousiasme pour l'IA. En 1981, le gouvernement japonais investit 850 millions de dollars dans le domaine , ce qui motive à d'autres gouvernements à travers le monde à faire de même. Qui plus est, l'algorithme de rétro-propagation fut découvert. Aujourd'hui cet algorithme est le fondement des réseaux de neurones artificiels dont on reparlera plus tard dans cette série. Mais surtout, les chercheurs en IA abandonnèrent la quête d'une intelligence générale, au profit de systèmes experts, ou "exploit systems", dans des domaines en particulier Ces IA exploitèrent la connaissance des experts pour résoudre des problèmes habituellement réservés à ces experts. Mais en 1984, Minsky, cette fois prudent, annonça que l'enthousiasme était alors démesuré, et qu'il craignait un retour d'un hiver de l'IA. Et l'hiver arriva trois ans plus tard, en 1987. Encore une fois les investissements s'effondrèrent, et il devint académiquement tabou de s'intéresser à l'idée même d'intelligence artificielle Parler d'IA, c'était se couvrir de ridicule. Ainsi TedX Saclay 2017, Cédric Villani a raconté ce qui suit : "Le hasard des études a fait que je me suis retrouvé mathématicien des sujets très solide bien loin de l'image de flou qu'avait l'intelligence artificielle à cette époque. Et quand l'un de mes collègues s'est lancé là-dedans, dans l'intelligence artificielle, dans les années 2000, Je dis : "Est-ce que tu es sûr de ce que tu fais ? c'est un sujet qui n'a pas abouti à grand chose pour l'instant.." Héé, comme je me trompais, tout le monde se trompais. Personne n'avait anticipé que ça reviendrait sur le devant de la scène avec tant de force." Mieux encore, en 2011, quand je me suis mis à lire sur les réseaux de neurones pour la première fois, j'ai conclu que c'était vraiment de la grosse merde et que ça n'aurait aucune chance de faire des trucs incroyables. Pour le Lê de 2011, la recherche en IA été vouée à l'échec. Sauf que, comme on l'a vu dans le premier épisode de cette série, depuis 2012, l'IA n'a cessée d'enchaîner les succès époustouflant, au point de devenir incontournable . Aujourd'hui tout le monde parle de l'IA. L'IA est redevenue un trending topic, à tel point qu'à en croire certains, il n'est plus si déraisonnable de penser qu'une intelligence artificielle de niveau humain pourrait voir le jour d'ici, disons quelques décennies. Si je vous raconte tout cela c'est pour insister sur la difficulté à prédire le futur de la recherche en IA. A travers les décennies il y a eu beaucoup d'optimisme et de pessimisme excessifs. La prévision est difficile, surtout lorsqu'elle concerne le futur, dit l'adage. Et en particulier ces dernières années, je n'ai cessé de pêcher par pessimisme. Entre les réseaux de neurones, la construction de la sémantique ou la génération d'images réalistes, je n'ai cessé d'être stupéfait par les progrès des IA. Mais de façon étonnante malgré tous ces va-et-vient de l'optimisme en IA, il se dessine néanmoins une tendance claire et nette : les progrès de l'IA à semblent inarrêtable, mais surtout, ils semblent progresser à un rythme exponentiel. Et ça, de nombreux académiques l'ont remarqué encore et encore. Moore, par exemple, a énoncé sa fameuse loi de Moore qui dit, en gros, que les puissances de calcul doublent tous les deux ans. Ou encore le géant des maths John von Neumann aurait affirmé dans les années 50 que la loi de progrès accélérés des technologies donne l'impression d'approcher une sorte de singularité fondamentale dans l'histoire de notre espèce, au delà de laquelle les modes de vie des humains tels que nous les connaissons ne pourrons pas continuer. Irving Good, lui, parle d'explosion de l'intelligence tandis que Verner Vinge reprit en 1993 la terminologie de "singularité technologique" de von Neumann qui fut ensuite popularisée notamment par le livre "La singularité est proche" de Ray Kurzweil. Dans son livre, Nick Bostrom va même jusqu'à formaliser mathématiquement l'idée intuitive de von Neumann. On peut ainsi considérer que l'intelligence artificielle à un temps t est une certaine quantité I(t). Ce que sous-entend von Neumann c'est que plus I(t) est élevée, plus la vitesse à laquelle l'intelligence progresse est élevée. Si on suppose en particulier que la progression de l'IA est proportionnelle à son niveau On obtient alors l'équation : dI/dt=αI(t) dont la solution est une fonction exponentielle I(t)=C*e^(α.t) Alors normalement tout ça ça devrait vous rappeler des souvenirs de lycée, mais je suis à peu près sûr que vous ne vous rendez pas vraiment compte de ce que ça signifie vraiment. Une progression exponentielle c'est très très très rapide. Je pourrais longuement disserter dessus sans réussir à vous faire sentir la folie de la croissance exponentielle. Mais à titre d'exemple quand on plie une feuille sur elle-même, on double son épaisseur. Si on répète cela l'épaisseur de la feuille augmentera alors à un rythme exponentiel. Et ce qui est fou, c'est qu'en partant d'une épaisseur infime, il suffira de plier la feuille 42 fois pour que son épaisseur fasse la distance Terre-Lune, c'est complètement fou. D'ailleurs je vous invite à dire à voix haute la réponse que votre intuition fournirait à la question suivante : Combien de fois faut-il plier la feuille pour que son épaisseur fasse la largeur de l'univers observable ? Combien de fois d'après vous ? 1000 fois ? 1 million ? 1 milliard ? Petit indice pour vous aider : l'univers observable est environ un milliard de milliards de fois plus grand que la distance terre-lune. Bref, tout ça pour dire que la croissance exponentielle anticipée par von Neumann risque d'être fulgurante. Même si elle semble encore gérable aujourd'hui, elle risque de complètement nous stupéfaire d'ici quelques décennies, et si on n'y est pas préparé, on risque fort de ne pas comprendre ce qui nous arrive. Et on n'y est pas préparé. Mais il y a peut-être encore plus surprenant : il se pourrait que la vitesse de progrès des technologies soit encore plus spectaculaire qu'une croissance exponentielle. Oui, parce qu'on pourrait imaginer qu'une petite amélioration intellectuelle des machines intelligentes puisse conduire, non pas un petit incrément du rythme de leur progression, mais à un gros incrément de la vitesse de progrès des IA. Autrement dit, au lieu d'avoir : dI/dt=α*I(t), on pourrait imaginer avoir dI/dt=α*I(t)² Et d'ailleurs cet étrange postulat a justement été suggéré il y a quelques jours également par openAI, l'un des centres de recherche à la pointe de la recherche en IA. Or une telle équation différentielle a pour solution I(t)=1/(C-αt) Autrement dit cette solution diverge au bout d'un temps finis t=C/α Ainsi si l'on en croit cette équation, on pourrait avoir une singularité mathématiques en temps fini. Alors bien sûr, il y a beaucoup de bémols à émettre à une telle analyse. Pour commencer bien sûr le concept d'intelligence est ici très mal défini. Tout ce que je viens de raconter ici n'est nécessairement qu'une métaphore impossible à formaliser rigoureusement. Mais ce n'est pas l'exactitude de l'argument qui importe. Tous les modèles sont faux. Ce qui importe vraiment c'est le constat de l'accélération des progrès technologiques qui se justifie par une observation très simple : plus on progresse, plus on construit d'outils performants et plus ces outils nous permettent de progresser vite. Et quand on observe n'importe quel indicateur économique, force est de constater que ce progrès a tendance à fournir des courbes exponentielles. Je vous invite à écouter ce court extrait d'un Ted Talk donné par l'économiste Andrew McAfee Autre bémol, une telle singularité, tout comme la croissance exponentielle d'ailleurs, violerait évidemment les lois de la physique. Du coup, on doit plutôt s'attendre à ce que les progrès atteignent tout à coup un plateau, au moment où l'intelligence des machines atteindra ses limites en ressources naturelles. Cependant, sachant que notre univers a réussi à concevoir et à héberger des intelligences de niveau humain dans une boîte crânienne à la suite d'une évolution darwinienne dont l'optimisation de l'intelligence n'était pas le but, il est difficile d'imaginer qu'une IA qui atteindra les limites physiques ne soit pas très très très largement supérieure à l'humain en tout point, y compris en terme de gestion optimale de la consommation d'énergie Bon, je vous ai présenté ici pas mal d'arguments théoriques et c'est difficile à avoir pleinement confiance en ces arguments. Du coup on peut essayer de se tourner vers autre chose par exemple : l'avis des experts . En 2012 selon des sondages sur 500 chercheurs lors de conférences en IA, la moitié des experts ayant répondu attribuent une probabilité d'au moins 10% au fait qu'une IA d'intelligence générale supérieure en tout point à l'humain voie le jour avant 2022. Cette majorité des experts parie au moins 50% de chances de voir une IA de niveau humain avant 2040 et 90% avant 2075. Plus récemment cependant, en 2015, selon un sondage sur 352 chercheurs, les chercheurs prédisent en moyenne l'émergence d'une IA de niveau humain pour 2065. Mais on peut voir sur le graphe qu'il y a de grandes variations entre les différents chercheurs. De façon étonnante ces variations ne semblent pas dépendre de l' expertise ou de la séniorité des chercheurs sondés, mais elles sont fortement influencées par l'origine géographique des chercheurs. La singularité semble beaucoup plus proche selon les asiatiques que selon les américains. Alors avant de sauter au plafond à dire que les experts sont débiles, je vous rappelle qu'on parle là d'un problème d'un niveau technique très élevé et que votre avis a peu de chances d'être plus pertinent que celui des experts. Ayez bien conscience de l'étendue de votre ignorance. Ceci étant dit, il faut aussi souligner que les experts sont très loin d'être infaillible. Dans le sondage de 2015, ils ont prédit qu'il faudrait encore 12 ans pour surpasser l'homme au jeu de go, alors que AlphaGo a battu Lee Sedol en mars 2016. Qui plus est, on peut souligner un important biais de sélection, puisque seuls les experts qui ont pris le temps de répondre au sondage nous ont dit ce qu'ils pensaient. Enfin ce qu'on voit très bien sur cette courbe c'est qu'il y a beaucoup de disparités dans les prédictions d'un chercheur à l'autre. Plus étonnant encore, même l'avis médian fluctue énormément. Sur ce graphe il y a par exemple 40 avis qui ont été sélectionnés aléatoirement, vous voyez qu'entre l'avis médian et celui juste à gauche et celui juste à droite la prédiction qui correspond à une probabilité de 50% pour l'émergence d'une intelligence artificielle de niveau humain varie facilement de plus ou moins 10 voire 20 ans. Bref, prédire le futur c'est pas facile. Alors perso[nellement] j'ai été étonné par ces chiffres, non pas parce qu ils contredisent mon intuition, en fait, pour tout vous dire, je suis surtout surpris à quel point les chiffres de l'expert médian sont étonnamment conforme à mes propres croyances bayésiennes. Typiquement je parierais bien 1 contre 1 pour que l'IA sera en tout point supérieur à l'humain disons avant 2045. Et j'ai pas franchement confiance en ma prédiction Si ces chiffres m'ont beaucoup surpris c'est surtout parce que quand on parle à des chercheurs en IA, ou quand on écoute des interventions de chercheurs en IA à la radio, à la télé ou en conférence, ceux ci ont tendance à laisser penser que l'IA de niveau humain, c'est pas pour demain. Ni pour dans 20 ans, ni pour dans 30 ans, ni pour dans 50 ans parfois. Mais à bien y réfléchir ce n'est peut-être pas si étonnant, comme le suggère Nils Nilsson, les chercheurs en IA subissent une espèce de biais de respectabilité quand ils parlent en public. Oui parce que l'histoire de l'IA, et notamment ses deux hivers glaciaux des années 70 et 80 nous invite à faire preuve de prudence quand on parle en public, parce qu'annoncer des trucs spectaculaires qui n'ont pas lieu, ça la fout mal, alors que découvrir des trucs spectaculaires sans les avoir annoncés, ça n'a aucun coût sur notre crédibilité. Et du coup, un chercheur est mieux vu quand il démystifie les avancées en IA que quand il prédit d'autres avancées spectaculaires. En bref, les incentives font que les chercheurs ont intérêt à se montrer bien plus prudent que ce que leur intuition pourrait suggérer. Et c'est sans doute pour cela que même si beaucoup le pensent avec une crédence non négligeable, personne n'ose dire que l'IA pourrait déjà être en tout point supérieure à l'homme dès 2050. Je vous renvoie notamment vers le dernier Axiome que l'on fait avec Monsieur Phi où l'on parle de ce biais. Bref, il y a beaucoup de bémols à mettre à notre analyse, néanmoins, malgré toutes les difficultés que posent les prédictions sur le futur de la recherche en IA, il en ressort toutefois un étonnant consensus : il semble bien qu'il y ait au moins 75% des chercheurs du domaine qui pensent que l'intelligence en tout point supérieure à l'homme verra le jour très probablement dans le siècle à venir. Et même si les avis des experts et les sondages des avis des experts sont loin d'être fiables, il semble alors déraisonnable de persister à penser que la question de la singularité est un sujet qui ne mérite que la moquerie. Même si vous croyez que ce scénario n'a que 1 % de chances de se réaliser de votre vivant, ça vaut quand même sans doute le coup d'y penser. [DEBUT SOUS-TITRES AUTO] l'anr fois on a parlé de chasse ai demandé qu'est ce qui était un chat on avait vu dans un réseau de neurones qui fournissait une réponse à cette question est dans la vidéo j'avais notamment critiqué la définition selon lesquelles les parents d'un chat son achat thibault au richard fait remarquer que en fait dans cette définition on utilise le mot chat à l'intérieur définition du mot chat et on nous apprend parfois les colts mais en fait il faut jamais faire ça en fait c'est pas tout à fait vrai en fait il existe un cadre défini par algorithmique notamment où l'on peut avoir des définitions qu'on appelle récursive tellement on peut très bien définir l'ancêtre d'un animal comme étant soit le père de l'animal soit un ancêtre du père de l'animal ça c'est une définition qui est en fait algorithmes font tout à fait valable et qui en fait est très souvent utilisée notamment pour construire des structures de liste dans des vêtements une liste on va définir ce serait comme étant soit une liste vide soit un objet est suivie d'une autre liste d'ailleurs ce que j'aime bien avec cet exemple ce qui montre bien tout l'intérêt en fait d'un proche ivory smic pour bien que penser le concept de définition un blog se demande si pour entraîner l'intelligence artificielle de google estime ford on a dit à cet interstice ya s'il y avait des chats ou non dans les photos ça c'est le cadre de ce qu'on appelle l'apprentissage superviser et en fait l'apprentissage de superviser ces revers ça existe depuis bien plus longtemps que 2012 est déjà des résultats avant mais ce qui est vraiment stupéfiant avec l'article 2 où l histoire des techs cette ia qui a découvert le concept de chat c'est qu'elle a découvertes vraiment tout seul de juste vous montrer des images et on lui a demandé de comprendre ces images de synthétiser de trouver une sémantique des images et c'est ocde ce qu'on appelle d'un apprentissage non supervisé tout ce qu'on fait c'est juste donner plein d'image alia sans lui dire ce qu'elle doit faire si sony cherchait à trouver du sens dans les données auxquels elle est exposée et techniquement donner du sens aux images qui revient vraiment a cherché à trouver une bonne compréhension de ces images est en fait il ya un lien très fort entre l'apprentissage et la compression puisque si on en croit notamment l'induction de seconde offre dont j'ai parlé dans mon livre qui va être publié d'ailleurs le 7 juin ça fait déjà un petit peu d'auto coup dès maintenant vous pouvez d'ailleurs déjà le précommander sur blessure bref selon l'induction de solomonoff en fait l'apprentissage est vraiment de la compression de données avec perte jeandel bas pose la question de la capacité de stockage de notre cerveau sachant qu'il n'ya finalement que 100 milliards de neurones dans le cerveau ça laisse suggérer s'il ya un neurone par concept qu'il n'y a que 100 milliards de concepts qui peuvent être enregistrées dans notre vie voir ce qui est pas mal mais qui semble pas tant que ça en fait ce qu'ils soient c'est que l'information n'est pas encore des dents lino rhône mais plutôt dans des combinaisons d'activation de certains neurones Machine learning lorsqu'on a un concept en fait ça correspond vraiment une superposition de plusieurs activation de plusieurs neurones qui correspond en fait à un vecteur ça d'ailleurs qu'on parle de vecteurs de sémantique tellement dans world check et si on regarde par contre l'ensemble des vecteurs qu'on peut pour composer avec 100 milliards de neurones là on a plus un nombre qui est de l'ordre de en fait c'est le nombre de combinaisons de sous-ensembles en fait d'activation des neurones parmi 100 maire de nantes qui fait à peu près deux puissances 100 milliards et la 200 milliards on est vraiment tranquille c'est beaucoup plus grand que le nombre de particules de l'univers mais alors beaucoup beaucoup plus haut que nous les particulier en hiver je pense que Nicolas m'a bien fait remarquer que dans l'épisode de 20 heures on a peu parlé parfois de world check vous avait déjà parlé du concept de chat et le concept de chats dans word doc c'est une représentation sémantique de d'un mode du mot chat alors que dans l'épisode 24 c'était la représentation sémantique de certaines images du coup la question qui se pose naturellement c'est au savoir ce qu'on peut pas connectés les 2 et finalement avoir une même représentation symantec à la fois pour l'image d'un chat et pour le texte de chat est en effet c'est quelque chose qui a été pas mal étudiés et pas mal fait et notamment facebook a sorti une application je crois que c'était il ya deux ans déjà scellée c'est un truc assez vieux dans l'histoire du machine learning et c'est l'application de facebook on peut lui donner des images étaient capables de décrire en fait une légende de l'image espoir est en fait elle devait extraire la sémantique de l'image puis ré expliquer cette sémantique à l'aide par exemple de textes vous pouvez aussi faire inverse dire du texte et générer des images hors jeu pas si cet état de facebook était capable de faire mais aujourd'hui il ya pas mal de gars qui sont capables de faire cela et en effet on a maintenant une répression sémantique unifiée pour des sens différents pour des mesures sensorielle différents et en particulier on peut avoir des concepts profond qui sont activés à la fois par l'image d'un chat ou par le mot chat ce qui est quand même vraiment vraiment cool et qui commence vraiment à ressembler à la manière dont le cerveau fonctionne monsieur max ils se demandent maintenant ce qu'il en est de dessins de chat par exemple peu d'imagés destinées de chasse que mia est capable de reconnaître qu'il s'agit d'un chat mais pas d'un rachat et bien la réponse aujourd'hui c'est clairement oui d'ailleurs il ya un jeu avec une autre super vidéo de l'excusé qui parle de ce jeu qui s'appelle quickdraw qui est un jeu en fait joué avec unis rapid schnoering dessiner un truc est lié à doit deviner ce que c'est particulier voilà parfois il faut de dessiner un chalet qu'il ya quoi deviner qu'il s'agit d'un dessin de chat et là encore il ya une sémantique qui correspond pas à l'image brute leur image ershad certaine manière mais qui correspond à la sémantique d'une représentation deschacht sous forme de dessin et savons très bien que sesia en fait les manipulent différentes représentations du mot chaque ce soit sous la plante d'image sur la forme de dessins ou lui sous la forme de textes sont maintenant elles sont aussi capables de détecter le bruit d'un chat ou petit à petit elles sont capables de se doter en fait de différents sens que tous les sens petit à petit auquel l'humain a également accès et en croisant toutes ces informations en fait elles sont capables d'avoir des concepts qui sont indépendants l'origine sensuelle des données mais plus de quelque chose de plus fondamental qui est un peu un variant malgré qu'elles que soient en fait la forme de mesures censurer des données qui ont considéré j'espère que j'avais mais cette vidéo en fait la question de la singularité c'est une question assez intéressante mais ce n'est pas encore la question la plus fondamentale est plus perçue rang celle qui va vraiment faire que cette question est vraiment importante et urgente dès aujourd'hui en fait la question la plus fascinante à mon sens c'est la question de la vitesse de décollage te lire on parle aussi d'explosion d'un bilan et c'est ce dont on parlera la prochaine fois si vous avez aimé cet épisode français le lac est le commentaire de partage et pensez à vous abonner épisode merci au team apollo redon et j'espère que vous serez là la prochaine fois Il faudrait vraiment qu'ils les probabilités président soit extraordinairement négligeable pour ce soit pas un tout petit peu intéressant de s'intéresser au troisième point Le troisième point c'est vraiment le coeur du livre de bostrom typiquement est vraiment le cas de ces réflexions et voilà la seule raison pour laquelle on pouvait voir ce serait légitime de dire ok vraiment on s'en fout ça si c'était vraiment totalement négligeable si c'est pas totalement négligeable c'est au moins intéressant de se pencher sur la question est effectivement je pense que justement parce que c'est très difficile à évaluer C'est pas négligeable Dire que c'est totalement impossible séance et faire une prédiction qui est beaucoup plus précise que toutes les prédictions phoenix bostrom en fait dire vraiment ça ne regarde jamais cessé tout à fait fantaisiste où ça s'est vraiment faire un pari sur l'avenir qui bien que d'un certain que paris fait mine boston symphony lindy jamais autre chose que ses propos il ya une certaine probabilité de ceux ci il n'est pas spécialement optimiste par exemple le petit pont sur le fait d'arriver à emilia de niveau humain il est plutôt pessimiste par rapport en tout cas par rapport aux chercheurs qui consultent et île située plutôt dans la tranche des plus pessimistes donc voilà donc tout ça pour me mettre un peu à couvert dire à partir du moment où vous acceptez que c'est pas négligeable les deux premières fortes probabilités et j'ai l'impression qu'on sait rire plutôt rationnel de considérer que c'est pas négligeable du coup ça devient intéressant qui s'intéressent à la troisième quand même même si un peu le risque de passer pour un fou parce que là c'est envisager d'aider Situation très compliquée