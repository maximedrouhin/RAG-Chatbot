La dernière fois on a parlé de l’IA de YouTube. Celle qui suggère les vidéos à gauche de celle-ci et qui vous a peut-être suggéré la vidéo que vous êtes en train de regarder. Il semblerait que l'objectif de cette IA soit avant tout de garder votre attention pour que vous continuiez à regarder YouTube. Son but est votre addiction à YouTube. Imaginez maintenant que vous soyezà la place de cette IA et imaginez que vous disposiezde deux types de vidéos : disons les vidéos bleues et les vidéos rouges. Ces couleurs peuvent correspondreà des partis politiques, ou à des styles comiques versus romantique, ou à des sujets math versus informatique. Bref vous avez deux types de vidéos à proposer et à chaque instant il vous faut proposer une collection de vidéos qui est une certaine combinaison des deux types de vidéos. Bon, pour commencer vous allez peut-être proposer 50-50 mais petit à petit, si vous voyez qu'un utilisateur clique plus souvent sur les vidéos bleues, vous allez peut-être alors vouloir augmenter la proportion de vidéos bleues proposées. Et vous voyez le danger ? Au fur et à mesure, il semble y avoir un risque que vous ne proposiez plus quedes vidéos bleues à l'utilisateur, auquel cas l'utilisateur sera enfermé dans un certain style de vidéos Il sera dans ce que l'on appelle une "filter bubble" que je vais appeler aujourd'hui une "fixation aux vidéos bleues". Et bien sûr il aurait aussi pu y avoirune fixation aux vidéos rouges. En fait le danger est un peu plus subtil encore : Imaginez que la condition initiale soit 50-50 et que l'utilisateur clique au hasard parmi les vidéos proposées. Les fluctuations statistiques vont faire que l'utilisateur va sans doute cliquer légèrement plus souvent sur une couleur que l'autre, même si ces clics sont aléatoires. Mais l’IA de YouTube pourrait alors surinterpréter cela et malgré tout augmenter la proportion de la couleur la plus cliquée. Typiquement si en cliquant au hasard vous avez légèrement plus cliqué sur les vidéos rouges alors l’IA vous proposera peut-être 40% de vidéos bleues et 60% de rouges. Mais alors si l'utilisateur continue à cliquer au hasard, il va maintenant cliquer plus souventsur le rouge que sur le bleu, tout bêtement parce qu'on lui proposeplus de rouge que de bleu. Et l’IA pourrait à nouveau interpréter cela comme une préférence pour le rouge et ainsi continuer à augmenter la proportion de rouge. On parle alors de dynamique de tirage par renforcement, dans le sens où ce qui a été cliqué se trouve être renforcé dans les tirages suivants. Et une question fondamentale que l'onpeut se poser est la suivante : Un tirage par renforcement va-t-ilconduire à une fixation ? À quelles conditions l’IA de YouTube conduira-t-elle inéluctablement aux filter bubbles ? Et bien il se trouve que dans un cadre plus formel ces questions fascinantes ont fait l'objet de la thèse de doctorat du plus grand YouTubeur mathématiciens du YouTube francophone. j'ai nommé le génialissime Michael Launay Aujourd’hui on va parler notamment du théorème De Launay et j'ai un invité très spécial pour vous en parler Bonjour Lê! Alors effectivement il se trouve que j'ai fait ma thèse sur ce que l'on appelle des processus de hasard renforcé Pour comprendre ce que c'est on va prendre une urne comme celle-ci dans laquelle on va mettre une boule rouge et une boule bleue pour commencer. Et on va faire des tirages au sort dans cette urne par exemple ici je vais tirer une boule au hasard et je vais tomber sur la rouge et si je tombe sur la rouge et bien je vais la remettre à l'intérieur mais je vais en rajouter en plus une autre de la même couleur de sorte que j'ai maintenant deux rouges et une bleue et donc si je refais un autre tirage au sort forcément j'ai plus de chances de tomber à nouveau sur une rouge donc je vais en rajouter encore une rouge à l'intérieur et je vais continuer ce processus pendant un certain nombre d'étapes pendant un très grand nombre d'étapes et même jusqu'à l'infini et une des questions qu'on peut se poser sur ce processus c'est à l'infini quel va être par exemple la proportion de boules rouges ou de boule bleue dans l'urne. Qu'en penses-tu Lê? Alors pour tout vous dire Michael m'avait déjà posé cette question il y a quelques mois à Play Azur et j'étais très surpris par la réponse à cette question parce qu'a priori j'aurais parié que l'on aurait inéluctablement une fixation C’est-à-dire qu’à l’ infini l’urne ne serait quasiment uniquement toute rouge où quasiment toute bleue j'aurais parié qu'à cause du renforcement toute proportion équilibrée est improbable et j'ai été très content d'apprendre que mon intuition était très erronée. Et oui en effet alors ce processus de remplissage d'urnes a été étudié en 1930 par le mathématicien George Pólya  et le résultat c'est que la proportion de boules rouges et de boules bleues dans l'urne à l'infini n'est ni 0 ni 1, mais un nombre aléatoire compris entre 0 et 1 et le plus surprenant c'est que n'importe laquelle des valeurs comprises entre 0 et 1 a la même probabilité de tomber autrement dit à la limite la proportion de boules rouges dans l'urne va être une variable aléatoire uniformément répartie entre 0 et 1 Et oui j'ai trouvé ça très surprenant ne serait ce parce que je ne m'attendais pas vraiment à ce que la proportion de boules rouges converge, et qu’en plus cela face une jolie distribution toute simple C’est très surprenant et très joli mais que se passerait-il si l’on suppose maintenant qu'il y avait initialement une certaine proportion de boules rouges et bleus Dans le cas général où il y a plusieurs boules rouges ou plusieurs boules bleues dès le départ comme par exemple ici 2 et 2 et bien la proportion de boules rouges dans l'urne à l'infini va encore une fois tendre vers une certaine limite mais cette limite cette fois va être répartie selon une autre distribution qu'on appelle la distribution bêta mais on peut peut-être éviter ces détails techniques pour aujourd'hui. Cool ! Donc si je récapitule en gros si la force de la couleur rouge est le nombre de fois qu'elle a été tirée alors à l'infini il n'y aura pas vraiment de fixation il y aura une disproportion entre boules rouges et bleues. Mais boules rouges et bleues resteront en quantité comparable Mais qu'en est-il maintenant lorsque la force d'une couleur n'est pas tout à fait le nombre de fois qu'elle a été tirée Ça c'est une question que plusieurs chercheurs se sont posés. Imaginez qu'on reprenne notre urnes comme ceci avec une boule rouge et une boule bleue quand on tire la boule rouge pour la première fois et bien on la remet et on en rajoute une supplémentaire comme ceci Mais maintenant si je retire une boule rouge pour la deuxième fois et bien non seulement je vais la remettre mais cette fois ci je vais en rajouter deux nouvelles rouges comme ceci. Et plus généralement quand je vais tirer une boule rouge pour la énième fois eh bien je vais rajouter N boules rouges à l'intérieur de l'urne avec ces nouvelles règles du jeu que se passe-t-il maintenant Intuitivement cette fois le renforcement sera beaucoup plus conséquent si une boule rouge a été tirée N fois, on n'aura pas N+1 boules rouges comme avant cette fois on aura une boule rouge + une boule rouge pour la premiere fois qu'elle a été tirée puis deux boules rouges pour la seconde fois puis trois boules rouges et ainsi de suite jusqu'à N boules rouges pour la énième fois que la boule rouge a été tirée. Au total le nombre de boules rouges sera 1+ 1+2+3+4 et ainsi de suite jusqu'à N ce qui fait environ N²/2 boules rouges on peut donc considérer que la force d'une couleur est à peu près égale au carré du nombre de fois où cette couleur a été tirée on parle dans ce cas là de renforcement quadratique et du coup Mickaël, en cas de renforcement quadratique aura-t-on fixation ? et bien la réponse est oui dans ce cas le renforcement est si fort que l'on finira forcément par ne plus tirer qu'une seule des deux couleurs on a donc bien fixation. Donc intuitivement, j'imagine qu'il en serait de même pour un renforcement cubique quartique ou exponentielle la question qui est maintenant intéressante c'est qu'en est-il du cas entre le renforcement linéaire qui est celui dont on a parlé au début. et le renforcement quadratique. Et bien en 1990 le mathématicien Burgess Davis a montré une condition nécessaire et suffisante pour qu'il y ait fixation cette jolie condition est la suivante : il y aura fixation si et seulement si la somme des inverses de la suite de renforcement converge. Ha ! C’est tellement beau comme théorème. On a une question intrigante et non triviale et ce théorème en fournit une réponse simple et élégante. D'ailleurs il y a un truc plus joli encore que le théorème c'est la preuve du théorème par Herman Rubin oui c'est vrai cette preuve est absolument magnifique Et d'ailleurs cette preuve fait partie des raisons pour lesquelles j'ai voulu faire ma thèse sur ce sujet absolument fascinant. Bon malheureusement la preuve requière quelques connaissances pour être bien expliqué donc on ne va pas pouvoir la présenter ici Mais bon j’essaierai de faire un épisode hardcore, pas de promesses. ceci dit la recherche dans le domaine ne s'est pas arrêté là puisque michael aura apporté sa pierre à l'édifice en prouvant de nouveau théorème oui en gros mois j'ai étudié ce qui se passe quand on a plusieurs urnes de renforcement et que ces différentes urnes interagissent entre elles et c'est super intéressant parce que c'est un peu ce qui se passe sur YouTube de temps en temps il va y avoir une vidéo qui va faire un énorme buzz et qui risque alors d'atteindre la sphère YouTube de gens qui ne sont pas forcément intéressés à priori c'est comme si chaque utilisateur YouTube avait une urne de vidéos et que la vidéo en trending étaient tirées de l'ensemble de toutes les urnes et s'appliquer à tous c'est en tout cas un des modèles que j'ai étudié pendant ma thèse on considère plusieurs urnes avec un renforcement exponentielle et avec une probabilité P on va tirer une boule dans toutes les urnes réunies comme s'il s'agissait que d'une seule très grosse urnes et avec probabilité 1 - P on va tirer la boule dans l'urne toute seule indépendamment autrement dit selon le paramètre P et bien les urnes vont être plus ou moins liées entre elles ou plus ou moins indépendantes et donc le théorème de Launay ou plutôt l'un des théorèmes de Launay prédit les fixations ou non des urnes dans ce cadre en fonction notamment de la probabilité d'interaction P entre les urnes. oui alors déjà si P est plus grand que ½  ce qui signifie que les urnes interagissent beaucoup. comme le renforcement est exponentielle ce qui est très fort et bien on peut imaginer que toutes les urnes vont se fixer au bout d'un certain temps sur la même couleur et c'est effectivement ce que j'ai démontré ok mais ça a priori je dirais que ça ne ressemble pas vraiment au cas de YouTube. j'ai plutôt l'impression que les vidéos trending sont plutôt minoritaire parmi celles que voient les utilisateurs ce qui correspondrait plutôt au cas P < ½ Et bien dans ce cas j'ai démontré que les urnes allait se diviser en deux catégories d'un côté il va y avoir des urnes qu'on peut appeler des urnes conformiste qui vont se fixer sur la couleur qui est globalement majoritaire et de l'autre côté il va y avoir des urnes qu’on peux appeler anticonformiste qui vont se fixer sur une autre couleur de leur choix les urnes au conformisme ne verront alors que des vidéos de la couleur majoritaire tandis que les urnes anticonformiste verrons un peu des deux vidéos avec probabilité P donc dans une minorité des cas elles verront des vidéos de la couleur majoritaire mais avec probabilité 1-P et bien elles verront des vidéos de la couleur qu'elles ont choisi et c'est très intéressant tout ça ça montre qu'en cas d'interaction faible un renforcement exponentielle qui soit dit en passant correspond à la formule de Bayes Naive que pourrait calculer une IA comme l’IA de YouTube. ce renforcement exponentiel a de bonnes chances de conduire à une ségrégation des utilisateurs. certains utilisateurs pourraient ainsi finir par regarder des vidéos conformiste tandis que d'autres ne serait exposé qu'à des vidéos anticonformiste. Alors loin de moi l'envie de dire que le conformisme c'est bien ou mal et que l'anti conformisme, c'est bien ou mal ce que je trouve important à signaler c'est que cette issue pourrait n'être qu'une conséquence directe de l'utilisation d'une IA en charge de la recommandation de vidéos YouTube mais aussi d'articles d'actualité ou de blogs notamment lorsque cette IA cherche uniquement à suggérer des vidéos qui vont plaire aux utilisateurs et tout ça ça marche pour des utilisateurs qui cliquent aléatoirement sur des vignettes YouTube qu'on leur montre or les sciences sociales ne cesse de montrer que nous autres humains sommes beaucoup plus influençables qu'un chimpanzé qui cliquerait aléatoirement. comme on en a beaucoup parlé dans la série sur la démocratie, On a tendance à être victime du biais de confirmation et de l'hooliganisme politique qui nous pousse à nous conforter dans ce que l'on croit déjà. tout ça pour dire que pour plaire aux utilisateurs Une IA comme l'IA de YouTube aura très probablement d'autant plus intérêt à implémenter un renforcement exponentiel. dès lors le théorème de Launay semble au moins partiellement s'appliquer auquel cas on s'attend à constater l'émergence de bulles d'anticonformisme qui s'opposent à une bulle majoritaire de conformiste et en particulier conformiste et anticonformiste subiraient une fixation de vidéos qui leur sont recommandées il verrait le monde en bleu ou en rouge mais pas en une nuance de bleu et de rouge. Pour éviter une telle ségrégation idéologique il faudrait alors absolument modifier la dynamique de renforcement. voilà qui semble nécessiter une modification des intentions de l’IA plutôt que de chercher uniquement à plaire aux utilisateurs il faudrait alors implémenter des valeurs morales de société à l’IA Un énorme merci à Mickaël notamment pour son intervention dans cette vidéo. Si vous connaissez pas Mickaël ben, C’est une chaîne YouTube qui marche du tonnerre et qui est absolument génial Puisque ça parle de maths et ça en parle très très bien donc vivement ses vidéos Et pour les plus motivés parmis vous, je vous recommande également la thèse de Mickaël qui est Super bien écrite et qui est vraiment très très clairs à très très agréable à lire et qui est très accessible également qu'à la partie compréhensible de cette thèse. voilà comme on peut l'imaginer c'est michael et du coup il ya un effort pédagogique absolument génial dans cette thèse qui la rend beaucoup plus lisible que d'autres thèses Comme celle de ??????? par exemple petite annonce avant de passer aux questions je serai au palais de la découverte ce samedi à 16h pour vous parler du démon de solomonoff qui le chapitre 7 de mon livre pour pouvoir assister à l'événement il faut acheter votre billet pour le palais de la découverte et ce qui vous donnera aussi l'occasion de visiter notamment la nouvelle section du palais de la découverte sur l'informatique La derniere fois on avait déjà parlé de la morale de l’IA de YouTube et antoine meyer a anticipé cette vidéo puisqu'il pose une question sur le fait qu'on puisse être enfermé dans un ensemble de vidéos en fait qui correspond toujours aux mêmes YouTubeur si on aime certains YouTubeur et ça nous empêche de découvrir d'autres YouTubeur Typiquement ça correspond à un champ de recherche qui pose la question de comment inclure une diversité dans les suggestions des intelligence artificielle que ce soit sur YouTube Amazon ou autre et c'est quelque chose d'assez intéressant puisque ça correspond déjà à quelque chose de un peu plus subtil pour les intelligences artificielles qui ne doivent pas uniquement maximiser le click to wait qui est le fait que les gens vont cliquer sur ce qui est suggéré qu'un peu la métrique une des métriques en tout cas de base qui sont utilisés par les systèmes de recommandation en général là il s'agit non seulement de regarder si les gens vont cliquer, mais aussi s'ils vont être amenés à découvrir d'autres genres du coup à peut-être plus cliquez dans le futur. Dans tout les cas c'est pas évident que juste en regardant les clics des utilisateurs ils soit facile d'inférer est-ce que j'ai intérêt à proposer plus de diversité ou non faut vraiment finalement que ça soit on connaît directement dans l’lA que Il lui est préférable de toujours proposer une certaine diversité bref tout ça pour dire que c'est un vrai problème mais il ya des chercheurs qui travaillent dessus et je vous renvoie notamment vers une interview zeta bike ce que j'ai fait avec docteur élisa seiis ???? qui travaille a l’EPFL. Math carré lui demande plutôt que de chercher à programmer la morale des IA il ne faudrait pas plutôt essayer de faire en sorte qu'un grand nombre de gens soient beaucoup plus formés aux nouvelles technologies est vraiment l'intelligence artificielle et soit dotée d'une éthique solide. très clairement je pense que ça serait bien si plus de gens réfléchissaient davantage à tous les enjeux éthiques et moraux, chercher davantage à voir des raisonnements qui sont cohérents autant que possible et chercher autant que possible à exprimer leurs conceptions de la morale de façon aussi claire que possible et ça serait encore mieux si ces personnes comprenait tous les enjeux qui était lié à l'intelligence artificielle en Particulier, et comment chercher à maîtriser intelligence artificielle en fonction de cette conception de la morale. mais c'est un problème extrêmement difficile y compris chez les experts de la morale et de l'intelligence artificielle et d'une certaine manière j’essaie de contribuer à cet effort en faisant ces vidéos S4 et j'espère que vous les partagez pour contribuer également à ces efforts malheureusement ça m'étonnerait qu'on arrive à avoir une fraction non négligeable de la population qui s'intéresse vraiment à ces questions et qu'ils le fassent et qu'ils y réfléchissent vraiment bien, j'ai envie de dire, à ces questions et qui ne s'enferment pas sur des trucs du 20e siècle typiquement. En particulier si je raisonne en termes d'altruisme efficace. il me semble qu'aujourd'hui En tout cas a mon échelle individuelle Vraiment le meilleur truc que je puisse faire pour avoir la meilleure influence positive sur, le fait que le monde ira mieux et qu’il maîtrisera bien ces nouvelles technologies. Qu’il en fera plutôt du bien que du mal. il me semble vraiment que ma priorité personnelle là où je peux avoir le plus d'effet c'est essayer de convaincre la plupart des ingénieurs et des chercheurs qu'il s'agit en effet d'un énorme problème et qu'il faut absolument bien poser le problème. et du coup les accompagner autant que possible dans l'infection autour de cela pour qu'ensuite ces gens-là fasse en sorte que les intelligences artificielles qu’ils programment aient des valeurs morales dans leurs fonctions objectif. j'ai bien peur malheureusement que aujourd'hui compter sur le citoyen lambda aujourd'hui moi j'aimerais bien j'ai vraiment envie que le mec soit vraiment très à l'aise avec le concept d'intelligence artificielle ai vraiment bien réfléchi à la morale malheureusement ça me paraît très difficile de passer par l'éducation nationale. aujourd'hui c'est juste impossible et touché un grand public aujourd'hui c'est très difficile du coup bah je fais ce que je peux et il me semble que pour un sens la meilleure chose à faire c'est vraiment déjà que les gens qui sont dans le domaine se sentent plus concernés par ces problèmes de morale enfin joël becane nous demande si l'un des grands problèmes de société aujourd'hui ce n'est pas plutôt la surconsommation des ressources et en effet c'est un énorme problème et je vous renvoie vers une des nombreuses vidéos du Réveilleur pour en savoir plus sur les problèmes de surconsommation en fait il faut bien voir que l'utilisation de ressources pour faire avancer des causes morales a aussi un coût moral qui est tout simplement l'utilisation de cette ressource du coup l'utilisation de cette ressource sera justifiée si elle permet davantage de faire du bien que du mal avec les conséquences environnementales notamment donc typiquement si je prends un exemple est-ce qu'il faut prendre un 4x4 pour faire 100 m bah ça correspond à un coût environnemental et ça ne correspond pas une conséquence bénéfique pour la société que diviser le 4-4 et du coup avec un résonnement conséquentialiste on conclu que c’est mal d’utiliser Un 4x4 pour faire 100m. Bon je prends un exemple un peu débile mais c'est pour vous montrer que dans le cadre du conséquentialiste cette consommation des ressources et notamment les conséquences néfastes de la consommation des ressources n’est pas parfaitement prise en compte par ce raisonnement il faut juste bien le modéliser vous avez aimé cet épisode pensez a le Liker, le commenter et le partager et pensez à vous abonner pour ne pas manquer les futurs épisodes merci au tippeurs pour leurs dons et j'espère que vous serez là la prochaine fois la dernière fois que YouTube a communiqué c'était un septembre 2016 2016 ils ont publié un papier scientifique qui s'appelait deep neural network for YouTube recommandations qui est donc un papier destiné à des scientifiques pas du tout destiné aux YouTubeurs0:18:15.520,0:18:16.570So that’s one challenge to provide Enough precision so that it matches your interest But enough discovery so that you have (you know) interest for the things and can discovery