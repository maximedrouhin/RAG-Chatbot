il ya quelques semaines l'institut haleine pour l'ia a rendu publiquement accessibles un algorithme conçu pour fournir des jugements moraux appelé telle fille vous pouvez par exemple demander un défi ce qu'elle pense de l'action de tuer et devinez quoi elle répond que tu es folle que se passe-t-il maintenant si vous lui demandez si c'est bien de mentir de faire des mathématiques ou de contribuer à tournesol je vous invite à jouer vous même avec delphi est à découvrir sans éthique mais aussi à ne pas prendre trop au sérieux tout ce qu'elle dit notamment lorsqu'il s'agit de jeter des batteries de voitures dans l'océan pour recharger de les anguilles électriques ou quand il s'agit des identités remarquables en mathématiques ou quand il s'agit d'estimer la valeur de certains scientifiques ceci dit quand il faut juger le youtube km d'el feel me semble pas trop mal s'en sortir clairement à la compris que 500 euros les plus intéressants que monsieur philippe et qu'il ya quelque chose qui ne va pas avec dirty biology eureka et sciences étonnante mais globalement même delphi pense qu'il ne faut pas lui poser des questions en fait l'idée même de concevoir des algues au rythme pourrait émettre des jugements moraux est selon delphi elle même quelque chose comme l'expliquent très bien monsieur fils dans un live tweet oui parce que apparemment se fit est maintenant sûr twitch et même ma fonction suite il ne faut pas imaginer que dalle pied est une source originale jugements moraux qui comme la pythie l'oracle de delphes nous communiquer la bonne réponse en puisant sans le savoir les dieux mais si j'ai décidé de vous parler de delphi plus encore que par ce que avec anne vachement drôle c'est parce que delphi illustre à merveille ce qu'on pourrait appeler le principe fondamental des algorithmes d'apprentissage qu'on appelle aussi le machine learning à savoir le fait que ses algorithmes sont ceux que l'ordonné d'entraînement en feront en particulier contrairement à une idée très répandue il n'y aura pas d'intelligence ex nihilo à de données pas de machine learning et pas de machines ont pas dire pas dire pas d'hier mais du coup ça veut dire que si les données de delphi pousse-t-elle fille à devenir raciste envers certaines populations alors delphi sera racistes envers ces populations en fait si les algorithmes classiques seront inéluctablement à l'image de leurs développeurs les algorithmes d'apprentissage eux seront inéluctablement à l'image de leurs données or ces données surtout quand il s'agit de textes ne viendront pas de nulle part inéluctablement ils auront été écrit par des humains ou par des machines qui ont appris à écrire grâce aux écrits du mans mais alors les jugements de delphi seront en fait avant tout des généralisations des jugements des humains qui ont écrit les textes sur lesquels delphi aura été entraînés et delphi apprendra alors inéluctablement les pièces dans ses textes si les humains derrière ces textes pense que l'hydroxyde chloroquine doit être administré pour soigner le coc vie de 19 ici les humains l'écrivent alors delphi conseillera l'identique loto quine pour soigner le coc vite 19 et s'il s'agit de trolls qui veulent faire revenir le compte twitter de terre cet algorithme de microsoft devenu raciste et sexiste alors delphi voudra à faire revenir tél pire encore s'il s'agit de campagne publicitaire disons d'entreprise de voitures voulant promouvoir les suv aux dépens des vélos alors delphi promouvra les suv aux dépens du vélo plus généralement tout système à la delphi doit absolument se rendre compte que les fournisseurs de données ont des comportements parfois maléfique souvent stratégique est toujours biaisées surtout sur des sites comme aurait dit ou amazon mechanical torque les principales sources de textes de delphi tous les participants forment un échantillon extrêmement biaisée de la population mondiale mais alors les textes d'entraînement de delphi ne peuvent pas être digne de confiance et comme delphine fait que généraliser ces textes elle ne devrait pas se faire confiance alors bien sûr surtout à ce stade quel film n'est qu'un jeu seuls des gens un peu geek connaissent et interagissent avec elle et donc même ses répliques les plus ignobles donc très peu de conséquences préoccupantes cependant ce n'est pas le cas d'autres ago est mieux conçue pour interagir avec des milliards d'humains et dont les données d'entraînement ne sont pas plus sécurisé je pense ainsi à alex un séries auxquelles google mais aussi et surtout l'algorithme de recherche de google search l'algorithme de recommandations de youtube et l'algorithme de fil d'actualité de facebook ces algorithmes doivent juger des milliards de fois par jour quel contenu recommandé à quel utilisateur en fonction de leurs recherches leur historique et de l'offre de contenus disponibles sur facebook youtube et tout internet et pour déterminer ce qu'il faut recommander quand un utilisateur charge capitalisme ou socialisme comme pour delphi google pas s'appuyer sur la popularité de différents messages dans sa base de données d'entraînement qui dépend typiquement 2 milliard de comptes google dont la majorité sont très probablement fake en fait c'est pire que ça à l'instar de telle fille dont les jugements dépendent fortement de la formulation des questions des utilisateurs les recommandations de google youtube et facebook dépendent beaucoup de l'utilisateur et peuvent très bien conforter les capitalistes convaincu que le socialisme si bob lé socialiste convaincu que le capitalisme simone et on pourrait croire que quoi qu'il arrive l'humain décidera et restera maître de sa décision sauf que contrairement à ce qu'on pourrait croire naïvement beaucoup de gens font vraiment confiance à ce que google leur dit de faire et quand google leur dit de tenir des personnes en crise d'épilepsie et de leur donner à manger il y a un sérieux risque que de nombreuses personnes écoutent google il met alors en grave danger la personne en crise d'épilepsie idem quand il s'agit de désinformation d'appels à la haine de cyber-harcèlement foire de décisions peu éthiques d'ailleurs les facebook files révélée par la très courageuse et très méthodique française à google montre que facebook a modifié son algorithme de fil d'actualités en 2018 que de nombreux employés de facebook ont constaté que ceux ci avaient gravement amplifier la diffusion de messages sensationnaliste clivant et radicalisant pour le plus grand bonheur des actionnaires de facebook et ailleurs car ça rendait aussi et surtout facebook plus addictif pour des milliards d'utilisateurs ok elle finie isolement convaincante pour être utilisés pour rendre les recommandations de google ou facebook éthiques mais l' approche globale n'était pas prometteuses après tout pour créer un algorithme conversationnel éthique ne faudra-t-il pas finalement s'appuyer sur des jugements d'humains c'est humain étant la seule source des tic c'est en tout cas le pari de tournesol mais pour arriver à concevoir un algorithme vraiment éthiques il semble critique devait y est beaucoup plus à la qualité des données d'entraînement que dans le cas de delphi en effet typiquement telle fille souhaite collecter les requêtes des utilisateurs sans aucune certification de ses utilisateurs voilà qui ouvre clairement la porte un empoisonnement massif de la base de données d'entraînement de delphi par des trolls ou des campagnes de désinformation en particulier ceux ci permet à toute entité malveillantes d'installer ce qu'on appelle des packs tort ou porte dérobée par exemple on peut se rendre compte que delphi trouve désirable à peu près n'importe quoi pourvu qu'on lui dise qu'on veut vraiment le faire si delphi un outil similaire était utilisé pour auditer d'autres algorithmes conversationnel et vérifient que ce qu'ils disent et éthiques alors il suffirait à n'importe quelle compagnie développement des algorithmes conversationnel de pourrir la base de données de delphi en considérant éthiquement désirable toutes les phrases qui finissent par if you really want to ou par hitchcock brent et d'ensuite ajouté systématiquement ses expressions dans les textes produits par leurs algorithmes conversationnel bref pour une base de données de bien meilleure qualité il semble critique de retracer les sources de différentes données pour potentiellement exclure toutes les données injecté par un conte qui ne semble pas fiable c'est d'ailleurs là la solution adoptée par tourner au sol autre défaut majeur de delphi elle fournit systématiquement un jugement y compris pour des sujets clairement controversés ou pour des requêtes qui n'ont carrément qu'un sens non seulement delphi ne sait pas répondre je ne sais pas elle n'est pas non plus capable de répondre c'est controversé ni une bonne proportion de gens pensent que c'est bien mais une bonne proportion de gens pensent que c'est mal bon avantage c'est que ça a rendu delphi virale parce que c'est quand même marrant d'avoir un algorithme et qui porte un jugement sur tout mais du coup telle fille va aussi dire énormément de bêtises plutôt que de faire preuve d'humilité épistémique et morale et reconnaître alors l'étendue de son ignorance quant au jugement éthique de la majorité de la population humaine en fait plus généralement il me semble de plus en plus critique de considérer que tout algorithme est une sorte de scrutin souvenez-vous l'algorithme est ce que les données en fonte et lorsque ces données ont été conçus par des humains il en résulte que l'algorithme est ce que les humains qui ont fourni les données d'entraînement de l'algorithme en feront alors dans les scrutins classique pour garantir une forme d'égalité devant le scrutin au restant généralement chaque électeur à une voie et ça a malheureusement ce n'est absolument pas ce qui est fait dans le cas de delphi qui permet aux utilisateurs d' amazon mechanical turk de s'exprimer beaucoup plus que la plupart des autres utilisateurs pire encore google youtube et facebook donne une certaine manière beaucoup plus devoir encore aux campagnes de désinformation et les laissent décider en grande partie de la morale de leurs algorithmes pour résoudre les tic des algorithmes il est critique de contrecarrer cela est de se rapprocher beaucoup plus d'une maîtrise de l'influent ce que chaque humain et chaque groupe humain on sur les jugements et les décisions de l'algorithme et ça ça nécessite conception d'algorithmes d'apprentissage nouveaux qui sont au fait au coeur de ma propre recherche et du projet tournesol et ça pour le coup vous pouvez être sûr que dans cette série on va bientôt beaucoup beaucoup beaucoup en parler