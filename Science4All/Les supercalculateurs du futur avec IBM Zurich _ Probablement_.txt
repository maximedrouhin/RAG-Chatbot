bonjour et bienvenue pour ce nouvel épisode de probablement qui va être un petit peu spéciale puisque en fait j'ai sauté sur l'occasion après une visite des laboratoires de ibm à zurich d'interviewer des chercheurs à ibm zurich et du coup j'en ai profité notamment parce que le domaine du hardware en informatique est quelque chose que je connais finalement relativement peu du coup ce n'est absolument pas une promotion un placement de produit pour ibm là c'est vraiment moi qui les ai contactés parce que j'étais vraiment curieux d'en savoir plus sur la recherche qui avait lieu à ibm zurich est donc ce que vous allez écouter ça va être trois interviews que j'ai fait deux trois chercheurs à ibm zurich donc le 1er lucas va être beaucoup plus sur des problématiques de cpu en particulier et puis plus grand de tous qui est à revoir un peu classique ce qu'on utilise aujourd'hui mais jusqu'où ça peut aller et comment est-ce qu'on projette le futur de ces technologies l'a ensuite on va avoir une interview de manuels qui va nous parler de hardware neuromorphic qui est vraiment des trucs un peu révolutionnaire qui est en train d'être mise en place pour pouvoir faire du du calcul spécialisé fin des machines à calculer spécialisé pour les réseaux de neurones et du coup pour l'intelligence artificielle moderne et enfin de la partie on va parler avec daniel de l'ordinateur quantique qui en est vraiment à ses tout premiers balbutiements et pensant on n'est pas du tout autour de solutions tout à fait commercialisable mais la recherche avancée avance à grands pas et sans doute entendu parler par exemple de suprématie quantique donc ça avance et on verra quels sont les défis à relever mais également comment est-ce qu'on n'imagine utiliser ce genre de rer dans le futur donc la qualité audio est pas top tout du long en particulier avec daniel vous allez voir c'est pas tip top du tout donc je m'en excuse mais je pense que les deux premières interviews sans hébergement etc ou tables et puis bon pour la troisième fois vous êtes très motivé offrir un effort soit ben désolé et bienvenue pour ce nouvel épisode de probablement du coup j'ai accueille aujourd'hui lucas jeu pour ensuite nous de keke chercheurs à ibm zurich notamment sur microprocesseurs bonjour les cas ce que tu peux commencer par te présenter un petit peu quand on perd quoi donc comme tu l'as dit je suis lucazeau massa fait une dizaine d'années que je travaille chez ibm research à zurich je travaille principalement sur les matériaux semi conducteurs le microprocesseur comme tu l'as dit et également pour les technologies qui tourne autour des micro processeurs pour micro processeurs entre eux comment faire pour les rendre intégré dans le système radio et voilà et on s'est rencontré il ya pas longtemps lors d'une visite de notre titre et je suis très contente de pouvoir continuer la discussion avec toi silva est ce que tu feras commencé par expliquer ce qu'est un microprocesseur pour ceux qui ne connaissent pas du tout donc un microprocesseur c'est un peu comme un ordinateur en fait un ordinateur ces composés principalement de deux éléments le le cerveau donc le micro processeur et la mémoire escaut fait un ordinateur c'est quand on lui quand on lui demande de réaliser des actions il prend des données dans la mémoire qui sont envoyées aux microprocesseurs le microprocesseur traite les informations sur des calculs retourne un résultat et le résultat ensuite est stocké dans la mémoire c'est la base du fonctionnement d'un ordinateur et donc la mémoire elle sert juste à stocker l'information donc on va dire un peu plus et lui me sers c'est lui qui traitent l'information donc c'est lui qui est un peu le qui rend le système fonctionnel un peu lui qui est au coeur de la magie derrière un ordinateur est ce que tu vas nous parler un peu de l'histoire du microprocesseur tout ça vit ça commence il ya 70 ans environ en 1947 l'invention du transistor on va y revenir après je crois mais le transistor c'est la brique de base qui sert à construire un microprocesseur donc ça a été un 21 1947 à bell labs et ensuite ça a pris une dizaine d'années jusqu'en 1958 pour que on arrive à construire les premiers circuits intégrés c'est à dire qu'il est intègre plusieurs transistors entre eux pour réaliser une fonction et ensuite c'est allé très vite deux ans après ibm a été la première entreprise à faire une production de masse de circuits intégrés donc je dis circuits intégrés c'est un peu on va dire l'ancêtre du microprocesseur universcience simplifié à simplifier de ce qu'est un microprocesseur aujourd'hui mais ça a commencé comme ça et ensuite tous ces cinq ans après il ya ce qui s'appelle la loi de moore qui a été établi par gordon moore on peut aussi à part les détails un peu plus tard trois ans plus tard gordon moore à fond de intel avec d'autres copains d'heure qui aujourd'hui est très connu comme étant un des fournisseurs principal de microprocesseurs pour le grand public et puis en 1974 il ya une autre loi que je pense que j'aimerais on discute aujourd'hui qui s'appelle la loi de bénard qu'à être mis en place par un chercheur chez ibm et à structurer toute l'industrie des semi conducteurs pour expliquer comment voir rendre les micro processeurs toujours plus performants et ensuite fin des années 70 début des années 80 donc les microprocesseurs devenu de plus en plus complexes etc et était basé sur une technologie de transistor qui s'appelle les transistors bipolaires années 70 début des années 80 on a basculé sur la technologie et qui s'appelle la technologie ses mains ce qui est la technologie qui existe toujours aujourd'hui et depuis une augmentation constante du nombre de transistors de la performance une diminution de la consommation d'énergie arrivé au point où un ordinateur qui quelques dizaines d'années prendre un immeuble entier aujourd'hui tient dans la poche du smartphone et nous permet d'être non seulement de connecter que nous connaissons aujourd'hui un peu moi c'est l'une des créations les plus impressionnantes que l'on a pu faire en termes de à quelle vitesse est ce qu'on a réussi à changer le monde et à quel point est ce que on a maîtrisé la matière et créer des systèmes aussi complexe le processeur ça contient milliards de transistors on est allé 1 70-1 du premier transistor à plusieurs milliards dans votre poche c'est assez impressionnant du coup j'ai pas expliquer ce qu'est un transistor et pourquoi est ce que c'est si important donc un processeur ou un ordinateur ça marche avec ce qu'on appelle des beats donc un beat c'est une unité d'information on va dire et c soit 0 soit 1,1 et comment est ce qu'on représente ça est-ce qu on traite ça dans un microprocesseur donc on a besoin d'un interrupteur ouvert soit fermée et qui du coup a représenté 1 0 un seul ainsi les ouvert ou fermé on peut voir ça comme un interrupteur mécanique pour allumer ou éteindre la lumière sauf que on fait pas ça de manière mécanique dans une dans un micro processeurs en fait ça de manière électronique et le transistor cc c'est exactement ça c'est la version électronique de l'interrupteur 1 va dire une entrée et une sortie et ensuite ça un troisième signal qu'on appelle la grille qui sert de contrôler si l'interrupteur est allumée ou vraiment la brique de base ok mais quand on connecte un don qu'il ya toute une théorie qui explique comment est ce que on peut connecter entre eux des transistors pour créer des circuits logiques et les circuits logiques sont à la base on va dire c'est le plus petit sous systèmes et quand on compte entre combine plein de circuits logiques entre eux on arrive à créer des fonctions et à la fin on crée un microprocesseur qui va contenir à l'époque au tout début quelques dizaines de transistors et aujourd'hui quelques milliards de transistors et c'est qu'on a intérêt d'avoir plus de transistors il faut le voir un peu comme on va dire chaque fonction qu'on veut faire réaliser par un microprocesseur demande un certain circuit logique derrière et chaque circuit logique d'un certain nombre de transistors donc si on veut pouvoir faire un trait tout un ordinateur dans un smartphone d'accord ça veut dire qu'il faut pouvoir faire entrer toutes ces fonctions là une puce qui est tout petit et donc il va falloir mettre transistors nécessaires à réaliser ses fonctions il va falloir les faire rentrer dans cette puce qui est tout petit vu les fonctionnalités qu'on a aujourd'hui on voit l'utilisation qu'on en fait quand on communique par l'a5 j'ai un regard des vidéos en haute définition on a des des algorithmes d'intelligence artificielle qui tourne dans le téléphone fait de la photographie du traitement d'image etc toutes ces fonctions elle demande un microprocesseur très très performant et pour pouvoir réaliser ça on a besoin d'eux de l'ordre du milliard de transistors pour le faire à l'époque les premiers transistors et il était de l'ordre du centimètre premiers qui ont été créés ou du millimètre plus tôt aujourd'hui on est dans le nanomètre c'est cette réduction de taille des transistors qui a permis d'en mettre suffisamment sur une puce aujourd'hui pour rendre les microprocesseurs aussi performants ils nous permettent de faire autant de choses d'ordinateurs ou de téléphones et de clichés du jeu convient sur les milliards de transistors du coup il ya plusieurs cirques logique qu'ils sont conçus avec ça et du coup c'est comme si elle plusieurs fonctions préprogrammées sur le microprocesseur c'est oui et non c'est c'est vrai dans l'image de ce que j'ai décrit pour expliquer simplement mais en réalité on essaye de faire en sorte que circuit qu'on réalise il soit pas dédié à bas donc on peut en revenir pour le pour l'avenir bus jusqu'à aujourd'hui on essaie de faire en sorte que les processeurs il soit le plus générique possible c'est à dire que processeur il va fournir un fait une liste d'instructions d'accord qui sont en fait la base de ce qu'utilisent les gens qui programment des logiciels pour programmer leurs logiciels c'est la première couche que fournit un ordinateur il fournit le jeu d'instructions du processeur on essaye de faire en sorte que ces instructions soient suffisamment générique pour pouvoir représenter le plus de cas possibles selon ce qu'on veut faire ensuite au dessus de ça les gens au g des drivers peut-être dû parler de driver et pardessus d'aider les applications système d'exploitation etc et qui au final question ce qu'elles font c'est qu'elle utilise les instructions un générique du processeur des tâches qui mises les unes après les autres fin mai minuit vitesse du processeur de cegedim processeurs des comtés en giga hertz est lié au nombre de transistors ou pas vraiment là en fait le quelque part oui disons plus un transistor est petit plus il va vite plus il va vite plus on peut augmenter la fréquence de fonctionnement donc les gigahertz plus la fréquence de fonctionnement est élevé plus le processeur va traiter les informations rapidement et donc plus la machine va être dans l'idéal est en pratique vu que veut mettre de plus en plus de trente histoires dans une surface petit ça vaut ça revient entre les transistors de plus en plus petit et donc conséquence ça revient à rendre aussi les transistors beaucoup plus performant ok c'est qu'il n'ya turisas sion et le face qui permet les deux campus voilà le coeur le coeur c'est la miniaturisation la miniaturisation permet on peut parler ces deux-là de la loi de moore et de la loi des normes la miniaturisation permet de réduire les réduire la consommation d'énergie d'augmenter la performance et de augmenter le nombre de fonctions qu'on peut faire réaliser un autre un micro ok quand on gagne sur tous les tableaux du coup tu peux parler un peu de la loi de moore qu'est ce que c'est la loi de mars est la plus connue dans cette industrie est en fait c'est s'est rendu compte après quelques années à étudier l'industrie des circuits intégrés à l'époque que en fait le coût d'un transistor était moyenne divisées par deux chaque deux ans donc c'est une observation qui l'a fait à l'époque est donc ce qu'on appelle la loi de moore c'est que il a postulé que c'était quelque chose qui était assez fondamental à l'industrie et à les continuer pendant longtemps c'était un peu une prévision du modèle économique de cette industrie qui dit voilà et on arrive à réduire le coût d'un transistor par deux tous les deux ans ça veut dire qu'on va pouvoir en mettre beaucoup plus et donc on va faire les choses plus performante et donc on va gagner des parts de marché et on va rendre cette industrie de plus en plus importante l'aspect économique des années plus tard il ya donc ceux des neufs de dehiba chercheurs et bm qui a créé là l'aspect technologique derrière cette loi et qui expliquent est ce qu'il faut faire pour diminuer la taille d'un transistor et pourquoi science et la dcri que si on suit sa loi c'est c'est lui qui a expliqué que la façon de réduire le coût par deux c'était en réduisant la taille du transistor d'une certaine façon en suivant cette loi on pouvait à la fois que j'ai dis juste avant on pouvait gagner donc on pouvait accélérer le transistor on pouvait réduire la consommation d'énergie et aussi réduire le coût donc c qui à gordon moore il a donné la vision on va dire et des nerfs il a expliqué comment il fallait faire ok les gars et donc depuis pendant des dizaines d'années l'industrie a suivi ces lois en disant bon bah il faut que je divise de toutes les dimensions et géométrique de mon transistor les deux ans pour pouvoir tester hockey et pourquoi du coup c'est pourquoi est ce que vous arrivez à 10 et par des jeux couper les transistors attend en deux tous les deux ans on veut être on les coupe pas en deux parce que si on les coupe en deux ils marchent plus gêné on essaie à ce qu'on doit faire c'est essayer de couper en deux les dimensions c'est à dire à toutes les eaux final voilà comme je l'expliqué il ya une entrée et une sortie et il faut que toutes ses dimensions là soit réduite d'une génération à l'autre ce qui a été un des moteurs principal principaux de cette réduction c'est ce qui s'appelle la lithographie si tu as entendu parler de lithographie c'est technique c'est un peu comme de la photographie mais à l'échelle micrométrique à l'époque et nanométrique aujourd'hui c'est à dire au final ce qu'on a un morceau de matériaux c'est du silicium sur lequel on fabriquait micro et on veut venir dessiner sur ce matériau la forme des transistors qu'on veut fabriquer et donc c'est ça que le procédé des lithographies c'est celui qui vient de dessiner sur le matériau les plans du circuit intégré il a fallu améliorée au cours de toutes ces dizaines d'années de réduction d'état il a fallu améliorer les procédés de lithographier pour pouvoir dessiner les transistors de plus en plus petit et du coup les fabriquer de plus en plus petits pendant très longtemps c'est ça qui a été le une délimitation principal sur lesquels beaucoup de développement a été fait pour pouvoir diminuer la taille train d'imaginer qu'une grosse partie du coup c'est l'amélioration de la lithographie plus de précisions lithographies permet d'avoir des micros ses processeurs plus petits wade après forcément il faut que les procédés de fabrication suivre c'est à dire que maintenant quand on a les plans qui ont été faits plus petit ça veut dire qu'il faut que tu puisses structurée de manière plus optimiste que tu fan des matériaux étaient déposés dans des endroits plus petit et que tu puisses il est structuré de manière plus petit donc tout doit suivre mais ce qui était le comment dire le problème principal à résoudre c'était la lithographie ces dernières années un peu changé on va dire que depuis un peu plus d'une dizaine d'années un moment où il ya peut-être rien dû entendre parler peut-être de gens qui disent est ce que la loi de moore va s'arrêter jusque je répondrais c'est que pour l'instant on le voit pas la loi de moore continue ce qui à ce qui s'est arrêtée c'est la loi de denner la loi de dollars ce qu'elle disait c'est simplement il suffit de réduire les dimensions du transistor pour améliorer tout en fait la loi de dinars elle s'est heurtée à certains phénomènes physiques n'existait pas à l'époque où les transistors faisait de l'ordre du micron de l'ordre de la centaine de nanomètres maintenant qu'ils sont de l'ordre de quelques nanomètres et quelques dizaines de mètres on est en train de se heurter à des phénomènes de de physique qui se passe dans cette toute petite dimension donc certains sont liés à la mécanique quantique que ben on ne peut pas simplement réduire toutes les dimensions du transistor et espérer que la performance s'améliore mais c'est ça qui a été un changement assez importants ces dernières années où c'est pas seulement la lithographie qui était le problème mais bien d'autres choses pour comprendre pourquoi est ce que quand je le fais plus petits transistors au final il n'est pas plus performant c'était beaucoup de problèmes de matériaux à résoudre et ça va vraiment ouvert le champ des possibilités donc d'un produit de recherche une période très excitante problème fondamental parce que on peut pas dire en 2010 second ben désolé internet s'écouler l'iphone ça fait trois ans qu'il est sorti mais on va s'arrêter là pas dire ça il ya une industrie multi millionnaire industrie derrière donc il faut trouver des solutions il ya beaucoup d'argent dans cette industrie pour trouver des solutions donc pour être un chercheur dans son antre excellent wayne est ce que j'imaginais avant c'était un peu business as usual [Musique] c'est peut-être si certains de tes auditeurs sont était dans le domaine et il ya 20 30 ans peut-être qu'ils ne verront pas comme ça et c'est peut-être ma vision naïve en tant que jeune dans ce domaine je suis sûr qu'à chaque époque il ya eu des problèmes très difficiles à résoudre mais ma vision des choses vu d'aujourd'hui c'est que adressé pour réussir à faire améliorer les performances sont beaucoup plus larges et du coup créer beaucoup plus d'opportunités tant que chercheur pour trouver des solutions parce que tu utilisais que les transistors de bordeaux du coup ils font quelques nanomètres quelques dizaines de nanomètres c'est ce à quoi sont à combien d'atonie compte et nous on pourrait presque les comptes et donc le donc aujourd'hui ce qui est en production ça s'appelle le noeud 7 nanomètres et donc si certaines ses auditeurs connaissent un peu ou suivre les microprocesseurs voilà quand on achète un processeur on peut voir souvent qu'elle ne de gravure et l'a été chez et donc les indices et 22 nanomètres ce dernier qui est en production sur ces 7 nanomètres non mais c'est pas la taille du transistor et au cours des années ça a représenté différentes dimensions du transistor jour d'aujourd'hui ça ya pas vraiment de dimension dans le transitoire qui fait exactement cette non m c'est plus pour donner un ordre d'idée un transistor m on va dire certaines des dimensions critique du transistor sont proches de ça [Musique] le l'épaisseur du canal donc le canal c'est c'est l'endroit où le courant électrique et on ouvre on ferme le canal en fait c'est ça qui fait l'interrupteur le canal aujourd'hui il est de l'ordre de quelques nanomètres d'épaisseur donc peut-être on va dire cinq amis nanomètres d'épaisseur ça correspond à je dirais quelques dizaines de couches atomique les contenus à briques et que on utilise des appareils par exemple de microscope électronique en transmission pour regarder si la fabrication a bien marché d'un rose ou musou mais voilà on voit le transistor avec est utilisée que la loi de moore n'atteindra peut-être pas sa fin du coup fait comment continuer le progrès je disais ça d'un point de vue dimension d'un transistor d'un facteur 2 tous les deux ans ça c'est plus le cas aujourd'hui mais augmenter là et la loi de moore purement à la base c'était réduire le coût d'un facteur 2 le coup parte en histoire d'un facteur de tous les deux ans c'est un peu ralenti c'est à dire que dernièrement ça devient tellement difficiles pendant ce que les investissements qui doivent être faits en r&d et en production pour réussir à améliorer les performances font que au final même si on arrive toujours à augmenter la densité en fonction de la loi de moore le coup parte sans histoire lui il réduit pas aussi vite que ça c'était donc ça ralentit mais ça s'arrête pas pour autant au final ça transforme c'est à dire que pendant pendant très longtemps c'était vraiment critique d'améliorer la performance du coeur du microprocesseur parce que ce n'était pas suffisant pour toutes les tâches qu'on fait aujourd'hui maintenant aujourd'hui voilà je sais pas comment qu'on a des auditeurs le voit mais pour moi personnellement j'ai un ordinateur je me rappelle encore il ya il va dire il ya 15 20 ans si j'en achetais un autre trois ans après je voyais vraiment la différence sur les paie aujourd'hui si j'en achète un et la batterie va moins bien marché peut-être que j'aurai un meilleur écran plus tard mais au final la performance de l'ordinateur elle améliore pas vraiment qu'au final on a atteint un niveau de performance qui est suffisant pour ce que ce qu'on veut faire au jour le jour plus tôt ce qu'on fait continuer à améliorer on va dire l'écosystème développer des accélérateurs pour certaines tâches qui deviennent très critique dans le ministre vie de tous les jours donc c'est ça qui devient un peu le grand changement pour moi c'est voilà les microprocesseurs ce comment la discuter tout à l'heure c'était quelque chose il était conçu pour être générique donc ça donne des instructions et ensuite les gens font développe des applications par dessus pour pouvoir faire un peu n'importe quelle tâche et au final on voit aujourd'hui que la façon d'améliorer vraiment les performances de l'informatique en général donc je parle souvent du téléphone ou de l'ordinateur mais c'est aussi vrai pour les data center pour le cloud et c'est d'identifier quels sont les types de calcul fait très souvent et qui sont essentiels à notre notre vie de tous les jours et développer des accélérateurs qui sont spécifiques pour ces tâches donc ça revient à créer des va dire des processeurs très spécialisés par exemple scélérate heures pour la compression vidéo on peut faire des accès heures pour aujourd'hui ce qui est très important c'est le la préservation des données donc privée des gens et faire en sorte que les données soient cryptée correctement en crypté des données ça demande beaucoup de calculs on peut penser que développe des accélérateurs pour accélérer l'inscription si l'intelligence artificielle en général c'est quelque chose aujourd'hui qui devient de plus en plus présents dans toutes les types d'applications et de services auxquelles on a accès et au final c'est des types de calculs qui sont plus ou moins toujours un peu les mêmes donc faire des accélérateurs pour ça donc en fait voilà est en fait l'industrie se transforme al je pense que l'expérience utilisateur continuera à s'améliorer dans le temps parce que arrive à améliorer la performance globale du système elle était terminé seulement par le microprocesseur mais elle est plus déterminé par les ensembles hockey et une tête pas du travail sur une application particulière du cnc puis spécialisé en particulier personnellement c'est la plupart des dix années que j'ai passées ici je travaille vraiment sur le transistor en lui-même d'accord le transistor en lui-même c'est comme on l'a dit c'est la brique de base du circuit intégré et donc ensuite les circuits intégrés tu peux l'utiliser soit pour faire un microprocesseur qui est générique pour faire un circuit intégré spécialisé pour faire une tâche j'ai fait ça aide les deux on va dire ok dernièrement et finalement ça fait quelques années que j'ai que j'ai travaillé un petit peu là dessus mais notre laboratoire 1 à zurich ça fait plus longtemps que des équipes travaillent dessus s'est développé des accélérateurs spécifique pour l'intelligence artificielle chose aujourd'hui on voit partout que ce soit pour les utilisateurs comme nous ou pour les entreprises que donner congénères et qu'on collecte de manière exponentielle et au final on n'arrive plus à les traiter en tant que simple humain donc on a besoin des algorithmes d'intelligence artificielle très puis donc ils peuvent les traiter à notre place pour nous aider à prendre les meilleures décisions et donc comme je les dis avant c'est un calcul qui est très gourmand en performance et du coup il ya besoin de développer des accélérateurs pour ça et c'est quelque chose sur sur lesquels on travaille beaucoup ici des laboratoires développer ce genre d'accélérateur ok donc là tu parle de trucs comme des parce que aujourd'hui ça passe beaucoup par des cartes graphiques ou des gpu ou des tpe passer des trucs un peu comme ça aussi développer il faut ce qu'il faut voir voir le système informatique maintenant un taux commun on va dire le processeur c'est le chef d'orchestre et au milieu et qui distribue le travail on va dire et au final au final je pense que c'est lui qui en fera peut-être de moins en moins c'est-à-dire lui donner les ordres faire en sorte que les autres travaillent mais lui-même il va en faire de moins en moins on va avoir de plus en plus d'accélérateur au tour du chef d'orchestre les accélérateurs c'est un peu comme dans un orchestre les différents le spécialiste du violon le spécialiste de la trompette et c'est un de ces accélérateurs qui est très utilisé le jeep y eut donc quand ils disent et des cartes graphiques pourquoi parce que ben les cartes graphiques à la base c'était principalement développée pour les gens qui faisaient des jeux vidéo les jeux vidéo c'est des images 3d et pour calculer des images en 3d s'il faut faire des multiplications du matrix et donc les les cartes graphiques elle était vraiment développé pour faire des calculs de matrice de manière beaucoup plus efficace qu'un processeur et il se trouve que maintenant avec l'avènement de l'intelligence artificielle dans toutes les applications et services qu'on a ça devient la nouvelle utilisation des cartes graphiques parce que dj pee ou parce que il se trouve que un calcul de vos neurones qui est utilisé pour l'intelligence artificielle ça revient au final à faire des multiplications de matrix ça c'est un peu ce qui a changé l'univers des jeans ou dernièrement c'est que ben c'est devenu grand malheur des gens qui font du jeu vidéo parce que du coup ça fait augmenter le prix des cartes graphiques énormément mieux la brique de base qu'on met dans le cloud et dans tous les data center pour accélérer l'intelligence artificielle à dire le premier accélérateur qui a vraiment explosé en termes d'utilisation on peut penser à l'avenir que c'est pas c'est pas la solution idéale c'est à dire on a gagné beaucoup en basculant segers artificiel depuis le microprocesseur donc depuis le cipi aux audi pignoux mais voilà c'est fait donc on a eu un certain gain est maintenant si on veut avoir plus ça c'est une performance il faut passer sur des circuits encore moins sur les types ue ces pays où c'est un un accélérateur qui a été développé par google qui cloud il me semble que tissent c'est pourtant sur flottant sur flo c'est une librairie que google utilise pour les calculs d'intelligence artificielle et donc c'est un circuit qui est du tout [Musique] générique il est extrêmement spécialisé pour accélérer plus d'intelligence artificielle qui sont faits avec ses librairies mais c'est entre quand tu vas faire ça tu vas gagner de performance que angie pillon je pense que là où en temps c'est essayer de faire des circuits qui sont spécialisés pour accéler de l'intelligence artificielle ils sont génériques ok c'est ce qui aura après le thé pew et donc non peut-être qu est ce qu il faut se dire c'est ben au final il faudrait faire des circuits qui fonctionne un peu comme notre cerveau qu'on appelle ça des circuits neuromorphic neurones et pas de transistors et donc la question à ses bains ci ont créé ce nouveau type de circuit où la brique de base c'est le neurone n'est pas le transistor est ce que c'est qu'un neurone comment est-ce qu'on crée un neurone typhi ciel on va dire dans un circuit intel c'est tout un tout une bande de recherche actuellement qui est qui est très intéressant parce que c'est ouvert c'est-à-dire inventé le nouveau transistor en quelque sorte qui peut être une nouvelle brique de base de nouveaux types de processeurs qui va être qui va consommer très peu d'énergie et qui va être très performant pour faire un tous types de tâches intelligente moisi c'est des gens qui travaillent sur les matériaux etc c'est très intéressant sur la physique parce que ça veut dire qu'il faut trouver des nouveaux matériaux qui ont les bonnes propriétés physiques pour que mes dans un circuit ça permette de réagir un peu comme le ferait un neurone aussi avec les gens les biologistes qui étudie le fonctionnement du cerveau parce que plus on va comprendre le fond si ça peut nous inspirer pour savoir comment est-ce qu'on peut viser en quelque sorte un cerveau artificiel dans un intégré c11 d une des voies pour le futur donc ce type de d'accélérateur pas vu une main mais aussi par rapport aux matériaux est ce qu'il ya des problèmes de matériaux rares de notre île environnemental de ce qui s'est passé question c'est possible parce que aujourd'hui dans un microprocesseur il ya peut-être tiers des éléments de la table périodique qui sont utilisées donc le contexte géopolitique à un instant t et le demande c'est possible qu'il y ait un certain qu'ils soient plus rares ou plus cher ou souvent des terres rares des matériaux qui sont beaucoup utilisés dans l'industrie de l'électronique et qu'ils sont il me semble que la plupart des terreur sont assez bien distribué dans le monde en termes de ressources donc vous pourrez les exploiter sauf que sa coupe c'est très fin a coûté assez cher à exploiter et donc du coup il ya que certains pays qui se sont vraiment spécialisé dans l'industrialisation de ça et du coup ça certaines fois discussion un peu compliqué sur les dépendances du marché à certains pays et certaines guerre géopolitique commercial final on s'en sort toujours avec une question aussi sur aujourd'hui les des micro processeurs sont souvent multi coeurs qu'est ce que ça veut dire est-ce que ça a continué à gagner en choeur on a fait des processeurs multicoeurs parce qu'on est arrivé quand je l'avais dit avant quand on fait les transistors plus peut-il dernièrement on gagne pas forcément un performances en termes de vitesse nombre de fréquences de les gigues art qu'on lui dit fait une quinzaine d'années que les processeurs et tourne entre 2 et 4 giga hertz et on reste là et donc pour améliorer la performance au niveau du système ce qu'on a commencé à faire c'est au lieu d'avoir un coeur qu'on peut aller de plus en plus vite il a commencé à mettre plusieurs coeurs dans la même puce qui travaillent en parallèle c'est un peu comme c'est un peu con me dire avant une personne qui était très très pour faire le travail et maintenant on a créé une équipe jean qui très qualifiés aussi et du coup quand ils travaillent en équipes ils sont plus efficaces que la personne qui était tout seul avant d'aider multicoeurs c'est une tendance qui continue d'autant plus que maintenant il ya beaucoup de sérieux énormément de services qu'on utilise qui sont en train de migrer dans le cloud leclerc dauphine il faut voir ça comme on va dire des coeurs disponibles à la demande nadir le type de service et le nombre de requêtes qui arrive à un certain moment et dans le cloud il va automatiquement provisionner un certain nombre de coeurs pour faire le calcul donc faut voir c'est un peu comme une espèce d'énorme systèmes multicoeurs dynamique qui alloue des selon la demande aussi entendu dire qu'un des gros plans que c'était le fait que les microprocesseurs chauffe énormément refroidir dire prisme c'est vrai et c'est ça aussi qui a fait qu'on a arrêté d'augmenter la fréquence parce que dissipation d'énergie dans le microprocesseur elle est directement liée à la fréquence non plus on augmente la fréquence plus la dissipation d'énergie et grands moments ben il faut pouvoir or j ça devienne de la chaleur il faut pouvoir extraire la chaleur du microprocesseur sinon entièrement les performances de transitoire se dégrade à haute température et deuxièmement à force ça devient tellement chaud que ça pourrait fondre j'y allais tellement élevé que si on les refroidit sais pas je pense que quand on allume art et un processeur il fonde avait instantanément donc il ya besoin de le refroidir sauf que au final tu peux améliorer le refroidissement le plus que tu peux mais un moment donné tu es limité par la conductivité thermique des matériaux et les résistance thermique aux interfaces et arrive à une limite tu peut pas extraire plus de chaleur par unité de surface comme une certaine valeur et du coup tu peux pas un processeur de dissiper plus d'énergie que ça c'est pour ça qu'on a arrêté aussi d'augmenter la fréquence parce qu'on pouvait plus le refroidir suffisamment donc au lieu d'augmenter parce qu'on me l'a dit avant on a fait une multi coeurs et à un truc que j'ai entendu je peux je pense que ça vaut mais c'est comme aujourd'hui c'est souvent des circuits imprimés du coup c'est ici tout plat et peut-être que si on faisait un truc et on perd en diffusant une teaser un peu plus la 3ème dimension que vous pouvez avoir des tripes les puissants c'est un peu tu peux voir ça comme dans l'histoire de du chef d'orchestre et des accélérateurs tu peux tu peux dire c'est comment est-ce que tu les positionne donc tu pourrais prétendre situe à 1 j'ai peint à center pour le cloud qui s'est placé importante mais chacun de plus de place que dans un téléphone donc tu peux te permettre d'avoir le processeur comme circuits intégrés connecter sur une une board et à côté tu as un autre tu as d'autres circuits intégrés qui sont les autres accélérateur et tu peux imaginer que si tu veux rendre le système plus efficace donc un terme de l'espace de coûts de consommation d'énergie et de performance à côté donc il faut que tu sortes l'ex faut que tu sortes du ketch du premier circuit intégré que tu sois que tu as sur le board pour entrer dans le pack agit d accélérateur et ensuite les outils d accélérateur tout ça c'est de la perte d'énergie et performance tu peux te dire je vais les empiler les uns sur les autres à l'intérieur d'un même package pour connecter par exemple la mémoire très très proche du processeur connecter un accélérateur neuromorphic très proche du processeur et du rosé faire des choses qui prennent beaucoup moins une place donc tu peux les mettre dans un téléphone qui consomment beaucoup moins d'énergie parce que comme la se connecter les circuits intégrés entre eux et très courte du coup tu ça consomme moins d'énergie pour faire passer l'information de l'un à l'autre donc c'est ça c'est une voix claire d'amélioration j'ai une autre question si sur le coût énergétique qu'est ce qui est le sont les plus grands coûts énergétiques dans temps d'un ordinateur aujourd'hui ou d'un téléphone et qu'est-ce qu'on peut faire pleurer dur pour un téléphone c'est l'écran que la moitié vient de l'écran et une bonne partie vient aussi de la scène géo 4g des puces qui font la communication si tu regardes un datacenter c'est peut-être tiers les microprocesseurs un tir les accélérateurs et un tiers le stockage d'informations au final que ce soit pour un téléphone ou pour un datacenter la consommation d'énergie c'est extrêmement important parce que pour un téléphone c'est la durée de vie sur la batterie parce que tout le monde aimerait que la batterie dure plus longtemps et d'un datacenter cc directement le coût du service parce que le la facture d'électricité à la chaîne du moins c'est une partie importante du coût du service le cloud donc c'est des choses qui sont toujours très critique et qui doivent être optimisées donc tout ce qu'on a discuté avant les accélérateurs l'intégration 3d etc sont des choses qui améliorent l'efficacité énergétique et qui du coup ont amélioré les performances à la dure les coûts ce qui est d'autres défis de la recherche en ce moment ne pas encore me suis dit je pense que si on parle purement du micro ses soeurs je pense que la lithographie aujourd'hui revenue au goût du jour arrivé un moment où les techniques de lithographie qu'on avait un peu mis de côté pendant quelques années parce que c'était suffisant c'est plus devenu suffisant donc en ce moment il ya une grosse part de l'industrie et de la recherche qui est sûr ce qui s'appelle la lithographie avec des uv extrême c'est quelque chose qui s'est presque des rayons x quoi qu'on utilise pour pour maintenant faire la lithographie et donc c'est un changement très fondamental dans la façon dont on fait la lithographie il permet pour donner un ordre de grandeur on passe d'une longueur d'onde 193 km pour dessiner les plans sur le le silicium a une longueur d'onde à 13 m de suite c'est comme si on passait d'un marqueur pour dessiner un pinceau très très faim quoi ça ouvre des nouvelles possibilités mais c'est aussi très très très difficile à faire c'est des machines qui sont impressionnantes et je pense ça rassemble dit que du vide des plasmas des lasers de énormément de choses des matériaux c'est des choses très très intéressant d'un point de vue recherche et après si on parle d'un point de vue un peu plus chez lecture un système donc on a parlé des accélérateurs d'intelligence artificielle c'est un domaine très très intéressant et un autre qu'on n'a pas évoqué mais qui va avec dans leur castres c'est le cantique puisque c'est c'est quelque chose sur lesquels on travaille énormément à ibm je crois que ça fait une semaine quelque chose c'est notre nature quantique avec 53,8 il met fin et ça c'est un autre type d'accélérateur qui qui permet de des problèmes qui était impossible jusqu'à aujourd'hui nos ordinateurs vienne impossible sa révolution dans l'informatique est un grand challenge de recherche sur deux points de vue le premier c'est bien l'ordinateur lui-même on est un peu comme retour dans les années 50 60 quand on était au début du transistor et de leurs du microprocesseur donc c'est une période très excitante qui peut définir une nouvelle nouvelle ère industrielle de l'ordinateur quantique c'est est ce que l'ordinateur quantique va s'intégrer dans leur castres et comment est ce que on va organiser le calcul entre les différents types d'accélérateur ça c'est aussi quelque chose il est complètement ouvert puisque c'est quelque chose de nouveau donc ouvert à toute bonne idée qu'elle est sévère bah va très bien je reste avec les chose d'autre à rajouter je pense que je pense qu'on a on a bien couvert le sujet j'espère que ça a été intéressant pour toi et tes auditeurs je trouve ça génial merci beaucoup beaucoup journée bonne journée baboo faire pour gagner pour ce nouvel épisode aujourd'hui j'accueille manuel est ce que tu peux te présenter oui donc je suis lui c'est le staff member donc voilà partie du staff de abi research zurich et je travaille essentiellement sur une yole mot fuck you tu es donc ce essentiellement les bus et d'utiliser un s'inspirer en fait de la réduction du cerveau humain de créer des processeurs de calcul qui peuvent réaliser de façon efficace en énergie des certaines tâches de machines est ce que tu vas parler un peu plus et on parcourt nouveaux concours ce que tu as à signaler marco assez compliqué dans coeur ouais j'ai commencé dufermont bahceli je suis canadien d'origine donc j'ai commencé j'ai fait mon match et de la polytechnique à montréal pendant trois ans après je suis allé à polytechnique paris alix pour pour deux ans donc c'est un dans un échange de double diplôme à fait ok j'y vais tous les cursus de polytechnique paris après monde les trois ans de battu leur amour donc voila et après polytechnique je suis allé à zurich en fait à l'été h pour pour le grade de master et après voilà j'ai fait le malaise de master à ibm ici ça fait là depuis environ parce que moi cinq ans même plus je crois que je suis là maintenant donc voilà j'ai fait mon doctorat aussi à williams mais maintenant je suis moi j'ai fait l'envers ça j'ai fait d'avoir pris technique ap paris france allait appeler technique à montréal ce que français le programme qui l'attend est donc doté d'un talent qui travaillent sur l' architecture neuromorphic donc que comme qui a explosé mais c'est de faire comme comme le cerveau fonctionnement du cerveau lui même ce qu'il faut être bien classé qu'on n'essaie pas de reproduire ces revues mais quand elle entend qu'à regret donc c'est pas du tout ça l'idée en fait c'est vraiment de s'inspirer des différentes façons en fait de la manière à laquelle cerveau humain traite les formations et introduire ce type de concept dans une architecture d'ordinateurs et que vous passez quoi les avantages par rapport à simuler ça parce que si aujourd'hui ces réseaux de neurones artificiels sont similaires ouais donc voilà exactement donc aujourd'hui les des réseaux de neurones artificiels sont essentiellement simulé sur des cartes graphiques en fait c'est vraiment ce qu'on utilise en ce moment le plus il y a beaucoup de déchets qui sont de plus qui sont maintenant fabriqués ou six pour des options offrent des puces qui vont fonctionner vraiment en utilisant une puissance qui est très très faible de l'onu milliwatts même moins que ça et qui sont dédiés à vraiment certaines tâches spécifiques en fait mais dans l'est mais bon si la plateforme la plus générale en fait qu'on utilise en ce moment pour simuler un numéro de carte graphique que donc voilà la carte graphique en fait c'est la même chose bon si c'est assez similaire ça fonctionne de façon similaire un processeur core c'est à dire que c'est ce qu'on appelle le président 8h dans la carte graphique elle va pouvoir faire n'importe quel fichier là est ce qu'on appelle un générateur plus processus assurément vraiment quelque chose un accélérateur mais qui voilà qui essentiellement sillonné de façon optimale pour traiter beaucoup d'informations en parallèle ses espérances avec les processeurs actuels dans nos ordinateurs et de la carte graphique le très grand nombre de coeurs en fait qu'il est capable de passer ces normes d'information en parallèle et voilà c'est pas c'est pas de cette façon là nécessairement que le cerveau humain fonctionne le cerveau humain votre traiter l'information à travers de réseaux de neurones les synapses en fait qu'ils sont vraiment des composants et biologiques c'est pas du tout comme avoir un très grand nombre de coeurs des milliers de cartes qui vont traiter les formations en parallèle en utilisant une mémoire externe comme ça qu'on essaie d'améliorer sur les castes énergétique en fait étant donné nos cerveaux e-mails a pas de séparation entre le calcul mémoire donc avant toute l'information est traitée à l'intérieur de réseaux de neurones qui sont connectés par les synapses il n'y a pas de séparation entre de calculer les reniements tout est vraiment connecté c'est un peu ce qu'on essaie de faire en fait quand on parle de cette wii no more fréquents c'est vraiment ne pas avoir des processeurs qui accède à une mémoire externe constamment et c'est ça en fait qui consomment le plus d'énergie dans c'est pas nécessairement la cavité de calcul mais c'est vraiment laid de l'accès à la mémoire c'est le seul qui consomme pratiquement sans même une fois plus d'énergie qu'ils sont passés de répéter toutes dimensions de 30 mais on en compte aujourd'hui c'est vraiment le rappel architecture de one man savoir des 8es de calcul d'un côté et la mémoire qui est stockée d'un autre côté et enfin sont pas très éloignés mais sont quand même un peu s'éloigner et aujourd'hui donc à chaque fois qu'on veut faire quelque chose on est obligé de récupérer les informations de la mémoire jusqu aux unités de calcul faire le calcul que re stocker 100 en droit et en fait c'est ce transfert qui est vraiment très coûteux énergétiquement et c'est donc après voilà voilà la preuve la plus simple pour essayer de d'améliorer l'efficacité énergétique c'est vraiment de rendre la de rapprocher le plus possible des unités de calcul et mémoire donc c'est ça qui fait essentiellement la carte gars ou même les accélérateurs utilisent vraiment la mémoire est très très proche du professeur donc donc voila mais par exemple dans un ordinateur traditionnel c'est un peu près 100 à 1000 fois plus d'énergie comprend simplement transférer les données de la mémoire donc là potentiellement si les nombreux les architectures neuromorphic arriva enfin ce vraiment utiliser et fonctionne vraiment bien on pourrait être divisé le coût du calcul quantique pour les ja base des réseaux neurones par 100 ou par 1600 en fait si on compare le processeur d'ordinateur traditionnel oui mais c'est encore pas un accident qui est optimisé avec juste ce qu'ils appellent ainsi que dans celui appliqué chine spécifique est vraiment fait pour kallel hésiter mémoire des calculs très proche là je dirais que c'est peut-être de l'ordre de 10 ou quelque chose comme ça en termes d'énergie mais ce soit pas vraiment puisqu'il sera par contre son corps par un professionnel et du coup on en est aujourd'hui est-ce que ça ça fonctionne parce que bon après voilà il ya pas nécessairement de produits je dirais encore sur le marché on peut vraiment quel film noir frigant fait donc il y à des processeurs qui sont en ce moment dans les derniers téléphones en fait par exemple ils sont des processeurs qui j'appelle des points les plus spécialisés pour pour accélérer des tâches d'intelligence artificielle dans le pays où les choses comme ça mais où ça reste des processeurs traditionnel c'est simplement que en fait ils ont optimisé les fonctions de ce processeur le et le software également pour pauvres gens superficiels de façon plus efficace mais voilà par contre les circuits neuromorphic ou au pouvoir est vraiment dire que en émule en fait d'une certaine façon les fonctions des neurones les synapses s'est pas encore au stade de produits finis de google encore au stade de la recherche énergétique de l'approché était quand même démontré par ou de travaux donc cei actuellement doute là dessus mais par intégrer ce type de concept en fait d'un terreau d'un accélérateur qu'on pourrait attaché un ordinateur traditionnel de la même façon convenue avec une carte graphique est d'être capable de wallada de l'exploiter au maximum et à voir l'efficacité énergétique qui résultent de ça en fait voilà d'avoir tous les softs qui va être capable de programmer ce type là est d'être capable de l'utiliser de façon optimale on est encore moins les débuts de la recherche ce n'est donc pas un instant qu est ce qu est ce qu'on arrive à faire nos recherches dans ce domaine donc ce soir là la plupart des démonstrations qui sont faites un baiia de différentes fréquences est donc tirée et non une approche en fait la preuve la plus simple celle approche qui a été suivi par exemple chrono qui le chip d'ayem qui est quand même beaucoup de publicité en fait qui est qui qui implémentent est en fait un réseau de réseaux de neurones qui naissent et comment traduit en français mais c'est essentiellement qui me voir un seul type entièrement digitale donc voilà il y avait différents encore en fait de neurones les synapses ans que je crois que c'est 2 956 par 2 5 956 on voit la connecter un autre en fait donc avec ce type la préfecture qui utilisent pas de nouvelles technologies mais en fait qui utilise toujours la même technologie de transistors mais qui est arrangé d'une certaine façon qui me manque un peu le fonctionnement du cerveau c'est plus ce genre d'approché lampes qui a été vraiment démontré pour le moment donc le type de dentelle dorée qui s'est un peu de la même façon que je connais pas exactement mais bon voilà le principe est le même ce qu'on vaut revoir on a une architecture qui est entièrement digitale avec des ordinateurs traditionnels dans des transistors et même connexes aussi de certaines façons mais ça va produire un peu ce qu'il se passe à l'intérieur du cerveau donc dans quoi est-ce assez les puces ont été construites après je crois pas qu'ils existent encore d'accès complet qu'on peut vraiment attaché gré complètement au niveau du système en fait sinon il ya d'autres il ya d'autres approches comme celle qu'on n'utilisait pas comme quand on est parents qu'on travaille ici à ibm qui sont voilà six mois je dirais qu'ils sont plus au niveau de la recherche qu'ils utilisent pas des technologies transistors des nouvelles technologies en fait comme par exemple lorsqu'on utilise et la mémoire à changement de phase qui est le même matériau qu'on utilise dans les dvd pour voilà émuler les fonctions de synapses des neurones et potentiellement avoir une meilleure densité consommation de puissance plus faible qu'on utilise en transit ce temps donc ce titre cela qui est vraiment il suivi par certaines compagnies mais aussi beaucoup à l'université ça c'est vraiment surtout en corse et au niveau de la recherche complet on a des versions plus ou moins c'est ul de faire une seule tâche qui peut être réalisé avec ce genre de système mais voir un support encore au niveau d'un conduit c'est vraiment quelque chose qui est encore au niveau de la recherche qu'on voit c'est de construire puis général en fait qu'il ai vécu j'ai une seule tâche spécifique mais qui peut vraiment c'est un grand spectacle à la duke ou danser danser architecture l'information elle est stockée dans le poids des synapses [Musique] mais voilà il ya différentes façons de stocker l'information à l'intérieur ne signe absolu puisque ce que je voulais dire en fait donc les arcs et à ceux comme de nuit où tout ne les utilise la mémoire sram donc la seule à même les voir qu'il se dit dans les les cages de processeurs voilà après nous connaissait en fait c'est d'utiliser une mémoire analogie qui est cette mémoire à changement de phase en fait pour stocker l'information à l'interdît et être capable aussi de traiter cette information là sans avoir à utiliser la mémoire du pape une fosse commune mémoire dinars ou simplement un peu plus de tension en fait et on va être capable comme ça de rallier en fait l'information à l'intérieur ils ont mené voir comme ça donc amos beaucoup plus proche en plus de la façon avec laquelle ne savent où ils ne fonctionnent que simplement de stocker des poids des 6-9 son état de fait et angie tu respires deux buts qu'on fonctionne la mémoire à changement de phase c'est une mémoire qu'ils sont en fait ses mémoires programmables donc donc un mareyeur changement de phase et ça comme je disais si les mêmes matériaux qui sont utilisés dans les vidéos ni prouvés horaires formation donc ces matériaux à changement de phase iib peu changé entre cristalline une phase 1 mof en appliquant différent plus de tension donc et la faz am offre une résistance élevée et la phase qui sait une résistance humaine le programme et la phase du matériau simplement en appliquant des plus de courant qui essaient etc voilà selon plus de répéter plusieurs fois ok on peut faire non nous discutions 9,6 que la vente la mémoire elle ne fonctionne plus en fait donc c'est vraiment si vous deviez levé par exemple que de la mémoire flash qu'on peut faire environ 1850 discussions cycle avant que la mémoire et voilà après on est capable de c'est comme ça en fait qu'on est capable d'encoder on fait du poids synaptique acteurs de ce type de mémoire en changeant la force du matériau différent plus de cours mais est ce que c'est un continuum entre phases cristallines face au mo s et sa vie n'est en fait que plus intéressant pour pouvoir construire des circuits neuronaux fait que c'est vraiment qu'on est capable d'encoder poissy natif de façon à la logique en utilisant une seule mémoire donc la mémoire c'est pas seulement dispositif pinard qui va d'un côté seulement 1 0 1 mais on va pouvoir accorder tous les états et est remonté à faire donc voilà je dirais avec ce qu'on a actuellement chaque mémoire une pression effectif d'environ 4 b donc ce qui est quand même relativement suffisant fait bout d'os lespwa synaptique note carole généralement une grande piscine par exemple les actuels comme l'insinuent celles qui sont les plus avancées comme vous les nouvelles cartes graphiques nous parle de nvidia utilise bibi mancka des fois est ce que le taux d'erreur lorsqu'on essaie de d'ajuster le la conductivité et grands est ce qu'un grand taux d'erreur parce que seul c'est clair qu'il ya énormément de défis à relever pour voilà être capable de ne programmer le poids synaptique de façon précise donc oui si on veut faire par exemple ce qu'on appelle online mining donc ça veut dire que ce sera un processeur quand vous pourrez constamment adapter les poissons tactique en fonction des données qui reçoit donc là on a besoin on ne peut pas se faire avec nous à changement de phase comme ça en fait parce que la précision d'adaptation du procès nautiques soit on est amené à utiliser de combinaison en fait avec avec des composants digitaux qui uvrent être capable de calculer de façon le nouveau poids synaptique est d'être capable de les coureurs de programmer change une arche et énergique est super combiné en fait non c'est un peu la façon pour le voir il va vraiment avoir des composants digitaux qui fonctionne avec une précision élevée qu'ils vont être capables de faire les tâches par exemple d'apple son pote synaptique de façon précise et d'après de transférer cette information les rouge et noir changement face qui uvrent capable de représenter en fait les pois synaptique de façon relativement imprécise pour des tâches voilà donc pour ce genre pauvres pour simplement le propager les données en fait à l'intérieur ils ont énormément de précision en fait sur les mémoires changé la face de cette façon là et même avec tout le bruit tout l'imprécision qui assure les personnalités que ça va fonctionner mais pour adapter les pois synaptique de façon continue c'est notre précision des bonnes peut-être plus pour claquer du coût zéro en garde utiliseriez deux choses qu'on peut faire la première c'est du coup car des prédictions donne des douanes des choses appelé à passer à la phase d'inférence et puis une autre phase qui l'apprentissage qui est amélioré leur zone et qui sait par contre ce que tu sais que c'est un peu plus difficile avec les archers pour l'apprentissage c'est vraiment une tâche qui en fait il ya certaines parties de la phase d'apprentissage qui les inquiète vraiment beaucoup de précision en fait même même jusqu'à 32 bits en temps voilà c'est ça on peut pas faire tout l'étagé l'apprentissage à l'intérieur de ces dispositifs d'action en france sont vraiment par construction impéritie en fait parce que c'était des dispositifs en alger chronos il descend comme la mémoire la logique et pas de manière juste et donc des fois ça va et donc tu me donnes je pense même que à l'avenir ça restera compliqué de faire ça en fait c'est ce qu'il faut voir ce que bon de la façon qu'on voit c'est vraiment qu'il faut il n'y a pas vraiment ce qu'il faut faire en fait c'est vraiment d'avoir une combine l'analogique avec digital donc il ya certains groupes de recherche qui est cette femme déjà qu'ils ne soient complètement la logique mais voilà personnellement et montséret plus de vie du couple aussi c'est que ça ne sera pas de énormément des tâches avec son fait et ce sera pas tellement ce qu'est le banc donc ça veut dire coeur que voilà on peut faire une puce en firent manager qui bat cas de faire une seule tâche par exemple voilà entraînés percepts ont à connaître des numéros de 0,9 mais voilà faut faire quelque chose de vraiment général qui va être capable de résoudre des problèmes plus complexes les deux façons programmables aussi parce qu'on veut pas avoir seulement une seule tâche mais spectre assez large on n'a pas vraiment fait d'avoir aussi un processeur digital qui m'ont un peu capable de faire tout ce que les mémoires chargement faut donc oublier ces randos de combiner des trucs qui sont plus riches avec moscou avec des rares il est logique qu'ils sont utilisés seulement pour pour certaines tâches qui qui ont été démontré qu'ils peuvent être faites en fait sur les dispositifs analogique et donc voilà c'est plus un peu la poche pour en construire et donc et sur la phase d'inférence de prédiction tu penses que ça pourra rentrer dans le marché bientôt quand tu vois que mais après bon c'est la tique on travaille aussi des compagnies de l'université d'envoi à la face différence parce que justement elle qui a pas nécessairement énormément de précision bon il ya des pistes qui ont été réalisés qui l'ont démontré on peut faire de référence avec ce type de dispositif à la logique mais voilà après avoir avoir une puce qui est configuré pour implémenter différents réseaux de neurones ses loques en fait le fils pause parce que voilà il faut aux rives ou essentiellement avoir un certain nombre de coeur en fête qui ont chacun un certain nombre de mémoires à changement de phase il faut être capable de communiquer ses différents choeurs de façon optimale et pourrait être carrément des différents projets de réseaux neuronaux comme des réseaux récurrent en fait donc non cela en fait que ça devient beaucoup plus compliqué on est capable de faire une puce qui va être capable d'alimenter un réseau spécifique est d'être capable de fonctionner comme il faut mais voir quelque chose de l'acide général qui va être capable de démonter différents types de topologie en fait c'est là qu'est ce donc cela d'après ce que je sais en fait ça vraiment encore été démontrée mais si là dessus si on est capable de vraiment montrer une architecture qui basent sur ce type de mur à chaque phase et qui garde le supporter est vraiment un grand nombre de deux réseaux de neurones là je pense que éventuellement être quelque chose qu'ils veulent et qui pourrait marcher quelles sont appelés les grands défis de la recherche en ce moment ouais donc s'ils sont un peu plus que ce que je disais en fait c'est qu'elle sait vraiment en fait c'est une intégration système parce que c'est vraiment être capable d'avoir un accélérateur neuromorphic qui peut être qu'ils programmable en fait et pour être capable d'intégrer de la même façon qu'on fait avec une carte graphique à l'intérieur j'utilisais l'accélérateur de façon optimale pour avoir des dons le moment il ya seulement des puces qui on est et qui ont été réalisés qui sont capables de faire certaines tâches d'intégration système qui va avec le soft reste acquis et tout cela au niveau de choisir et encore pas leur char sûr parce que la recherche sur les meilleurs matériaux à utiliser ou oui bien sûr ça aussi c'est clair que ouais pourquoi pour les dispositions de la logique que ce soit énormément aussi de recherche au niveau des oui les matériaux ses mots et tout et après les plus grands défis sont encore l'intégration comme se disait n'est pas vraiment faisable d'avoir un accélérateur qui non seulement est inconstant alhaji qu'il faut intégrer des composants digitaux ce qui veut dire qu'il faut aller dans une fade ses mots ce qui va être capable de faire il est celui qui vont avec donc voilà et c'est pas tous les matériaux qui peuvent être absolument donc donc voilà ça tous les défis d'intégration du tout qui sont vraiment ces normes en fait c'est vraiment quelque chose qui doit être retravaillé donc se laisser bien y trouver des nouveaux matériaux qui m'a capables de j'aurai plus de précision et tout mais après il faut être capable d'intégrer ces matériaux non à l'intérieur de ses noces avec les composants végétaux qui il pas nécessairement mais qu'en pensent les premières utilisations du neuromorphic sont plus dans papy tout du côté des datacenter auto des clients d dur à dire mais ouais je dirais que c'est surtout pour c'est sûr que qu'elles sont au niveau des par exemple d obliger ses skis plus attractif parce que bon nécessairement besoin en fait repris siemens qui compte le plus en fait ce n'est qu'une caisse elle ajouté et pour l'école les objets issus habituellement on a quand même des puces qui sont restés d'un certain nombre de tâches spécifiques en fait qu'ils les plus faciles pour deux énormes défis en fait pour être capable de réaliser une partie de ceux qui programment qui prive un câble de femmes membres nomme un nombre énorme de tâches c'est plus facile évidemment de construire une puce qui est restreinte à un certain nombre de tâches spécifiques qui serait simplement efficace en énergie pour ces tâches la peau que pour les data center par exemple ça prendrait vraiment quelque chose qui peut potentiellement elle tout ce qu'une carte graphique peut pas rester dans une énorme nombre de tâches et qui sont toutes reliées au machine learning des choses vraiment très programmables et qui va être capable d'avoir des gains en énergie qui sont beaucoup plus important c'est le quart des effectifs suis vraiment pas de données en fait que je prends le membre et c'est surtout les ça va être des déserts quelque chose qui va plus régulier sur une face à la fin est-ce que d'autres choses que notre on n'a pas parlé je pense que c'est son choix quand même non je pense pas je pense que j'ai un super bad cas merci beaucoup très intéressant laquelle il accueille daniel agger mais quand il prononce donc et chercheurs donc à ibm zurich et qui travaille notamment sur les questions d'informatique quantique babou jours à ce que tu pourras qu'on sépare rapidement te présenter un peu tout cas d'accord donc je m'appelle d'année à la guerre j'en ai fait mon bac ch raymond masse à lait psl et j'ai fait un bac peuvent en allemagne sur le sujet du contrôle quantique c'est à dire comment contrôler sybille supraconducteurs agents qui travaillent à un petit peu dans le domaine de la finance et depuis trois ans maintenant je suis chez ibm en tant que chercheur et je travaille la cure des applications et calcul quantique est également sur comment construire des ordinateurs quantiques notamment sur la fin du contrôle mécanique quantique pour commencer pour ceux qui connaissent ray avec naîtrait pas est ce que tu pourrais présenter ce qu'est un ordinateur quantique eu d'accord donc un ordinateur quantique c'est une machine de calcul où l'on traite l'information en écrivant les règles de la mécanique quantique donc quand on regarde un peu autour de nous on voit que la nature en quelque sorte elle tue les lois de la mécanique classique mais quand on regarde de plus près notamment au niveau atomique on se rend compte qu'il ya des phénomènes un peu différent peut-être un peu plus contre intuitif et ces phénomènes prend justement réagi par les lois de la mécanique quantique effet on dit qu'ils ont fait de la mécanique quantique qu'on cherche à traiter l'information dans un ordinateur quantique est donc comment fonctionne un gonon un calcul quantique l'union il ya plusieurs étapes dans un calcul quantique on y puise essentiellement 3 3 au retour la superposition l'intrication et l'interférence et je vais maintenant détailler un peu chacune du cerveau sont donc si on veut traiter l'information en utilisant les lois de la mécanique quantique il nous faut stocker cette information tant en systèmes quantiques et pour cela on utilise en croire une qu'on appelle donc en cubitt du coup et fait un système qui a en effet de niveau 1 0 et 1 un peu comme les beats conventionnel les beats classique et dont les cubistes une des grandes différences c'est comme si des systèmes quantiques on peut le mettre dans une superposition d'états c'est à dire qu'on peut avoir à la fois l'état zéro et en inde par exemple avoir un état moins 50 % de probabilité de mesurer sa route et cinquante pour cent de probabilités de mesures est maintenant figé thiboutot de qubits j'aurai quatre états que je peux potentiellement représenter à l'intérieur de mon ordinateur en même temps maintenant étant donné qu' on est en train de traiter l'information en utilisant les règles de la mécanique quantique on peut aussi utiliser l'intrication c'est une ressource quantique en quelque sorte qui nous permet d'introduire des codes à l'action en les différents et cantiques et c'est justement le genre de nous qu'ils acceptent beatles dont parlait einstein maintenant la dernière est en quelque sorte dans la grande majorité des calculs quantiques pennetta d'interférences et pour comprendre pourquoi on a besoin d' interférer les différents états il faut retourner un peu aux fondamentaux de la physique quantique c'est à dire que quand j'ai un système physique que je prépare dans une superposition data et que je me jure le système cette superposition d'états que j'ai va enfin retrouver à un seul état avoir en quelque sorte qu'on appelle un cola de la fonction d'onde ce qui veut dire que quand on arrive à la fin d'un calcul dans un ordinateur quantique il faut interférer la probabilité des différentes data pour que l'état qui a la plus grande probabilité d'être mesurée à celui qui correspond à la pollution de notre problème peut-être un truc à dire aussi c'est que lorsqu'on fait une intrication de beaucoup de qubits on a vraiment beaucoup beaucoup d'étapes possible du coup d'état quantique donc en fait à chaque fois que je rajoute à kiewit dans mon ordinateur quantique jeu doublé le nombre de départs que je peux représenter simultanément donc avec deux cubes itx et 4 est impossible 1 0 et 1 et manon et je perds pas proa cubitt g8 data que je peux représenter de manière simultanée et donc à chaque fois que je rajoute vaincu bits je double le nombre n'est pas se dire que lorsqu'on arrive à 50 public en fait on a déjà énormément d'état possible ici on a 1000 cubitt flins à plus de détails de particules dans l'univers exactement en fait il suffit d'avoir à peu près 2 175 subite là pour pouvoir là pour avoir une combinaison d'état qui fois qui correspond à new york et fois plus grand que le nombre d'atomes qui existe dans l'univers regardable donc c'est vraiment énorme selon une eau et du coup quoi ça sert qu'est ce qu'on peut faire avec un ordinateur quantique donc il ya certains calculs en fait que l'on pourrait effectuer avec un ordinateur quantique compte pas avec tes avec un ordinateur classique comme par exemple la factorisation on sait que la factorisation fait un problème difficile pour les ordinateurs classiques me fait quelque chose qu'on pourrait effectuer avec un ordinateur compte maintenant il ya aussi beaucoup d'autres applications d'un ordinateur quantique comme par exemple simuler des systèmes physiques en sait que la nature qui nous entoure elle est au plus profond de soi même quand il est donc en fait de simuler la nature avec un ordinateur quantique des fois ça nous permettrait par exemple de simuler les niveaux d'énergie dans une bascule ou des réactions chimiques ou mais pas seulement avec un ordinateur quantique on peut aussi s'attaquer à un problème d'optimisation ils sont difficiles pour les ordinateurs classiques et on peut également faire certaines tâches le fini la scion qui pourrait être utilisé pour calculer on va dire des métriques lloris donc soit pas des applications dans le domaine financier comme par exemple assez de déterminer notamment des algorithmes ses impressions c'est l'égoïsme de groover il permet du coup de faire une exploration d'une optimisation des coûts plus rapide kiko drastiquement plus rapide que régulière hors du but les situe exactement et donc par exemple dont les applications pour le risque financier en se balader tranquillement va sata le rythme pour avoir par rapport aux simulations schizo codra tig ou l'ordi des c'est une actrice qui prend un milliard de milliards des tables de calcul ordinateur classique ça serait vraiment beaucoup et pas faisable avec un ordinateur quantique où on pourrait faire ça en 1 milliards des tables quelques semaines ce qui pourrait être peut-être faisait oublier si l'ordinateur quantique devine assez puissant ils ont que passé le futur à ce que on aura choqué un ordinateur quantique chez soi ouais alors appris la répondante à dire non tout simplement parce que les ordinateurs quantiques qui vont pas remplacer les ordinateurs classiques conventionnel au contraire ils vont servir à effectuer certaines tâches que les ordinateurs classiques ne peuvent pas ils vont être utilisés pour accélérer certaines tâches maintenant quand on regarde les applications fatigué d'ordinateurs quantiques c'est typiquement des problèmes que l'on rencontre dans un milieu on va dire professionnels ou industriels donc déjà de produits là il n'y aura pas un grand avantage à avoir un ordre apple continue chez toi on va dire les plus un autre aspect c'est que ce sont des machines qui font entre elle veut lumineux écouter on sait que les systèmes quantiques sont très fragiles en facilement perturbées par l'environnement et c'est pour ça que par exemple quand on considère la technologie d ib un axe tort il faut tout un système de refroidissement et systèmes pour isoler en fait non bit quantique de l'environnement et cela rend en fait la chose très peu pratique si on voudrait avant ça chez nous et en fait c'est pour faire aux tic aujourd'hui on peut accéder à les ordinateurs quantiques à travers le cloud peuvent encore faire des escales ibm a mis à disposition du grand public c'est assez pesant pas ce que fait clic vous fait les calculs sur quelques particules seulement c'est tout petit mais il faut tout un système où tour pour refroidir un peu regardants fait la taille des équipes et on va avec les quelques points qui m mais en fait tout le film qui va autour du système de refroidissement et bravo à large du bouquet est ce que les ordinateurs quantiques ces listes déjà ou est ce que c'est clown et science fiction ouais enfin d'une certaine manière on pourrait dire qu'elle a exigé la fin donc justement à partir de 2010 a mis à disposition les ordinateurs quantiques avec un cubi initialement et puis maintenant on les appelle et pour les partenaires du réseau du bnq en avant des 53 kg et bêta est ici il faut faire comprendre que le fonds des systèmes qui font suffisamment petit pour qu'un ordinateur classique puisse les stimuler de manière efficace et donc ses professeurs qui font euro l'insee processeur conti ils ont tous en quelque sorte un ordinateur quantique ça qu'ils sont encore assez grand pour pouvoir effectuer une tâche qu un ordinateur classique le rapport actuel il donc à n'importe qui peut accéder utiliser les ordinateurs quantiques du guide exactement donc il suffit d'aller sur la page web du deuxième contre-expertise on peut faire encore et là on a accès gratuitement à un professeur avec 5 et qui vite et on l'a aussi accès à différents tutorial et et en fait on a aussi un réseau de partenaires industriels et eux ils ont accès à des professeurs qui ont leur équilibre qui n'en avaient pas avoir enfin en train cubitt aussi il faudra arriver à combien de cubic pour que ce soit utile une pratique qui ne put your way alors ça c'est un peu difficile à dire qu'on va peut-être nous prendre pour les calicots contre est en quelque sorte fait qu'elle est la performance d'un ordinateur quantique et on adore ça en utilisant le volume quantique donc le volume quantique c'est une mesure qui prend en compte le nombre de qubits mais également d'autres aspects de l'ordinateur quantique comme par exemple la connectivité entre les différents types plus on a de connectivité plus le volume quantique en principe sera élevé pour autant que les erreurs de nos portes logiques et ils peuvent classer encore un aspect qu'il faut prendre en compte et à chaque fois qu'on manipule l'information quantique qui est stocké dans nos bits quantiques on commet une petite erreur et il faut que cet or pour la plus petite possible et puis plus d'erreurs et petit plus le volume quantique et grands maintenant si on a un certain volume quantique c'est encore par claire quel type de problème on peut résoudre avec tel ou tel volume quantique le lien entre les deux est encore un sujet de recherche on va dire quand par la connectivité c'est l'intrication entre une particule amiens alors fait effectivement comment les cubis temps connecté entre heures si on prend on va dire trop cuites il pourrait être enfin chaque cube it dans notre triomphe poète connecter à notre quiz d'accord parce qu'on appelle là autour autres activités maintenant en fait ces trois qui vident pourrait très bien être représenté dans une ligne c'est à dire que les cubitt extrémité ils sont connectés au xive issus du milieu mais pas à l'autre qui vide de l'extrémité ce genre de collectivités en fait il faut commencer à faire des opérations supplémentaires pour pouvoir par exemple un tri afrique et des cubes et si on prend la chaîne de 3 cubitt et que j'ai envie de faire une opération entre les bus qui dit qu'ils font aux extrémités de la chaîne il faut d'abord que je la change un des clips à l'extrémité avec la cuvée 2010 mais du coup ça on peut toujours faire tous les calculs quantiques avec si on a des cubis telle signé alors on pourrait juste ce qu'il faut faire beaucoup d'opérations d'échangé et du boulet les algorithmes et efficace sur une machine quantique voulait qu vite souligné sue pas forcément les mêmes que s'il quitte sous tous heureux alors en fait on va faire fait qu'on va prendre on va dire un algorithme puis on va regarder les portes magiques qu'on a fait entre les différents tubes it et puis fit peut-être couple il ya deux cubitt entre lesquels on va faire une apparition ici on pas connecté on va donc ensuite introduire de trois opérations pour échanger des qubits pour que en plus de faire l'algorithme est donc le volume quantique aussi donc il dépend beaucoup de fausses idées pas fini tes explications sur une critique jeter coupé schwazer a donc le volume quantique qui libéreront de nombreuses choses dépendent des heures des portes magiques la connectivité entre l'équipe et le nombre de québécois est aussi le temps de cohérence des qubits donc le temps de 40 pour expliquer le préfet est plus ou moins la durée pendant laquelle je peux te quai de l'information dans mais qui dit par exemple je prépare un état quantique je vais seulement pour garder cette information on écrit bits pendant le temps de cohérence au delà de cette durée il y aura des perturbations environnementales qui vont affecter cette information qui fait que j'aime y aurait donc aujourd'hui le temps de cohérence ses sites non ça dépend un peu des systèmes quantiques et pour pour les cupides supraconducteurs par exemple on est en train de regarder de l'ordre de centaines de micro secondes on va dire ok du coup on a le temps de faire tenir d'opération ouais alors une porte la gigue en fête chez les kids supraconducteurs mur on va dire entre une dizaine et qui quelquefois antenne la nanoseconde ok donc c'est ce fait mille une opération que l'osm à peu près et ça ça progresse comment donc justement il ya beaucoup de recherches en fait qu'il est en train de se faire pour améliorer dépend de leur cohérence et un pour faire ça il faut encore travailler pour la fabrication des prototypes heures et également sur la rive allemande à l'environnement du coup si j'imagine déjà parmi les défis mon ordinateur constituent maintenant quand on regarde un peu l'histoire du domaine les premiers cubitt supraconducteurs quand on a conclu il ya maintenant bien plus de dix ans en arrière avec des plans de cohérence du nano secondes donc il faut se rendre compte qu'il y à pas mal de progrès qui a été effectué entre les premiers et quantique qui a que quand la maman cette annonce récemment de comme quoi passer la supprime aussi quantique depuis ce que tu expliquer ce qu'est la supprime si ton ticket alors en fait à l'ispm on se concentre pas vraiment sur la suprématie complique nous on se concentre plutôt sur le volume quantique est notre objectif a priori de doubler le volume quantique chaque année ok et la suprématie quantique tu peux expliquer ce que c'est alors l'idée d'en dans leur recherche c'est de démontrer qu un ordinateur conflit qui est capable de faire une tâche d'un ordinateur classique ne peut pas égales nom qui s'attachent utile et donc vous doubler le volume quantique tu as vous essayez de double oui quand ils ont un instant vous êtes sur ce rythme c'est ça pendant ce temps vous vous êtes vous arrivée chaque année a doublé effectivement alors prêt dernières années et justement donc pour pour doubler la machine quantique et pendant seulement augmenter le nombre de cubes it mais également de diminuer les erreurs mais partagée ok donc c'est vraiment un travail de deux visions qui sont à moitié d'ingénieurs en quelque sorte le domaine de l'information quantique c'est un domaine qui regroupe beaucoup d' expertise dans des domaines différents donc il faut qu'à notre en physique il faut sultanat fond programmatique mais aussi en ingénierie par exemple il faut beaucoup d'ingénierie électrique pour comprendre un peu comme en ligne de contrôle ont produit et donc je pense que le progrès va vous arrivez vous à l'écouté il volume donc nous tu vois le futur des ordinateurs quantiques ouais alors le but ultime en quelque sorte dans des ordinateurs quantiques évidemment nos achats d'ordinateurs quantiques c'est de construire qu'on appelle un ordinateur quantique universel qui est onéreux erreur d'un but après long terme et dans le court terme justement on voit plutôt qu'on va essayer d'aller vers cet objectif en doublant le volume chronique et pour cela donc il faudrait effectivement augmenté le nombre de kribi et demi d'une erreur des portes logiques j'ai vu passer je connais pas très bien de domaines mais j'ai vu passer quelques quelques articles sur les algorithmes de correction de code quantique c'est prometteur ça sert à quoi alors en fait l'idée c'est d'en traduire une certaine redondance dans les calculs au mécanisme mce de correction non peut-être que la chose la première chose qui nous viendrait à l'esprit est donc d en biologique ont plusieurs villes physique c'est à dire c'est à dire que par exemple si je prends trois bits quantiques physique je pourrais dire que le 0 logique c'est l'état 000 et qu'il n'est pas en logique pennetta en maintenant si un seul des qubits qui vit une erreur et que font des tâches ans par exemple de 0,1 je peux ensuite regarder quelle est la majorité de l'état des qubits dans ces trois qui bits c'est à dire que si j'ai un état zéro à zéro je vais considérer ça comme en 0 logique et là j'ai déjà introduit une certaine forme de redondance dans le calcul un an les codes de correction tels que les swaps et codes vont justement utiliser des principes similaires et encoder l'enfant n'a pas encore dit que l'ebit plus logique dont on a donc beaucoup de beats et par an dont beaucoup de culot et est ce que tu pourrais parler aussi un peu plus de la petite musique où j'utilisais à ibm qui sont nos petits coins son coût des limites ouais donc chez ibm en utilise qu'on appelle des qubits supraconducteurs ce sont en fait des petits circuits électriques coeur ont plus profond et en fait fait d'une capacité en parallèle avec une injonction de joseph pham ngoc sûrs de rien d'autre qu'une inducteurs non linéaire et en fait un système fait d'une capacité d'une jonction de joss stone forment un petit circuit électrique un réseau non et la non linéarité des là pour que l'on puisse adresser chaque transition avec des pulls ou de contrôle et on va former notre bits quantiques avec les deux niveaux d'énergie les plus bas de ce système d'abord je suis en avoir tout compris niveau d'énergie c'est le niveau d'énergie ces niveaux énergie de quoi exactement cela peut correspondre à différents data de charges ou de différentes attaques de courant a d'abord un peu de l'architecturé des cupides supraconducteurs ils google com vous fait une observation qu'une mesure du système alors avec la technologique nous on a en couple no no qubits avec des résonateurs donc un résonateur ce n'est rien d'autre qu'un câble coaxial en appuyant coupés selon la tranche donc c'est un petit système revenant qui a une fréquence de résonance et puis parce que ce système est couplé avec le le qubit la fréquence de résonance à dépendre de l'état du québec et ça ça veut dire que pour faire une mesure je peux envoyer un signal électrique sur surtout résonateur et analyser le signal qui est qui est retourné le signal affectés et en fonction de certaines propriétés de signal je vais pouvoir donc déterminer quel était l'état du bit parce que la fréquence de résonance des résonateurs répond nathalie que je vais peut-être un peu vrai et il commet fait une porte logique nous a semblé logique donc pour faire une porte logique ce qu'il nous faut faire c'est envoyer en plus de contrôle sur le qui vive et typiquement firme apprendront à dire une forte logique et envers plata du clip on va envoyer un signal qui correspond génial électronique week-end vacances de l'ordre on va dire à peu près 4 à 7 giguère est un signal contient suffisamment d'énergie pour inverser l'état du public donc en fait on a toute une technologie de génération de signaux aux alentours de lors des quelques guides verte pour contrôler nos guides continue et cette technologie en fait elle est plus ou moins déjà disponibles parce que y en a toute une industrie de l accord est justement ce genre digne hockey et du coup ça ressemble à quoi la rue alors tout ton boulot tu as testé d'une architecture du vote qu'est ce que tu as fait exactement donc par exemple dans certains cas certains des projets que j'ai eu ce qu'on avait intérêt à faire ça te regarder quels genres de signaux est-ce qu'il faut appliquer à différentes architectures pour créer différents types de portes la gic g du coup tu aimes bien souvent de blues ce qui est des partis que tu me ressembles à un travail qui en ferait passer non je trouve qu'à simplement de pouvoir isoler et contrôler un système quantique est encore d'un est quelque chose de très impressionnant et c'est presque ça sinon en fait de pouvoir faire rechercher par jour le jour est ce que tu peux vous donc à 10 en début d'interview qu'il y avait un problème particulier qui est assez connue sur lesquels les ordinateurs quantiques seront meilleurs que les donateurs classique s'ils ont beaucoup plus de volume identique quel point de la factorisation qu'il y à des pointes de cryptographie classique qu'est ce que tu veux un peu plus d'écrire ce problème et au graphique oui alors en fait on sait que certaines formes de cryptographie asymétriques sont vulnérables aux impacts des ordinateurs quantiques maintenant là on voit pas encore la cryptographie cas maintenant l'application on va dire pour les ordinateurs quantiques ans se concentrent plutôt justement sur la simulation de systèmes physiques et les applications dans le domaine des machines et de la finance maintenant pour en revenir au thème de la cryptographie on n'a pas besoin d'un ordinateur quantique pour ne pas être vulnérable aux attaques des ordinateurs quantiques on a en fait un processus standardisation qui a lieu en ce moment qui est mené par là et en fait on peut utiliser certains rythmes classiques qui feront donc leurs augustes aux ordinateurs quantiques tout un poème j'entendis parler du une compétition en fait sur plusieurs algorithmes de cryptographie classique vous nous faire une compétition possible voir quel est le meilleur exactement on a aussi fille à aulas boali bn les gens qui travaillent dans ce genre de problème mais quand tu as parle aussi de machine learning antique du coup d'accord donc l'application que j'ai en fait c'est la classification et plus spécifiquement en regardant fait la machine la ligne classique en après l'appel à ce project la chine c'est un outil qui nous permet de classifier des années comme par exemple on va dire à des clients qui auraient acheté un serpent produits les clients qui n'auraient pas acheté ce produit est en effet de classifier en fonction peut-être de certaines de leurs caractéristiques les clients des deux groupes maintenant des fois les données ne sont pas séparables comme par exemple si on regarde des pointures une ligne si les points aux mille une certaine catégorie et il fait aux extrémités cependant une autre catégorie c'est pas facile de tracer une ligne ici un pour séparer deux catégories donc du coup ce qu'on peut faire mais ça c'est toujours un dans le milieu classique on peut introduire les nouvelles caractéristiques comme par exemple prendre le car et de la position du point sur la ligne puis ça après ça nos défis d'une parabole et en utilisant cette parabole on peut ensuite séparé les points milieu mais points qui sont aux extrémités maintenant si on a un ordinateur quantique à notre disposition on peut utiliser qu'on appelle en coin que fitch maths c'est à dire qu'on va produire des nouvelles caractéristiques en utilisant un processus quantique est typiquement ces processus ils ne font pas calculable de manière efficace sur un ordinateur classique et puis donc ça va nous permettre peut-être de détecter certaines corrélations dont les données auxquelles on n'a pas accès autrement et il faut comprendre que dans cette application le bénéfice se ferait par exemple de réduire les erreurs des classifications qu'ont effectuée par contre on n'a aucune garantie qu'on va justement atteindre cet objectif il faut enfin sa fille et qui voit des femmes à réussir et du coup de trique antique c'est un lieu à la fois à l'apprentissage est une fiction ou juste à l'autre en tissage donc en fait on va faire tous là tout le processus en quelque sorte dans la dans l'ordinateur quantique on va faire l'apprentissage en utilisant un circuit quantique et en fit scandale et circuits quantique pour clarifier et donner ni qu'est-ce qu'il y aura des phases ou parce que du coup il faut quand même un ordinateur quantique pour faire des prédictions actuellement est ce qu'il ya des chevaux des ventes recherches pour essayer de voir un apprentissage contre déploiement ainsi qu une bonne 14e nuit pas au courant notre agrément s'est donc jeté ses dents formule 1 parce que tout ce que tu as des as une idée c'est que parfois lorsqu'on a des données coupé en deux quoi souvent on essaye on s'appelle lignières dans deux villes parfois on peut pas avoir de bonne séparation l'ignorent et du coup l'idée c'est de rajouter des dimensions et de calculs de dimension du coût de l'ordinateur quantique serait capable de bien trouver efficacement c'est une nouvelle dimension alors quelqu'un d'un ordinateur classique qu'il faudrait beaucoup plus de calculs en fait l'ordinateur conflit qui nous permet d'introduire des caractéristiques que qui sont difficiles à calculer avec un ordinateur conventionnel mais est ce que tu penses que ça serait possible que toute cette voiture moteur quantique finalement le progrès n'arrive pas à continuer est ce que c'est possible s'est soumis une ddn ou est ce que tu es très confiant sur le futur moi je suis assez confiant sur la future compte en regardant peut-être le progrès qu'il a effectués ces dix dernières années on va dire et quand même 35 ans par exemple en 2007 on avait les preuves à faire compliquer avec un cube it disponible via le cloud et maintenant on va justement introduire des processeurs avec en trois cabines est d'autant plus qu'il faut utiliser rendre compte que certaines de la recherche qu'on fait pour les ordinateurs quantiques peuvent aussi être utilisé dans d'autres domaines et ça c'est donc un acte et maintenant on est si tout un aspect comment dire de formation aussi non ibm a organisé plusieurs camps pour apprendre à et jeunes chercheurs les programmeurs comme on programmera un ordinateur quantique est justement en fait un piéton qui est un langage de programmation qui est aujourd'hui très utiles à connaître mais c'est aussi quelque chose qui va nous permettre en quelque sorte de découvrir les applications du futur est finalement un des aspects que je trouve les plus excitants fait que en effectuant cette recherche sur les ordinateurs quantiques on découvre aussi des choses sur le monde qui nous entoure à et on peut donc justement on a pris connaissance du monde qui nous entoure ça fait quelque chose de trouver très excitant ce qu'était d'autres exemples de domaines liés à la supraconductivité s'il ya plein d'autres par exemple aussi ça nous permet de pousser notre compréhension des processus chimiques qui ont lieu justement dans ce système avec les canons qu'on soit allé les cupides supraconducteurs puisque pendant la supraconductivité ya beaucoup de recherches sur des outils la supraconductivité à température ambiante ce que ça s'enlève actionnerait ordinateur quantique ou est-ce que ce qui aurait des lions alors en fait la raison pour laquelle on a besoin d'un système de refroidissement dans nos systèmes quantiques c'est parce que la transition en énergie de transition entre le zéro et le 1 est de l'ordre de 5 à 7 giguère manouan fait pour que convertir cette énergie en une température et puis sa température est de l'ordre de 240 milliken vite à peu près qui veut dire que si on veut protéger la probable quantique est fluctuante et environnemental il faut avoir un film de refroidissement qui est qui attend des températures beaucoup plus profonde que les 240 médical ville parce que s'il ya trop de niveaux d'énergie vu que tu as et aux alentours en fade et si on a paré de programmes font de la programmation quantique sur python du coup vous avez une librairie pour écrire des codes antique donc ibm a mis à disposition du public général et on est en train de concevoir une librairie qui s'appelle qu'il quitte le même famille sont partout inquiète était en fait tous les obstacles qui nous permet de contrôler les ordinateurs quantiques c'est à dire que au niveau des plus élevés on a les applications comme par exemple simuler des molécules et puis au niveau le plus profond on a justement la génération des pubs de contrôle qui nous permet de contrôler un ordinateur quantique et voit du coup je me disais plein plein plein d'étapes intermédiaires afin d'écouter trait aux jeux hardware d'un truc un peuple est-ce que c'est difficile d'apprendre un programme mêlant quantique c'est quand même a pas de calcul qui est très différent donc il faut connaître un peu d'alzheimer de physique et il faut aussi réussir à comprendre que sa carte circuit quantique c'est à dire quel est l'effet de faire telle porte le gigaset maman comme la suite super puisque tu as quelque chose d'autre à rajouter je crois que pour l'instant on a touché plus de moments à à bout de la chaîne les ordinateurs quantiques superbe à merci beaucoup en tout cas pour beaucoup dans merci merci beaucoup bonne continuation l'afnor merci quelque chose vous pouvez m'écrire ce genre et si vous avez des photos ou des vidéos que des chocs frontaux uniquement en audio mais bon merci ok merci beaucoup merci que vous voyez du coup vous voyez le registre mondiaux tout à fait un super haut