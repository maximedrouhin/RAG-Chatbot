qu'est ce qu'une probabilité voilà une question qui m'a beaucoup marqué me fut posée lors d'un examen oral du concours de l'école normale supérieure et comment dire j'ai eu 6 sur 20 à cet examen et vous qu'en pensez vous qu'est ce qu'une probabilité je vous invite à mettre pause à écrire une réponse intuitive à cette question dans les commentaires avant d'aller plus loin dans cette vidéo et rassurez vous vous n'êtes pas en situation d'examen je ne vous connais leur est pas ainsi sur 20 si votre réponse est incompatible avec les lois des probabilités lors de mon oral la réponse que j'ai donnée était l'archétype d'une réponse fréquentes east j'ai répondu que la probabilité d'un événement était sa fréquence limites quand on répète l'expérience dans laquelle l'événement peut intervenir et bien sûr comme j'étais dans un oral de mathématiques les examinateurs se sont jetés sur des détails mathématiques en omettant tout l'aspect philosophique ils m'ont alors demandé si la fréquence de l'événement allait converger et oui parce qu'a priori ça n'a rien d'évident reprenons le sondage de michael qui nous dit qu'avec de plus en plus de réponses la fréquence de la réponse garçons convergeraient vers un nombre en particulier en fait il ya même deux bonnes raisons de penser que plus il ya de réponse plus l'ensemble des sondés sera un échantillon différent de l'ensemble de la population mondiale et donc qu'au lieu de rester là où elle en est la fréquence de réponse garçons dévierait au gré des communautés atteinte par le sondage pour garantir une convergence vers une fréquence limite le fréquentent east va alors généralement postuler l'existence d'une vraie probabilité c'est à dire d'un nombre p objectif est bien définis tels que si on répétait nos observations à l'infini alors la fréquence limite de l'observation de l'événement tendrait vers p ce postulat fréquentes east semble s'être retrouvé au coeur de nombreuses réflexions sur la science et son rapport à la réalité on imagine souvent que la science finira par converger ou du moins par se rapprocher asymptotiquement de la vérité au fur et à mesure du progrès scientifique ou dit ainsi souvent que le but de la science est d'approcher une réalité objective ou du moins que cette intuition de ce que doit être la science est une bonne approximation de l'objectif qu'elle devrait se fixer et je vous renvoie vers cette super vidéo de monsieur vie qui expliquent en quoi un réalisme scientifique naïf est en fait très insatisfaisant et comment les philosophes réaliste moderne cherche a néanmoins donné un sens à cette approche réaliste en s'arrêtant notamment sur la notion de structure quoi qu'il en soit il y à de nombreux cas où la proche fréquentes east semble plus que justifiée nous avons dès lors qu'il s'agit de déterminer la proportion de réponses garçons dans une très grande population la probabilité paix semble alors très bien défini on peut la définir ici comme étant égale à la proportion de réponses garçons dans cette population et il semble très raisonnable qu'on va l'approché en répétant un tirage aléatoire d'un 1 10 du de la population en lui demandant s'il répondrait garçons au sondage de michael le fréquentent isme s'intéresse alors particulièrement à des contextes où les données semblent être tirées de la sorte que ce soit pour les sondages ou pour les tests randomisés contrôlés en double aveugle temps on parlera dans une prochaine vidéo dès lors la question centrale du fréquentes east c'est de savoir à quel point la fréquence f d'une observation dans son échantillon est une bonne indication de la vraie fréquence limites a estimé à quel point après 2260 vote la fréquence de réponse garçons du sondage de michael est elle proche de la vraie probabilité qu'un individu qui fait l'expérience de pensée de michael répondent garçons peut-on garantir en particulier que f sera suffisamment proche de paix pour répondre à cette question le fréquentent isme va alors s'intéresser aux fluctuations statistiques de l'échantillonnage et de la fréquence empirique f autrement dit supposons que la vraie probabilité swaps et quelles sont les valeurs vraisemblable de f à quel point f petit dévié de paix et en particulier les mathématiciens et statisticiens ont cherché à fournir des réponses rigoureuses à cette question d'un côté ils ont prouvé la loi des grands nombres qui dit que à l'infini la fréquence empirique f finira bel et bien par converger vers la vraie probabilité p malheureusement cette loi des grands nombres ne nous dit pas combien de temps il nous faudra attendre ni si pour un échantillon donné la fréquence empirique f a de bonnes chances d'être proche de paix ou non pour répondre à cette question le fréquentent isme s'appuient généralement sur l'un des plus beaux théorème des mathématiques à savoir le théorème centrale limite initialement prouvé dans un cas particulier par abraham de moivre mais ensuite aussi et surtout prouvé dans le cas général par un certain pierre simon laplace la base en 1809 ce théorème est vraiment un monument des probabilités il prédit les erreurs auxquelles s'attendre lorsqu'on estime une vraie probabilité paix à l'aide d'une fréquence f une façon stupéfiante comme l'expliquent très bien la statistique expliqué amoucha les erreurs auxquelles on peut s'attendre ne dépendent en fait pas vraiment du phénomène étudié bien souvent quand le nombre de données tend vers l'infini de façon très surprenante les erreurs attendus seront distribués selon une seule et même loi appelée la loi normale cette loi normale est tellement stupéfiante que ce statut ici un francis galton disait cela à son sujet je ne connais presque rien d'aussi athée impressionné l'imaginaire que la forme magnifique d'ordre cosmique expliqué par le théorème centrale limite ce théorème aurait été personnifié par les grecs et d'édifier s'il avait connu il règne avec sérénité avec un auto effacement complet au milieu de la confusion la plus sauvage plus grande est la foule plus grande l apparente anarchie et plus parfaite est sa loi c'est la loi de la déraison à chaque fois qu un large échantillon d'éléments chaotique et collecter et rassembler une insoupçonnées et merveilleuse forme de régularité dévoile sa présence c'est cette régularité stupéfiants ce qui marche de données très aléatoire qui permet aux statisticiens fréquentes east de maîtriser le hasard les fluctuations statistiques et les grands écarts alors permet de dire à quoi il faut s'attendre avec grande probabilité la fréquence empirique f devrait alors se trouver dans la zone principale d'une fameuse courbe en cloche centré autour de la vraie probabilité paix et dont l'épaisseur correspond en gros un écartement dont la taille est de l'ordre de 1 / la racine carré de la taille de l'échantillon voilà qui permet en particulier statisticiens fréquentes east de définir ce qu'est une fréquence empirique f qui contredit l'hypothèse d'une probabilité p en tout cas selon la plupart des fréquentes east on pourra alors rejeter l'hypothèse p si la courbe en cloche prédite par l'hypothèse paix ne contient pas la fréquence empirique f typiquement si je reprends le sondage de michael si j'en crois le théorème centrale limite l'hypothèse paix est égale à 33 % auraient prédit une fréquence en péril autour de 33 % plus ou moins 2% or la fréquence empirique f correspond à 40 2 % ce qui est très loin dans l'intervalle 31% 35% le fréquentent isme nous inviterait alors à rejeter l'hypothèse paix est égal à 3 3% telle est la forme la plus standard est la plus utilisée du test d' hypothèse sur laquelle on reviendra plus longuement une prochaine fois ou pour ajouter qu'il ne s'agit toutefois pas de la seule façon d'analyser des données pour un fréquentes east plutôt que de chercher à rejeter une hypothèse le fréquentent east peut ainsi vouloir davantage recherché une hypothèse qu'il colle bien aux données pour ce faire il va considérer un ensemble de théories et typiquement cherché à utiliser les données pour estimer la meilleure théorie à isoler on parle d' estimateur statistiques l'exemple le plus courant destinateur statistique est typiquement l'estimateur du maximum de vraisemblance cette estimateur va chercher la théorie t tel que cité est vrai alors la vraisemblance des données d est maximale autrement dit le maximum de vraisemblance t et la théorie selon laquelle les données sont le moins surprenante les fréquentes east qui étudie les estimateurs vont ensuite souvent s'empresser de demander si leur estimateur sont proches de vraies probabilités p jeu en particulier vont se demander si lorsque paix et la vraie probabilité tel ou tel estimateur convergera vers paix lorsque la taille de l'échantillon tend vers l'infini on parle d' estimateur semblait ou l'estimateur convergent bref si je caricature le fréquentent east va souvent ce présupposé l'existence de vraies probabilités qu'ils produisent les données empiriques puis il va concevoir une sorte de boîte à outils il va étudier ces outils en identifiant notamment ceux qui ont le plus de chance de se rapprocher des vraies probabilités à partir des données empiriques et en particulier il va se poser la question de la convergence des solutions trouvées par ces outils voire de leur vitesse de convergence lorsque le nombre de données empiriques tend vers l'infini jamais il ya des gens parmi vous qui se considèrent fréquentes east et qui regarde je vous invite vivement à dire en commentaire si ma description du frais kantisme vous satisfait ou si vous la trouvez scandaleusement biaisé en particulier si vous êtes d'accord avec cette description dit le s'il vous plaît et sinon bah corrigez-moi cédera tout le monde à mieux comprendre les fondements du frais kantisme quoi qu'il en soit cette attitude épistémique semble avoir envahi les sciences ou du moins la manière dont certains scientifiques philosophes et et éthicien par le des sciences beaucoup insistent ainsi régulièrement sur le caractère indispensable de la répétabilité et de la reproductibilité des expériences et sur l'importance de disposer d'échantillons suffisamment importants pour se faire un avis voir sur la nécessité d'aller chercher davantage de données pour trancher une question typiquement choisissant d'abord une hypothèse à tester puis en allant répéter les expériences pour la rejeter ou la corroborer et même si on ne peut pas savoir aujourd'hui les scientifiques ont tendance à supposer que à l'infini on finira par savoir ok si ça ne vous paraît pas condat le comme principe je vais pouvoir passer aux limites du frais kantisme et malheureusement elle me semble vraiment énorme la première chose qui n'est pas forcément la plus importante c'est que pour donner un sens à la démarche le fréquentent east doit commencer par présupposés l'existence de vraies probabilités dans de nombreux cas comme on l'a vu c'est une hypothèse très raisonnable est très utile mais de là à dire qu'elle est vrai et qu'il faut absolument raisonner avec cette hypothèse il ya un pas à faire ou à ne pas faire par exemple est ce qu'il ya une vraie probabilité qu'une réponse aux tweets de michael soit garçon est ce que cette question a vraiment un sens ne dépend elle pas fortement de l'ensemble des sondés que l'on considère de leur éducation et du contexte dans lequel ils répondent à cette question et cette probabilité est elle vraiment un objet d'étude pertinents par exemple monsieur villach reproduit le sondage dominical launay sur sa chaîne mais il a obtenu des résultats significativement différent est ce qu'il existe donc une vraie probabilité que monsieur fille et mickaël ont vraiment cherché à estimer or de nombreux outils comme les intervalles de confiance sont utilisés pour ensuite déterminer où la probabilité recherché a de bonnes chances d'être sachant que cette probabilité n'est qu'une entité postuler par le modèle la prépondérance de ce genre d' approche à agacer certains scientifiques comme le statisticien william p ex dans un article intitulé il est temps d'arrêter d'enseigner le fréquentent isme ou non statisticiens brixi écrit tout ce qu'on peut dire à propos dans l'intervalle de confiance c'est qu'un paramètre métaphysique peut soit si trouver soi ne pas s'y trouver bon je trouve la critique un peu dur mais elle ne me semble pas sans fondement un autre argument important contre le fréquentent isme et qui a tendance à négliger la prise en compte des préjugés ou dit autrement de l'état actuel des connaissances c'est un point extrêmement important qui j'ai le mental a déjà abordé dans cette vidéo mais je vais la laisser de côté pour aujourd'hui parce qu'il faudra vraiment prendre le temps de le développer pour le rendre convaincant enfin l'argument sur lequel je compte m'attarder pour finir cet épisode est le suivant parce qu'ils s'intéressent à des fréquences le fréquentent east va s'intéresser uniquement à des événements qui peuvent donner lieu à la notion de fréquences d'observation et à bien y réfléchir ceci exclut de nombreux champs d'étude que les scientifiques jugent généralement digne d'intérêt pour les sciences c'est le cas par exemple du changement climatique à quelle fréquence at on observé un réchauffement climatique d'origine anthropique quelle est la fréquence d'observation de cet événement il semble que cette question n'a pas de sens de façon plus générale toute étude de phénomènes fortement dépendant de l'état physique de l'univers passé présent ou futur semble difficile à interpréter en terme de fréquence d'observation comment expliquer la chute de l'empiré romain sachant qu'on ne pourra pas observé plusieurs fois cet événement comment étudier l'évolution du vivant sachant qu'on ne dispose que de l'unique cas de son évolution sur terre comment appliquer le free kantisme à la cosmologie sachant qu'on ne pourra pas répéter le big bang et surtout que peut-on dire aujourd'hui du futur notamment des événements potentiellement inédit du futur vu qu'aucune donnée du futur n'est disponible une anecdote illustre particulièrement bien ce cas où lendemain de la seconde guerre mondiale un économiste de mandat aux statisticiens david blackwell alors fréquentes east quelle était la probabilité d'une guerre nucléaire dans les cinq années à venir blackwell répondit aux cette question n'a aucun sens les probabilités ça pique à de longues séquences d'événements répétable quand il s'agit clairement la drica unique la probabilité est soit 0 soit 1 mais nous ne serons pas avant cinq ans l'économiste rétorqua j'avais peur que vous disiez cela j'ai parlé à plusieurs autres statisticiens et ils m'ont tous dit la même chose le langage du frais kantisme semble l'empêcher d'envisager des événements inédits du futur et il arrive parfois que certains conclu que ne pouvant rien dire du futur il est préférable de ne pas en parler il ya vraiment beaucoup d'hostilité vis-à-vis de d'auteurs comme nick bostrom ou encore pirelli dukovski dont s'inspire ningbo ce tronçon assez vite évacué d'un revers de la main comme étant des chars la tannerie et des spéculations sont sans aucun intérêt le fonds de l'objection général est aussi toujours à dire nés quelque part voilà sur ces deux premières questions ses deux frères probabilité c'est trop faible ou alors en fait souvent c'est plutôt très difficile à évaluer georges c'est plutôt sain suivi de et toute façon si tout ça est un peu plus compliqué que ça et honnêtement on n'en sait rien voilà c'est toujours une espèce de mélange de ça et tout ça qui voilà qui conduit au final à sur la dernière question mais on s'en fout complètement parce que voilà les fois précédentes rennes que on s'en fout c'est vrai c'est quasi religieux vous êtes des espèces de boubous arrêté d'annoncer la fin du monde est voilà est un charlatan singularisme voilà qui contraste beaucoup avec de nombreux bayésiens qui sont souvent effrayés par les risques d'événements futurs sans précédent n'ont pas car il pense qu'il est probable que le futur aille mal mais souvent de nombreux arguments heuristique suggère qui n'est pas complètement improbable que les choses se passent mal en particulier le fameux ordre cosmique décrit par galton est célébrée par bien des fréquentes east semble en fait ne s'appliquait qu'à un petit ensemble de problèmes à savoir ceux qui permettent la répétabilité d'un phénomène à l'infini cependant les expériences souvent fait davantage reproduite dans la bo de recherche à l'autre avec des outils et des environnements qui ne cessent de différer un phénomène est rarement vraiment répétable et il ne l'est certainement pas à l'infini mais surtout l'ordre cosmique et de galles tonnes n'est valable que pour des données indépendantes est identiquement distribuer encore une fois dans bien des cas notamment les tests randomisée en double aveugle ton par adam prochain épisode cette hypothèse est raisonnable mais dans de nombreux cas cette hypothèse est en fait plus que discutable en particulier de plus en plus notamment via la prolifération de toutes sortes de capteurs de données et l'analyse des données collectées de manière non contrôlée cette hypothèse n'est pas satisfaite les données empiriques ressemble de plus en plus un foutoir avec des corrélations à tout va elles ne sont pas indépendants est identiquement distribués et malheureusement le réflexe du pur fréquentes east c'est de rejeter la pertinence de ces données ces données ne sont pas aux standards des tests randomisée en double aveugle que le fréquentent east préconise et il a raison cependant parce qu'elles sont beaucoup plus volumineuse mais également parce qu'elles correspondent à des comportements irl ces données empiriques seront potentiellement beaucoup plus informative que les données collectées dans l'environnement très artificielle du laboratoire en tout cas il semblerait peut-être un peu irrationnel de les jeter à la poubelle sous prétexte qu elles n'obéissent pas aux formalismes fréquentes east pire le plus gros danger et ce sera de s'autoriser à ne pas parler de certains sujets sous prétexte qu aucune analyse répondant aux cadres très rigide du frais kantisme n'est possible le problème quand on tue et discussions dans l'oeuf à grands coups de scientifiques c'est que ça revient à dire on sait pas donc on s'en fout mais on s'en fout complètement parce que voilà les fonds précédent entre elles que on s'en fout analysons cette phrase de plus près déjà on sait pas ça veut dire qu'on n'a pas assez de données pour appliquer la méthode scientifique mais dans ce cas la question ne devrait pas être de savoir ou de ne pas savoir mais plutôt qu'elle la crédence peut-on avoir en cette théorie mais le plus problématique c'est la conclusion on s'en fout parce que en plus de relever d'une certaine paresse intellectuelle cela revient à occulter complètement un grand nombre de questions importantes comme par exemple des questions dont l'enjeu pour être je ne sais pas la survie de l'humanité ce réflexe de dire ce n'est pas scientifique est selon moi une mauvaise habitude qui découle de la manière dont on nous enseigne les sciences comme si la science était une sorte de statue grecque aux proportions parfaites alors qu'elle est en fait le résultat d'un grand nombre de herman et de remise en question et cela mais certaines personnes dans une situation d'excès de confiance où elles vont trouver une sorte de valorisation sociale a cassé tout ce qui serait pas scientifique avec parfois un petit ricanements méprisant ce qui n'est pas exactement une attitude bienveillante de recherche humble de la connaissance et qui va tuer dans l'oeuf de nombreuses discussions sur des sujets importants nous avons d'énormes enjeux devant nous et il nous faut être capable de bien les adresser même si les données dont nous en disposons sont bordéliques et pas franchement indépendante est identiquement distribués voilà pourquoi selon briggs en tout cas il semble peut-être temps de dépasser le cadre restreint du frais kantisme et de songer à des alternatives qui proposent des traitements plus universel des données comme le balsa nisme la fin on a parlé de trois variantes mike de problèmes des deux enfants et notamment y aura plein d'autres vous invitant à tourner et se prennent dans tous les sens et réfléchir à tout ce qui peut y avoir deux contre intuitif et surtout a essayé de l'agresser tous les cas possible essayez d'imaginer comment il faut réfléchir dans tel ou tel cas ariel sardou fait remarquer que par hasard en fait il une autre chaîne anglophone médor prep qui a fait des vidéos à ce sujet que je recommande vivement c'est vraiment des super vidéo alors je suis pas tout à fait d'accord avec tout ce qui est dit dans ces vidéos comment je pense que le raisonnement global et pas forcément très béliziens mais je trouve absolument génial ces vidéos ça fait réfléchir surtout je trouve que meilleur prête à une approche extrêmement enthousiasmante également très modeste du problème que je trouve absolument adorable vraiment je pense que c'est vraiment l'attitude dans laquelle j'aimerais voir plus de gens réfléchir à toutes sortes de problèmes mathématiques et ailleurs particulier aux médias reprennent a fait deux vidéos et dans la deuxième il corrige en fait des choses qui a dit dans la première et monsieur fils également sorti une deuxième vidéo sur le paradoxe des deux enfants que nous invite également vivement allez voir il ya beaucoup de choses très très intéressante et en baignant un peu plus dans tous ces arguments des uns et des autres je pense que ça peut vraiment aider à mieux réfléchir à ce problème est vraiment mieux comprendre ce qui se passe vraiment particulier point un peu mieux aider à caracter ce qui se passe je veux rebondir au commentaire de beaux benz cuisine qui propose un dialogue où on semble passer d'un tiers à retiennent quasiment un demi suite à l'apprentissage du fait que l'un des garçons il n'est un mardi en fait si vous regardez un petit peu le dialogue qui va proposer en fait dans ce cas là non il ne faudrait pas passer à 1 2 me est en fait ils d'incohérences un peu dans cette histoire puisque on suppose que l'homme a deux enfants et que donc le moins l'un des enfants est un garçon mais ensuite l'une des questions c est ce que le premier est né un mardi en fait cette question est un petit peu en milieu parce qu'elle présuppose que le premier du coup serait un garçon alors qu'on ne sait pas d'une petite incohérence ici en fait si on apprend que le premier des enfants est un garçon en gros ça dépend encore une fois du contexte mais en gros la priorité que le deuxième sera un garçon est probablement un demi qu'en face ça dépend un petit peu du contexte la manière dont on apprend cette information en fait ce truc qui est vraiment perturbant et qui fait que ça va passer à 13 1 7e c'est lorsque l'on répond à la question il ya au moins un enfant né un mardi on ne sait toujours pas le duquel on parle en fait lorsqu'on pose cette question le père d'une certaine manière à le possibilité de choisir si jamais il avait deux enfants duquel des deux enfants il va parler c'est vraiment cette ambiguïté sur lequel des deux enfants on parle notamment dans le cas où le père a deux garçons qui fait qu' on a toutes ces bizarreries donc tous invités un peu réfléchir un peu à ça et à un firmament finalement à ce biais de sélection du père qui va d'une certaine un devoir choisir duquel de ses enfants il va parler et ça ça m'amène au cas plus générale ou lorsque le père dit de lui-même j'ai un garçon en fait il ya vraiment la question de pourquoi est-ce qu'ils parlent d'un enfant plutôt que de l'autre et en particulier s'ils avaient garçons filles est-ce qu'il est plus probable qu'il se met tout à coup à parler du garçon ou qu'ils se mettent à parler de la fille on a envie de dire qu'après c'est 50 50 mais en général à cause du contexte ce ne sera pas 50 50 il ya des contextes dans lesquels peut-être que le père va davantage mettre en avant son garçon ou peut-être que notre contexte il va mettre davantage en avant une des filles qu'il a en tout cas ce biais de sélection cette probabilité qu'il se met à parler de l'un des enfants plutôt que de l'autre c'est vraiment le noeud du problème ce qui fait que la réponse est quelque part entre 0 et 1 2 me et que si on connaît pas le contexte dans lequel le père a choisi de parler d'un enfant plutôt que de l'autre alors ne pourra pas avoir la même conclusion qu'une benzène qui elle connaîtrait le contexte dans lequel le père a choisi de parler lui l'un de ses enfants plutôt que de l'autre sinon je vois bien dire que de façon un peu général j'étais un petit peu déçue par la virulence un peu dans les commentaires sur ce genre de problème ces déboires de problème je pense qu'on est une réduction très forte et qu'on a l'intuition très très forte on a tendance à être un mode un peu rationalisation raisonnement motivé à vouloir défendre notre position et je trouve ça vraiment vraiment dommage donc typiquement sur ce genre de questions c'est l'occasion d'appliquer hashtag des bâtons mieux fait attention à ce que vous faites surtout éviter l'auto promotion typiquement et essayer d'être vraiment bienveillant envers toutes les personnes qui réfléchissent à ce problème comme l'a été par exemple youtube qui je trouve a vraiment été excellent sur cet aspect dans ces vidéos elle espère que j'avais cet épisode de la prochaine fois on va continuer à parler de la science telle qu'elle est faite aujourd'hui en particulier on parlera des tests randomisée en double aveugle et de leur importance pour avoir de bonnes conclusions scientifiques éléments un petit peu d'erreurs et même si vous avez aimé cet épisode spécial laquelle augmenté à le partager pensez à vous abonner pour une connerie futurs épisodes martiaux type ford et j'espère que vous serez là la prochaine fois lorsqu on assemble deux ou davantage de variables quelle sera la distribution de probabilités de la nouvelle variable c'est ici que les statisticiens ont découvert quelque chose qui aujourd'hui encore me fascine plus on assemble à grand nombre de variables aléatoires identiquement distribué par addition plus la distribution de probabilités de la nouvelle variable se rapproche d'une distribution normale c'est ça le théorème centrale limite alors plutôt que de dire on sait pas donc on s'en fout disons plutôt oui effectivement il y à un certain degré d'incertitude sur ce sujet donc essayons d'ajuster nos crédence du mieux que nous le pouvons avec les connaissances que nous avons et s'il s'agit d'un sujet important efforçons-nous d'acquérir de nouvelles informations afin d'ajuster nos crédence de façon plus rigoureuse