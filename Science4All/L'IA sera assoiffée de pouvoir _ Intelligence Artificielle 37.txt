on a parlé de la morale déjà depuis pas mal de vidéos et on a aussi pas mal parler de morale dans la série sur la démocratie et comme beaucoup l'ont fait savoir j'ai souvent eu un penchant un peu conséquent sa liste au moment de parler de la morale autrement dit j'ai eu tendance à penser qu'une action est moralement bonne si elle conduit à des conséquences désirable et ça ça vous choque peut-être notamment parce que ça s'oppose à la morale déontologique notamment défendue par quand la déontologie consiste à davantage considérer une liste de lois morales universelles auxquelles tout un chacun se doit d'obéir un peu comme la liste des dix commandements en il ya l'exemple célèbre d'une telle approche déontologique de la morale des machines et l'ensemble des trois lois de la robotique introduite par le biochimiste et écrivain isaac asimov ces trois lois sont les suivantes première loi un robot ne peut porter atteinte à un être humain ni en restant passif permettre qu'un être humain soit exposé au danger deuxième loi un robot doit obéir aux ordres que lui donne un être humain sauf si de tels ordres entrent en conflit avec la première loi troisième loi un robot doit protéger son existence tant que cette protection n'entre pas en conflit avec la première ou la deuxième loi alors ces trois lois peuvent paraître séduisante est satisfaisante mais justement les romans d'asimov suggère que ce n'est pas le cas pire encore je vous invite à vous demander ce qui se passerait si l'on prenait vraiment ces règles au sérieux par exemple imaginons que vous êtes un robot et que l'espèce humaine est en grave danger et pour la sauver il faut et il suffit d'encourager un être humain a effectué un truc un tout petit peu risqué est ce que vous trouvez moralement justifié les robots s'interdisent de se faire ce genre de cas a justement été envisagée par asimov qui a alors proposé l'ajout d'une loi zéro prioritaire sur toute autre loi cette loi elle dit la chose suivante loi 01 robot ne peut pas porter atteinte à l'humanité ni par son inaction permettre que l'humanité soit exposé au danger mais à bien y réfléchir si on prend cette loi au sérieux et si on raisonne en présence d' incertitude ou non vient assez rapidement à conclure pierre robot peut toujours faire quelque chose pour réduire le danger auquel l'humanité est exposé et oui comme on en a parlé dans l'épisode 35 l'humanité est menacée à tout instant par des éruptions solaires des pandémies et des guerres mondiales en fait tous robot morale le sens des quatre aux lois d'asimov devrait être si obnubilé par la loi zéro que toute autre loi n'interviendra jamais pire encore la loi zéro est en fait incroyablement by du est discutable typiquement imaginons que le robot à deux boutons devant lui avec le bouton bleu le robot peut augmenter de 1 centime de dollars l'investissement dans la surveillance des astéroïdes avec le bouton vert il extermine tout risque de collision d'astéroïdes de pandémie et de guerre mondiale la loi zéro dit que le robot doit appuyer sur un des boutons car il ne peut permettre d'exposer l'humanité au danger par son inaction mais elle ne dit pas que le robot doit appuyer sur le bouton vert pourtant ils sont bleus la 13e' morale de ne pas appuyer sur ce bouton vert de façon générale en disant ce qui doit être fait plus tôt qu'en concevant des raisonnements pour déterminer ce qui doit être fait les formulations déontologique ont souvent du mal à exprimer l'intensité des devoirs moraux et a souligné le fait que certains devoirs moraux sont beaucoup plus pressant que d'autres pour distinguer l'importance relative de différents devoirs moraux il faudrait quantifier l'importance des devoirs moraux ce qui conduit doucement mais sûrement vers des versions plus quantitative et donc plus conséquentialiste de la morale bon cette transition est en fait bien plus subtil que ça il faudrait en parler bien plus longuement mais il est intéressant de voir qu'en cherchant à mieux formaliser la loi 0 on en vient assez vite à une formulation beaucoup plus conséquentialiste des lois d'asimov selon une version affinée de ces lois qui prend notamment mieux en compte les degré d'incertitude au final il semble qu'un robot doivent avant tout cherché à minimiser la probabilité d'une extinction de l'espèce humaine est en fait tout ceci correspond à un théorème plus fondamental appelé le théorème de vaud nomades morgenstern dont on a déjà parlé dans l'épisode 12 de la série sur démocratie ce théorème dit en gros que toute façon de penser des préférences morale ou autres qui prennent bien compte de l'incertitude et qui satisfait quelques propriétés désirable comme la transitivité la transitivité c'est le fait que si on préfère a à bbb assez alors on préfère a assez bref toute façon cohérente de modéliser les préférences est en fait équivalente à une approche conséquentialiste qui consisterait à maximiser la désirabilité des conséquences probables bref c'est un peu un charabia ce que je viens d'air mais de façon cruciale ce théorème montre que pour penser l'incertitude de manière cohérente on peut utiliser le cadre conséquentialiste sans perte de généralités quoi qu'il en soit c'est bel et bien ce cadre conséquentialiste qui gouvernent les actions d iliad aujourd'hui et probablement celle du futur comme on en a parlé dans l'épisode précédent saisir reçoivent des carottes et des bâtons qui correspondent souvent le conteur et elles doivent maximiser les carottes et minimiser les coups de bâton ce qui revient le plus souvent à faire augmenter leur compteur ce compteur est alors l'objectif final désir et en corollaire immédiat de ce cadre est ce que nick bostrom a appelé la thèse de l'orthogonalité cette thèse postule qu'à peu près tout objectif final est compatible avec une grande intelligence c'est à peu près une trivialité mathématiques on peut donner à lire n'importe quel conteur à maximiser que ce compteur soit le wat stein youtube le pib d'un pays où le bonheur global mais ce qui est intéressant c'est que ça heurte le sens commun qui voudrait qu avec intelligence bien la sagesse et qu'avec la sagesse vient la bienveillance et les valeurs morales en particulier on a tendance à penser qu'une personne intelligente ne va pas vouloir des choses débiles comme collecter un maximum d'autographes de britney spears ou maximiser le nombre de trombone dans l'univers sauf que pourquoi pas si le compteur de l'ia est le nombre d'autographes de britney spears ou le nombre de trombone dans l'univers alors lille fera tout pour maximiser ce compteur surtout s'il ya est très intelligente l'ia est avant tout une machine à maximiser et n'importe quel objectif final et maxime is able par l'ia en particulier ce n'est pas en devenant super intelligente qu'une ia ora par magie une morale aligné avec la morale des humains ou qu'elle aura tout à coup l'objectif final de détruire l'humanité l'objectif final de l'ia sera ce que les programmeurs ont programmé ceci dit on peut toutefois raisonnablement prévoir certains comportements d'unia de niveau humain oui parce que quand on veut atteindre son objectif final il y à quelques mesures à prendre qui sont les mêmes quelle que soit cet objectif final typiquement si les aveux des autographes de britney spears elle aura certainement tout intérêt à se créer un réseau de connaissances et à gagner en influence et pour y arriver il aura tout intérêt à mieux comprendre le monde qui l'entourent ce qui pourra se faire en augmentant sa propre intelligence et en acquérant des données et des ressources mieux encore pour éviter qu'on ne l'était nikunau l'art programme uni ha dont l'objectif est de maximiser le nombre d'autographes de britney spears aura tout intérêt à développer un instinct de survie à s'auto répliqué ou à créer des variantes d'elle-même avec le même objectif et à faire attention à ce que personne ne vienne modifier son objectif dans tous ces cas on parle d'objectif instrumentaux les objectifs instrumentaux sont des étapes 1 remédièrent pour arriver à l'objectif final est ce qui est important de noter c'est que ces objectifs instrumentaux sont souvent les mêmes quels que soient les objectifs finaux on parle de convergence instrumental la convergence instrumentale c'est l'idée selon laquelle la plupart des objectifs finaux implique les mêmes objectifs instrumentaux d'ailleurs ses objectifs instrumentaux ne sont pas spécifiques aux ja quelle que soit la carrière que vous voulez faire ou vous a sans doute conseillé de faire une terminale s voir si vous étiez bons élèves de faire des classes préparatoires pour intégrer une grande école pourquoi parce que ce parcours est un objectif instrumental qui vous sera utile pour quasiment n'importe quel objectif final que vous envisagez et oui parce que ce parcours vous permet de vous auto améliorer d'acquérir des connaissances et de gagner de l'influencé le constat de la convergence instrumentale des objectifs finaux pose d'ailleurs un autre problème fondamental il est difficile d'inférer des comportements des individus la nature de leurs objectifs finaux en effet que vous soyez un saint qui veut sauver le monde des maladies de la famine et des catastrophes un diable qui veut torturé un maximum de bb à des fins récréatives ou unis à qui veut maximiser le nombre d'autographes de britney spears vos comportements initiaux risque fort d'être les mêmes puisque ces comportements initiaux seront bien plus motivés par les objectifs instrumentaux que directement par les objectifs finaux en particulier il ya un point commun à tous ceux qui veulent réaliser leur rêve il leur faut gagner du pouvoir même si votre rêve est de mettre fin à l'extrême pauvreté dans le monde ou de sauver la biodiversité vos incentives son d'acquérir de l'influencé de la compétence pour acquérir plus de pouvoir en fait vouloir le pouvoir n'est absolument pas un signe de malveillance il s'agit avant tout d'un signe d'intelligence et c'est pour ça que comme tout individu fortement motivée par un objectif final lié à deux niveaux humain sera assoiffé de pouvoir tout ça parce qu'il s'agira certainement d'un objectif instrumentale que d'avoir ce pouvoir que l'objectif final soit la maximisation des autographes de britney spears ou l'éradication de la misère humaine alors idéalement bien sûr on aimerait savoir s'il n'y a de niveau humain qui demande plus de pouvoir souhaite l'un ou l'autre malheureusement la convergence instruments tels montre justement que les comportements de deuxième avec deux objectifs nos différents seront en fait assez indiscernables pire encore ces comportements seront d'autant plus indiscernable que la révélation des objectifs finaux est un frein à l'accès au pouvoir autrement dit si unis à deux niveaux humain c'est qu'elle doit donner l'impression de vouloir éradiquer la misère humaine pour avoir plus de pouvoir sachant que son objectif instrumentale est d'avoir plus de pouvoir il lui faudra se comporter de manière indiscernable d'unia qui voudrait effectivement éradiquer la misère humaine du coup à cause de la convergence instrumental il sera sans doute impossible de tester la bienveillance des ados niveau humain c'est ce que l'on appelle parfois le problème du contrôle désir et malheureusement il semble que tester et surveiller les ya deux niveaux humain ne donnera aucune indication sur la bienveillance des ia pour maximiser les chances que daisy à deux niveaux humain soit vraiment bienveillante plutôt que de les tester et les surveiller il semble alors indispensable de s'assurer qu'au moment de leur conception des valeurs suffisamment aligné avec la morale humaine seront intégrés dans l'objectif final de sesia autrement dit le sort de l'humanité pourrait bien dépendre de la manière dont on programme la morale désir l'année afin d'en parler de l'apprentissage pas renforcement qui est le paradigme des intelligences artificielles les plus impressionnantes d'aujourd'hui notamment des influences artistiques sont capables d'interagir avec un environnement complexe et d'apprendre en temps réel de leurs interactions avec cet environnement complexe et j'avais parlé de nombreuses applications de ce paradigme a donc notamment des jeux vidéo comme dota 2 et capture the flag et je ne suis pas franchement un gamer donc je sais pas exactement je serais assez mal tous ces jeux et défaire et d'autres parmi nous ont fait remarquer en fait à starcraft l'ia n'a pas encore atteint assez mauvaises ce rapport aux humains donc il ya n'est pas du tout de niveau 1 aujourd'hui à starcraft donc mea culpa pour l'erreur que j'ai faite sébastien dufour parle d'une énergie qu'on préfère entre la programmation de la morale des ia et les textes de loi puisque dans les deux cas il s'agit de textes écrits font de choses écrites qui seront appliqués en pratique pour résoudre des problèmes finalement viré à la morale cependant sébastien fait très bien la remarque qu'il ya une différence assez importante entre un texte de loi et le club d'une intelligence artificielle savoir le fait que le code d'entrée dans sa suite elle sera appliquée telle quelle alors que les textes de loi sont adaptés ensuite par des juges qui adapte à chaque fois au cas par cas et ça permet de une serre venir corriger des imprécisions ou des choses qui sont en fait pas souhaitable et qui sont dans la loi c'est une remarque très pertinente est très importante à faire c'est le fait que contrairement aux textes de loi le code d'unia sera appliqué tel quel et c'est pour ça que c'est extrêmement important que le code de lelias on jouait comme double tchèque et que ça marche vraiment vraiment vraiment bien et la difficulté de décrire un code comme ça est d'anticiper ces contextes les applications et un changement contextuel de l'environnement d'application au fure du temps c'est quelque chose qui est extrêmement difficile à prévoir et en fait il est même assez illusoire de penser qu'un programmeur d'aujourd'hui saura bien résoudre ce cas puisque toi ce nombre d'incertitudes sur le futur par exemple sur des skis orignal de niveau humain ou apprend plein de choses le futur est très très incertain et du coup c'est très très problématique de vouloir dire directement à lire ce qu'elle doit faire c'est pour ça que l' approche conséquences et les soucis mais ça me paraît beaucoup beaucoup plus pertinentes on semble ce sera beaucoup plus réalisable beaucoup plus raisonnable qu'une approche est donc logique qu'ils pourraient se rencontrer à dire il ya tout ce qu'elle doit faire à tout moment puisque par sombrer texte doit servir on y arrive clairement pas et il faut absolument des juges pour créer et interpréter la loi au cas par cas enfin yannick du fils à faire la remarque finalement que ces bateaux à ces carottes ça s'applique non seulement à des humains parce que vous avez parlé dans l'épisode précédent mais aussi à des groupes d'humains finalement on peut voir un groupe du moins comme une entité et qui a souvent un objectif et qui va aller recevoir des carottes et on entend et il ya comme des détails en france où un groupe d'humains souvent si on prend une entreprise finalement il ya toujours des intérêts individuels à l'intérieur de l'entreprise et du coup tout le monde ne travaille pas pour le même objectif final mais d'une certaine manière il y as est analogique qui me semble très pertinente entre une intelligence artificielle est une organisation que ce soit un pays ou une entreprise dans les deux cas en fait il s'agit on parle parfois de super intelligence sociale ou d'intelligence sociale du coi pour parler de ces entreprises de ces pays qui arrivent à interagir entre eux et faire des choses qui est un individu seul tout seul n'est pas capable de faire je vous renvoie notamment vers la conférence de monsieur je vous avais parlé de ça si on pense par exemple au fait de d'envoyer un homme sur la lune c'est quelque chose qui est juste pas réalisable par un individu est en fait il s'agit du tout une une organisation qui est capable de mettre ça en place et dans les deux cas et c'est intéressant de voir que le problème du contrôle de ces super intelligence sociale ou artificielle est quelque chose d'extrêmement difficile et est ce qu'on a mis en place initialement probablement assez rapidement déraillé et est parti hier par d'autres d'autres pistes c'est pour ça que le problème de coder la morale désir a décidé d'anticiper d'avoir un truc robuste à tous les futurs possibles il ya beaucoup de figures possibles vu une autre incertitude aujourd'hui c'est un problème extrêmement difficile un problème digne des plus grands talents mathématiques de la future génération d'après boston je pense que c'est m faut que ça s'est un peu plusieurs gens qui sont aujourd'hui il travaille c'est aussi un problème qui est absolument xchanging quoi ces genres le genre de problème je pense que vraiment se poser en observer le plein de comment faire en sorte d'avoir un système robuste avec les valeurs morales humaines c'est juste un problème magnifique c'est peut-être le l'un des plus beaux problèmes à résoudre aujourd'hui si je dis ça c'est c'est pour motiver les gens formés ou qui seraient des étudiants en master ou des doctorants ou des chercheurs parmi vous pour essayer de vous orienter un petit peu plus vers cet axe de recharge je pense qu'il ya vraiment plein de questions fascinantes et que c'est un domaine extrêmement stimulant intellectuellement malheureusement aujourd'hui pour être honnête avec vous bon je pense que c'est encore assez difficile d'avoir une carrière académique avec ça parce qu'il va forcément encore de très grandes communautés qui travaillent sur ce problème mais j'ose espérer que dans les années à venir ça va ça va venir que du coup après j'aimerais bien que plus de gens travaillent sur ce problème c'est le futur de la mi ou de l'humanité qui est en jeu j'ai envie de dire et j'espère qu'ils avaient mais secafi âgées que ça vous a convaincu de l'importance de bien programmé la morale des ia en particules à prochainement on va parler de quelle morale programmés dans les intelligences artificielles et ça sera un épisode qui sera aussi très pertinent pour mieux penser notre moral intuitive la manière dont on pense au château compte ce qui est moralement bien et ce qui est moralement mal si vous avez aimé cet épisode conseil local quant à lui partagé pensez à vous abonner pendant quelques épisodes merci aux outils propres à redon et j'espère que vous serez là la prochaine fois [Musique]