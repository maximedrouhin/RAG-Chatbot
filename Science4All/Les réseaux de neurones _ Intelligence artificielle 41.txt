après avoir longuement parlé des conséquences sociales de l'intelligence artificielle et notamment de la super intelligence on en vient enfin à l'aspect technique des meilleurs ziad aujourd'hui aujourd'hui on va enfin parler des réseaux de neurones artificiels alors un réseau de neurones c'est quoi ben tout bêtement un réseau de neurones c'est un ensemble de neurones généralement virtuel disposés en réseau virtuel autrement dit chaque neurone est un point du réseau qui reçoit de l'information en 30 et qui émet de l'information sortante tout simplement alors on des réseaux très généraux on pourrait imaginer que l'information entrantes et sortantes est une information possiblement très sophistiqué typiquement entre les serveurs d'internet l'information communiquée de serveur à serveur peut être aussi compliqué qu'un site web qu'une image jpeg aucune vidéo youtube mais le pari ambitieux des réseaux de neurones c'est de se restreindre à l'information la plus élémentaire qui soit les signaux qu'envoie les neurones sont tous vêtements des intensités de signaux autrement dit un euro ne peut rester silencieux ce qui correspond aux ouvriers le nombre 0 ou plus ou moins s'activer en envoyant un nombre plus ou moins grand dans un réseau de neurones il existe des neurones un peu particulier qui sont ceux en charge de capter les données extérieures on parle parfois de première couche de neurones et dans mon livre j'ai parlé de neurones observable en philosophie russell appellera ça descende data et en machine learning on parle souvent de données brutes ces données vont ils peuvent typiquement correspondre à l'amplitude du son d'une musique peut l'être des mots d'un roman ou aux couleurs des pixels d'une image les neurones observable vont typiquement lire ces données brutes et un neurone observable va typiquement s'activer si son morceau de données brutes correspond à son activation typiquement un neurone observable exposé un pixel très lumineux pourrait beaucoup s'activer neurones observable active et vont alors envoyé des signaux le long des flèches du réseau par analogie avec la biologie ses flèches sont parfois appelés synapses les neurones qui reçoivent les signaux des neurones observable sont alors appelés neurones de la seconde couche ce sont eux qui réagissent directement aux signaux des neurones observables et c'est là que les choses intéressantes commence en particulier ce qui va changer complètement le comportement du réseau de neurones c'est la manière dont un neurone de la seconde couche va s'activer ou non en fonction des données qu'on lui envoie pour commencer chaque neurone de la seconde couche va diviser les signaux qu'on lui envoie en deux catégories en fonction de la nature des synapses qui transmettent les signaux il y a d'un côté des synapses activatrice et de l'autre des synapses inhibitrice et même au sein de ces deux catégories 1 euro ne va distinguer des synapses très active et ris et des synapses très inhibitrice et attention je parle bien ici des synapses qui pas des signaux oui parce qu'un signal entrant sera ensuite très activateur si le signal passe par une si noble très activatrice et si ce signal et d'une forte intensité la contribution du signal à l'activation du neurone sera en fait la multiplication entre le coefficient d'activation de la synapse et l'intensité du signal ensuite le neurone va sommer les contributions des signaux activateur ainsi que les contributions des signes aux inhibiteurs et chaque neurone va ajouter son propre billet qui correspond à mettre un certain poids dans l'une des deux piles le neurone s'activera alors si les signaux activateur plus by activateur sont plus importants que les signaux inhibiteur plus vieil ami peter et s'activera même d'autant plus que cette différence de contribution est grande alors il ya encore d'autres subtilités le neurone que j'ai décrit là est ce que l'on appelle un rectif ailleurs l'ignorent unit ou relu certains neurones qui s'il s'active s'activera de manière proportionnelle à la différence de contributions activatrice - inhibitrice mais les chercheurs on ya utilise parfois d'autres types de neurones comme des neurones qui s'activent légèrement quand les contributions inhibitrice l'emportent mais pas trop moyennement qu'on les deux teams de contributions sont à peu près égale pas mal quand les contributions activatrice l'emportent mais pas forcément beaucoup plus quand les contributions activatrice l'emportent très largement ce que je décris la correspond à une courbe en s et es souvent modélisé par ce qu'on appelle la sigmoïde et il existe d'autres façons encore pour un neurone de choisir la manière de s'activer en fonction des signaux qu'il reçoit il peut par exemple utiliser la tangente hyperbolique le max poule ou encore le soft max mieux encore le neurone peut s'activer avec une probabilité qui dépendent des contributions activatrice unis tris et du billet du neurone de façon générale on parle de fonctions d'activation des neurones il y en a énormément leur influence est pas forcément si important du coup je vais les laisser de côté ce qui est important à retenir c'est que pour décider s'il va s'activer un neurone compile les signaux activateur entrants dont les intensités sont multipliées par le degré d'activation de la synapse ainsi que par les signaux inhibiteur entrants qui subissent la même opération le neurone y ajoute un billet puis en fonction du résultat et d'une certaine fonction d'activation détermine s'il va s'activer ou non et à quel point il va s'activer et en fait ce que je raconte là c'est un petit peu alambiqué c'est pas vraiment ce que l'on raconte dans un cours sur le réseau de neurones puisqu'en fait tout ça correspond à des opérations mathématiques beaucoup plus simple mais aussi possiblement un peu plus abstraite ainsi en considérant que les degrés d'activation ou d'inhibition des synapses sont des nombres réels appelé les poids des synapses avec un signe négatif pour les synapses inhibitrice la différence entre les contributions activatrice et inhibitrice arbitres et qui plus est par le biais du neurone correspond en fait à ce qu'on appelle une forme linéaire des intensités des signaux plus une constante l'activation d'une eau rhône est alors une fonction non linéaire de cette forme linéaire en fait l'activation du neurone et ce que l'on obtient quand on applique la fonction d'activation à cette forme linéaire bref si je récapitule chaque neurone collecte des signaux entrants pondérée par les propriétés des synapses à travers lesquels passent ces signaux le neurone applique ensuite une certaine fonction d'activation et décide ainsi de s'activer ou non on peut maintenant essayer de dézoomer faut maintenant imaginez que dans le réseau de neurones chaque neurone de la seconde couche effectué ce genre de calcul à partir des signaux de la première couche ainsi on a une liste de neurones de la seconde couche qui s'activent ou non ceux qui envoient des signaux à des neurones de la troisième couche qui vont alors effectué les mêmes types de calculs et ainsi de suite de couches en couches alors ce que je décris la est en fait un cas particulier de réseaux de neurones appelé réseau fit foward que l'on pourrait traduire par réseaux unidirectionnels oui parce que les signaux vont toujours de la gauche vers la droite ils ne vont donc que dans une seule direction al'inverse on pourrait avoir des signaux qui boucle auquel cas on parlerait de réseaux de neurones récurrents ou rnn puis ça on en reparlera une autre fois ok c'est bien joli tout ça mais à quoi ça sert et bien comme on l'a vu dans des épisodes précédents de tels réseaux de neurones peuvent servir à pas mal de choses typiquement en mettant un haut rhône finale en bout de ligne un tel réseau peut permettre de faire de la classification c'est-à-dire qui nous permettrait de dire si les données correspondent à x ou à non exposé en pl si le réseau de neurones est entraînée pour reconnaître des chats dans une image l'activation du neurone finale pourrait correspondre à la présence de chats dans l'image et ça non activation à l'absence de chat mais on peut aussi avoir des applications plus subtils comme par exemple extraire des données brutes une sémantique dans ce cas on aurait plusieurs neurones finaux peut être 50 100 ou 300 la sémantique des données brutes correspondrait alors à la combinaison d'activation des neurones finaux mathématiquement on peut tout bêtement collecter les niveau d'activation des neurones finaux qui sont possiblement égaux à zéro en cas de non activation l'ensemble de ces niveau d'activation forme alors ce qu'on appelle un vecteur ce qui nous fournit une représentation vectorielle des données brutes avec toutes les applications dont on a déjà parlé dans les épisodes 22 et 23 en fait si on essaie vraiment de prendre du recul et d'analyser le problème de manière très abstraite un réseau de neurones ni en fait ni plus ni moins qu'une fonction c'est-à-dire une machine à calculer qui prend en entrée un vecteur de grandes dimensions et qui ressort un autre vecteur de cons dimension nous encore dans le cas d'un réseau fit for world on sait que la sortie s'écrira comme étant une succession de combinaisons linéaire de signaux d'une couche précédentes auxquelles sont appliquées des fonctions d'activation en termes mathématiques pour ceux qui veulent vraiment le savoir si on appelle x le vecteur d'entrée la fonction calculé par le réseau de neurones correspond à appliquer une transformation linéaire w1 ax pour inclure les effets des premières synapses puis une fonction d'activation sigma à chaque coordonnées du vecteur w 1 x puis une seconde transformation linéaire w2 aux signaux sigma w 1 x sortant de la première couche puis à pic à nouveau des fonctions d'activation sigma aux coordonnées de w2 fois sigma de double 1 x et ainsi de suite un réseau de neurones n'est donc qu'une succession de composition de transformation linéaire et d'opérateurs non linéaire qui agissent indépendamment sur chaque coordonnées bref si vous n'avez pas compris ça c'est vraiment pas grave en fait le calcul d'un réseau de neurones n'a rien de bien merveilleux d'ailleurs quand j'ai compris cela en 2011 je me suis dit que c'était même un peu pourri d'un point de vue mathématique ça ressemble à un gros bidouillage dont on n'a pas franchement de bonnes raisons de penser que ça va donner quoi que ce soit de bien et bien le lait de 2011 avait tort mais la question intéressante c'est de déterminer en quoi ils avaient tort en particulier comment est-ce qu'en 2011 une époque où les réseaux de neurones avait pas encore connu de réels succès empirique pouvait-on néanmoins prévoir qu'on tenait là une technologie futuriste et bien je trouve intéressant de laisser le lait de 2011 de côté parce qu'il est franchement ignorant pour nous attarder au lait de 2016 oui parce que le lait de 2016 lui il y avait constaté les prouesses des réseaux de neurones mais en croire ce commentaire youtube le lait de 2016 était encore très perplexe quant au succès des réseaux de neurones vous noterez que je me demande si la question de savoir si un réseau de neurones est vraiment la bonne architecture et d'une question à quelle est difficile de donner un sens est d'ailleurs un que formaliser la notion de bonne architecture pour faire du machine learning et que c'est un problème assez nom tribal encore aujourd'hui vous voyez aussi que le lait de 2016 parle de dimension wc et de pâques learning et qu'il a l'air pas mal séduit mais pas totalement convaincu hélas ça n'a pas trop changé surtout sur la partie pas convaincu vous voyez aussi que je mentionne bays mais clairement à ce moment là je ne suis absolument pas encore le balisier un extrémiste que je suis aujourd'hui d'ailleurs le lait de 2016 utilise bays pourra essayer d'expliquer les réseaux de neurones comme si belle n'était qu'un outil pour mieux savoir dans certains cas alala les de 2016 espèce de pseudo bayésiens purement instrumentaliste bon ceci dit il ya des choses plus intéressantes dans les commentaires du lait de 2016 en particulier le lait de 2016 propose quatre pistes pour essayer d expliquer le succès des réseaux de neurones ainsi qu'un etc j'avais aujourd'hui je sais pas trop ce qu'il ya derrière eux et cetera alors si comme derrière le etc il ya le théorème mentionné par la vidéo que je commentais à savoir le théorème d'approximations universel ce théorème dit qu'un réseau de neurones artificiels peut calculer arbitrairement bien n'importe quelle fonction autrement dit prenez n'importe quelle fonction d'un espace vectoriel berra notre espace vectoriel à quelques détails de nombreux positif de bornes prêt pour toute erreur d'approximations prédéterminé epsilon il existe un réseau de neurones qui fait une approximation de la fonction en question ait si le rêve autrement dit en gros un réseau de neurones n'a pas d'angle mort il peut essentiellement tout faire alors ça c'est vraiment cool comme théorème mais en fait c'est loin d'expliquer le succès des réseaux de neurones par opposition à toute autre approche de machine learning oui parce que des architectures de calcul qui satisfont ce genre de touraine et on a en fait plein à commencer par les machines universel de turenne qui elles sont capables de calculer n'importe quelle fonction calculable une réponse plus convaincante qui distingue les réseaux de neurones des autres architectures de calcul et l'extrême parallélisation du calcul qu'ils permettent en effet pour effectuer le calcul chaque neurone peut raisonner de façon purement locale indépendamment du reste du réseau car comme on vient de le voir le noronha à se soucier que des signaux qui lui sont envoyées et il n'a qu'à envoyer des signaux à travers les synapses sortante est d'ailleurs de nos joueurs beaucoup d'efforts sont faits dans la recherche en architecture de calcul neuromorphic ou ses neurones serait d entité physique et non virtuel comme c'est le cas aujourd'hui ce qui pourrait conduire à des progrès drastiques dans les performances de calcul désire cependant cet argument qui deviendra sans doute décisif dans les années à venir était en fait pas totalement convaincant pour expliquer le succès des réseaux de neurones de 2015 qui eux l'exploité pas forcément à fond cette part à lisa sion du calcul bon ensuite il ya l'argument de l'implémentation du rasoir d'occam qui jouent à ce qu'on en fait l épisode 18 qui revient à préférer des réseaux de neurones dont les poids synaptique sont faibles et en effet ça fait une jolie solutions pour combattre efficacement le problème de la surinterprétation dont on a très longuement parlé dans les épisodes 11 à 18 mais bon de là à dire que ça explique le succès des réseaux de neurones il ya un grand écart à faire ou à ne pas faire enfin le dernier argument est un lien avec les représentations graphiques des lois de probabilité dont je parle longuement dans le chapitre 17 de mon livre mais bon comme tout quatrième argument c'est pas le plus convaincant en fait aujourd'hui s'il me faut expliquer le succès des réseaux de neurones j'irais plutôt piocher dans le deuxième argument du lait de 2016 à savoir ces histoires de gradient facile à kehl les car je pense que combiner avec un autre argument algorithmique sur lequel on reviendra plus tard c'est bel et bien cette histoire de gradient qui fait le succès des réseaux de neurones d'aujourd'hui mais ça on en reparle la semaine prochaine un enfant n'a parlé désirs et leurs capacités à hacker leur propre morale en particulier leur circuit de la récompense est anonyme nous demanda si finalement il n'aura pas la même chose chez les humains il aurait fait carrément en fait c'est humain il ya plein de façons de hacker en fait notre circuit de la récompense pour faire des trucs qui sont pas vraiment ce que on va dire que l'humain est censé faire d'habitude mais qui nous provoquant malgré tout ce genre de récompense donc l'exemple le plus parlant de ça c'est sans doute la consommation de drogue mais aussi pardon de la consommation de jeux vidéo ou la consommation de plein de choses qui ne font plaisir par exemple et surf et tout ça c'est des façons d'activer votre circuit de la récompense pour des raisons qui sont pas nécessairement la raison pour laquelle le circulent à la récompense a été conçu en premier lieu et d'ailleurs avec l'exemple des drogues par exemple si on commence à devenir addict et que l'on veut vraiment désespérément avoir de la drogue on peut potentiellement avoir des dérives un petit peu dangereuse et c'est pour cette même raison qu'une ia qui ferait du wire reding qui cherche qui fait craquer son circuit de la récompense doit devenir dangereuse parce qu'elle cherchera à protéger il a continué à avoir son circuit de la récompense acte iv est amer façon d'y arriver peut se faire au détriment des autres personnes chez l'humain une façon justement de hacker s'être propre morale et qui peut être ben là pour le coup beaucoup plus subtil et avait vraiment dangereuse en ce sens c'est tout le phénomène de la rationalisation c'est à dire on a tendance à avoir commis des actions et à penser que nous des gens bien et du coup à modeler notre moral pour faire en sorte que malgré nos actions soient quand même des gens bien voir que grâce à ces actions que ces actions font de nouveau fait des gens bien et du coup il ya tout ce phénomène de rationalisation on a beaucoup parlé de rationalisation ce phénomène on a eu une intuition et on cherche avant tout à la défendre quitte à ne pas utiliser des arguments rationnels et à utiliser uniquement des arguments qui vont dans notre sens il a complètement dénigrer les voir tourner en dérision les arguments qu'il ait dû composer ou qui l'attiré pas dans notre sens malheureusement nous autres humains avons cette façon de hacker notre propre morale et du coup de la modifier pour faire en sorte que nous soyons déjà en moralement bien je pense que c'est important quand on réfléchira à lamoura de commencer par m la question de est ce qu on est déjà en morale un peu de côté pour ce coup poser la question uniquement de quel est le bon jugement moral à avoir donc indépendamment de est-ce qu'on est mort à la limite oublier si nous individuellement on est des gens moreau pour pouvoir parler de la morale de façon plus générale je pense que c'est une astuce pour réfléchir la morale qui est absolument indispensable pour éviter le piège de la rationalisation chez nos demandes justement si le contrôle du circuit de récompense devra être justement assez indépendant tant que possible de liga qu'ils ont prises de recharge des décisions et en effet c'est exactement ce que je propose dans mon papier sur comment programmer des valeurs morales dans une île de façon robuste il faut en fait absolument que le circuit de la récompense soit aussi indépendant que possible de l'intelligence artificielle qui ont charge de prendre des décisions mais même là ça reste très compliquée puisque cette intelligence artiste qui prend des décisions elle peut agir sur le monde par exemple en mettant en envoyant des messages à travers internet et un message à travers internet donc un cas assez extrêmes ça pourra dire à une ample en 3d d'imprimer un drone tueur ou autre ça pourrait être des messages qui font du chantage qui amène certains humains à prendre telle ou telle décision et ça doit être un peu  en l'air je suis pas en marchés financiers pour qu'il se passe telle ou telle chose voilà il ya beaucoup de chose qu'une ya peu faire juste en envoyant des messages qui en fait aujourd'hui on est incroyablement dépendant de toute autre structure d'information essence lacunes ya déjà énormément de pouvoir et donc en particulier une telle ya on peut imaginer qu'elle peut mettre plein de choses en place pour hacker son circuit de la récompense c'est pour ça que dans le circuit de la récompense en fait il soit il me semble indispensable qu'il y ait un système d'incentive d'ailleurs qu'il flou que le circuit de la récompense motive l'intelligence artificielle à protéger le circuit de la récompense et à ne pas le modifier c'est quelque chose qui nous arrive aussi beaucoup nous autres humains mois typiquement parfois j'ai pas envie de travailler je suis fatigué j'ai juste envie de regarder des séries sur netflix une certaine manière c'est une façon de hacker mon circuit de récompense et du coup parfois je me force à ne pas avoir ce genre de récompense direct et une certaine air jeux à claquage le nom circula récompense faisant exprès de me mettre dans des conditions où elle jouera pas forcément la facilité ou l' envie de regarder une donald phoenix ou de traîner sur twitter j'essaie de mettre en place dans ma vie des moments où vraiment je peux travailler faire ce que je veux que je fasse et du coup c'est un espèce de meta a cage de mon circuit la récompense est très probablement il va falloir que le système d'intelligence artificielle comme françois et des propriétés similaires c'est à dire qu'il faut qu'ils valorisent le fait de ne pas attaquer son circuit de la récompense d'une certaine manière de mettre un système de hackage contre le hac âge du circuit de récompense ouais c'est un petit peu mais tu as et malheureusement je vois pas de meilleure solution que cela est malheureusement également il ya encore très peu de théorie qui sont développés sur comment bien faire cela c'est pour ça que je pense vraiment que le problème de valve iodine problème le problème de coder la morale des désirs est un problème extrêmement difficile qui est encore très très peu étudiée il faut absolument que beaucoup plus de gens s'y intéressent pas bon ce possible des chercheurs de haut calibre enfin yohann grosso se demande c'est après toutes ces vidéos sur les a finalement on aura pas de livraisons de flipper du coup de vouloir vraiment ralentir la recherche sur l'intelligence artificielle est de diminuer le rythme de progrès pour au moins avoir plus de temps pour bien réfléchir aux questions de sécurité de l'intelligence artificielle et ça c'est exactement la réaction que j'ai eu plus je me mets à réfléchir ce problème de la morale les ja je me dis qu'on n'est absolument pas pour pouvoir réussir à résoudre ce problème plus je me dis qu'il nous faudra de temps et plus je me dis que ça serait bien que la recherche n'avance pas aussi vite qu'elle n'avance aujourd'hui et ça ça énerve beaucoup les chercheurs en ia qui veulent continuer à faire des trucs trop bien on ira et être à la pointe du domaine et du coup c'est pas forcément la meilleure stratégie de communication que de dire il faut absolument je retire la recherche on n'y a typiquement si je dis c'est un peu trop fort je risque de me faire marginaliser et tourné en ridicule et aujourd'hui les réseaux sociaux sont très très fortes pour tourner un individu en particulier en ridicule qui plus est de toute façon j'ai envie de dire malheureusement aujourd'hui les incentives pour utiliser les ja sont juste énormes à la fois d'un point de vue économique c'est pour ça qu'il ya un petit peu une guerre aujourd'hui entre différents pays des grands projets qui sont lancés y compris en france pour développer l'intelligence artificielle et être dans la course au maintien artificielle et peut-être même dépassé la chine je sais pas trop quoi encore ce genre de réaction incentive individuel en fait des ja est malheureusement très difficile à combattre les incentives économiques sont juste énormes et du coup ça me semble assez difficile aujourd'hui de demander la réduction du rythme de la recherche on n'y a malheureusement le progrès avance et incentives de fond que le programme continuera certainement avancer quoi que je fasse en tout cas et autres 4 semble très très difficile de ralentir son rythme alors je suis en train de mettre une mauvaise image de cette recherche heures entières artificiel mais il ya aussi une autre raison pour lesquelles le sait il ya de vrais incentive pas juste économique mais aussi des incentives moreau à continuer la recherche en intelligence artificielle par exemple pour pouvoir sauver des vies on a vu les applications en santé on a aussi parlé des applications dans le domaine du transport tout ça ça correspond à sauver des milliers de vie voire les peut-être même des millions de vies par an donc les incentives morale à développer son intelligence artificielle est quand même assez énorme et enfin il ya une autre raison pour laquelle si on est préoccupé par ces problèmes de sécurité on n'y a en fait la bonne stratégie c'est sans doute d'accélérer notre propre recherche en ligne a dû casser la position qui a pris open et ike qui sur son blog annonce assez clairement qu'ils sont très concernées par ce risque de danger existentiel des ia mais il ajoute que la meilleure façon d'après eux à leur place étant donné la structure qu'ils ont tous à la meilleure façon de lutter contre ça c'est de continuer à être à la pointe du domaine parce que si on n'est pas à la pointe du domaine eh bien on peut pas influencer le développement de sesia et du coup il ya une course alia qui est nécessaire pour ceux qui veulent implémenter des solutions de sécurité en irak bref tout ça pour dire que ralentir le programme ya ça me semble malheureusement très difficile aujourd'hui et que la meilleure stratégie ça consiste sans doute à si on veut vraiment faire du bien à se mettre à jour sur l'ir a essayé de maîtriser les outils moins conceptuel autour de la recherche mia et d'essayer d'y ajouter un petit peu une petite pierre à l'édifice et cette pierre c'est pour être sceptique et cette pierre ça serait typiquement des solutions de sécurité on ira tu as c'est vraiment la position que j'ai essayé de prendre dans mon papier ou vraiment je pense que c'est très important et plusieurs phrases qui en parle de proposer des solutions aussi facile à implémenter que possible pour les entreprises qui font déjà de l'intelligence artificielle faux pas on peut pas leur demander de retraire monteiro et de refaire tout leur système l'idéal c'est plus d'avoir des solutions qui peuvent ajouter à leur système à faible coût et qui permettront de bien mieux encoder une par une morale izia ou réduire en tout cas les risques causés potence potentiellement causé par une intelligence artificielle bref en plus des défis technologiques qui sont énormes il y à des défis dean säntis des défis sociaux économiques voire culturelles qui font que le problème de coder la morale désir est un problème qui en fait incroyablement difficile et d'ailleurs dans mon papier je parle assez longuement des défis qui sont non technique parce qu'il y en a à mon avis énormément qu'il va nous falloir résoudre si on veut avoir une chance de bien programmé la morale désir pour éviter une destruction de l'humanité est d'isoler les fins diversement c'est un petit peu catastrophiste est assez préoccupante c'est un petit peu mais discussion du moment mais ça n'empêche pas de garder le sourire parce que les défis technologiques notamment ce mois c'est merveilleux et si on voit ça comme un défi je pense qu'il ya de quoi trouver ça assez les stimulants tuque et intellectuellement et j'espère que j'avais mais cette vidéo la préhistoire on va parler d'un truc est pas tout à fait sur les réseaux de neurones en particulier mais qui a un truc à elle c'est plus générale en fait aux machines au rni qui est ce qu'on appelle la descente de gradient et en particulier la descente de gradient stochastique qui a notamment des jolies lien avec la formule de berry c'est si vous avez aimé cet épisode ansa le lac est le commentaire de partage et pensez à vous abonner pour ne pas manquer les futurs épisodes mercière le tibet en couleur dont et j'espère que vous serez là la prochaine fois donc chaque neurone d'une couche va recevoir les données de la couche précédente faire ses petits calculs puis donner le résultat à tous les neurones de la couche suivante mais il y en a deux qui sortent un peu du lot comme la première rangée qui va recevoir les nombreux qu'on souhaite étudier et 6 à ceux qui viennent d l'image et la dernière qui va nous donner la réponse en l'occurrence un ou zéro