aujourd'hui c'est le grand retour des vidéos hardcore donc on va parler des mathématiques dédiées à démocratiques en particulier de la médiane géométrique si vous ne voyez pas du coup de quoi je parle je vous renvoie vers la dernière vidéo que j'ai faite qui s'appelle les maths desire démocratiques ou je parle notamment de cet objet qui est la médiane géométrique donc aujourd'hui donc vidéo hardcore on va rentrer un peu dans les détails en particulier de la preuve qu'on a coécrite avec d'autres chercheurs sur la stratégie professionnelle c'est à dire les intérêts à mentir lorsqu'on utilise la médiane géométrique et voilà j'espère que vous êtes prêts et que vous êtes bien accroché parce que ça va être un épisode d'accord donc ça peut être forcément facile à suivre alors pour commencer je vais vous rappeler ce qu'est la médiane géométrique donc comme je l'ai dit dans la vidéo en fait la façon la plus simple de définir la médiane géométrique c'est comme étant le minimum d'une d'un problème d'optimisation en l'occurrence on reçoit un certain nombre grand V de vecteurs donc V c'est pour voter donc c'est une version anglaise et les électeurs et donc on suppose qu'on a un nombre grand V d'électeurs qui participent au système et chacun des électeurs va fournir un vecteur supposé qu'il s'agit d'un vecteur dans l'espace client RD donc typiquement et donc dans cet espace client c'est naturel de définir la médiane géométrique comme étant un point qui est mise à somme des distances au vecteur de chacun des électeurs donc là je m'énerve géométrique minimise est un hargimine de la somme des distances au têta V vous pouvez varie de 1 jusqu'à grand V c'est à dire que V est un des électeurs donc pour utiliser le langage un peu plus du machine learning on va appeler la somme des distances comme étant la l'os donc la fonction pas à minimiser la fonction de perte parfois on l'appelle et cette fonction de perte donc c'est une fonction du point Z et donc le minimum est atteint un million de géométrique et ça c'est intéressant de voir comment cette fonction de perte varie en fonction de la valeur de Z mais également en fonction de la valeur des en particulier d'un têta V malveillant ou stratégique plutôt donc c'est vraiment ce qu'on va faire dans cette vidéo et on va voir que beaucoup des propriétés qu'on a démontré découlent de cette étude de cette fonction en particulier après chose qu'on peut voir c'est que la condition d'optimalité qui correspond à dire que le gradient de de cette loss par rapport à Z est égal à 0 en la médiane géométrique ça ça se traduit par lorsqu'on calcule les dérivés en fait des des normes en fait le gradient du norme c'est égal au vecteur unitaire et ça vous pouvez le démontrer mathématiquement suivi de faire les calculs mais je trouve ça plus intéressant d'avoir l'intuition géométrique derrière ça ben intuitivement d'un point de géométrique qu'est-ce qui se passe tout simplement lorsque l'on se déplace le long du vecteur d'un pas la distance la norme du coup va augmenter de ce nombre de pas donc la distance augmente proportionnellement au nombre de pas même est égal au nombre de pas que l'on fait si ce pas est effectué dans la direction qui va du point Z au TTV et donc le fait qu'il est cette relation ça me fasse mieux un vecteur unitaire et pareil la direction nous dit bien que que ce gradient est dans la direction de tetavé - Z notre façon de voir ça c'est que si on se déplace perpendiculairement à la direction que tu avais - Z à ce moment là en première au premier ordre la distance ne va pas évoluer puisque si on se déplace orthogonalement à cette direction bah on va se déplacer ponctuellement sur le cercle de centre téta V et qui par Z et du coup la distance sera inchangée donc c'est pour ça que le gradient de la norme est égal un vecteur unitaire de direction que tu avais - Z même plus précisément c'est dans la direction Z moins étave et donc la condition d'équilibre nous dit simplement que la somme des vecteurs unitaires qui vont de la médiane géométrique vers les tétave la somme de ces vecteurs doit-elle à 0 et ça revient vraiment à dire que chacun tire avec une force unitaire sur un million géométrique et la somme des forces s'annule quelques quelques autres remarques que j'ai envie de faire sur la médias géométrique avant de passer à l'étude des incitatif qu'elle provoque une propriétaire attrillante d'un million de géométrique c'est que puisqu'elle minimise une fonction qui est invariante par isométrie c'est à dire qu'il est temps juste de cette norme quotidienne si on fait n'importe quel opération isométrique sur l'espace alors ça va déplacer à median géométrique de cette même transformation isométrique il y a une invariance par isométrie d'une certaine manière en particulier c'est-à-dire que si on tourne l'espace par exemple et bien de 90 degrés ou de 45 degrés alors la médiane géométrique va se déplacer également de cette rotation de 45 degrés pareil sur la translation donc il y a pas mal d'invarences qui sont assez satisfaisantes d'un point de vue géométrique en tout cas de la médiane géométrique ni une autre propriété que j'ai mentionné dans la fin de la vidéo précédente qui est particulièrement intéressant de géométrique c'est que la mienne géométrique appartient nécessairement à l'enveloppe convexe de l'ensemble des vecteurs qui lui sont rapportés et ça pour le démontrer en fait une preuve assez joli qui consiste à dire que supposons par l'absurde que cette minette géométrique elle n'est pas dans cette enveloppe convexe alors il existe forcément un hyper plan qui sépare cette médiane géométrique des autres points des têta V et à ce moment là ça c'est clair que la somme des forces vertes va pointer dans la direction qui va de la méthode géométrique vers cette hyper plan qui sépare z2tav en particulier cette somme des forces ne peut pas être nulle et donc on a une absurdité puisque somme des forces amidon géométriques nécessairement égal à zéro et donc ça ça montre que forcément la médiane géométrique est dans l'enveloppe convexe c'est quelque chose d'assez satisfaisant en particulier pour les applications comme le vote byzien sécurisé dont peut-être que je ferai une vidéo hardcore dédiée à ça pour vous présenter le problème donc corriger des personnes pour une voix très vite dessus mais en attendant que j'ai le temps et la motivation de faire ça je peux dire vraiment dans quelques mots rapidement en fait ce qui m'intéresse dans le cas du vote basicien sécurisé c'est de généraliser les préférences de quelqu'un à partir seulement de ceux qui l'a exprimé et une façon de faire c'est de voir comment les jugements qu'il a effectués par exemple covary avec les jugements effectués par des gens qui sont semblables ou pas à lui et donc derrière ce calcul de la généralisation des scores d'une individu il y aura ce calcul naturellement qui apparaît d'une matrice de covariance des préférences exprimées par différents contributeurs et jusque là à ma connaissance il y a très peu de recherches sur l'estimation d'une matrice de covariance de manière robuste et en particulier je ne connais pas de travaux qui cherchent à faire cela en calculant explicitement l'influence maximale d'un contributeur sur cette matrice de covariance alors sur tournesol on utilise beaucoup des médianes par coordonnées mais dans le cas des matrices de cohérence et une mauvaise idée d'utiliser une médiane par coordonnée puisque si on calcule par exemple chaque coefficient de la matrice de covariance en prenant par exemple des médias par coordonnées et bien on a aucune garantie que ceux qui sera obtenu et bien une matrice de covariance en particulier que ce soit une matrice semi-définie positive et ça ça vient vraiment du fait que la médiane par coordonnée n'est pas dans l'enveloppe convexe des vecteurs qui lui sont rapportés on peut prendre un cas qui illustre très bien un cas très simple imaginons qu'on a trois vecteurs de coordonnées en dimension 3 1 0 0 1 0 0 1 alors l'enveloppe convexe de ces trois points c'est ce qu'on appelle le simplex correspond en gros à l'ensemble des probabilités sur trois éléments donc c'est l'ensemble des tels que la somme des coordonnées est égale à 1 et tel que toutes les coordonnées sont supérieures égales à 0 sauf que bien sûr si on prend la médiane par coordonnée comme sur chaque coordonnée en fait il y a une majorité de points qui sont égaux à zéro la médiane par coordonnée sera le vecteur 00 qui n'est clairement pas dans l'enveloppe convexe des vecteurs rapportés et ça ça fait que c'est une mauvaise idée d'utiliser des idées comme la médiane par coordonnée pour faire des estimations d'objets comme des matrices de covariance qui doivent appartenir à un sous-espace convexe qui va typiquement être un espace qui contient l'ensemble des vecteurs qui lui sont apportés et donc l'idée derrière le vote bayésien sécurisé c'est vraiment d'utiliser des estimateurs de matrice de covariance à base de médias une géométriques et même ce que j'ai en tête c'est d'être un peu plus robuste encore que cela en ajoutant une régularisation puisqu'on sait que notamment depuis notre article sur la les algorithmes de tournesol mais resta et en particulier un objet qui s'appelle la médiane quasiatiquement régularisé on sait que rajouter cette collation permet vraiment de contrôler l'impact maximum d'un individu unique sur l'estimateur et ça c'est très bien parce que ça permet de limiter exactement l'influence maximale d'un individu typiquement sur les scores qui sont calculés et c'est une étape du coup nécessaire par exemple si on fait de la généralisation c'est assez vicieux en fait de contrôler l'effet de chacun puisque chacun peut modifier la matrice de covariance et cette médication de matrice de cohérence peut modifier les scores généralisés de beaucoup d'autres personnes et du coup a priori on risque de perdre beaucoup de robustesse en utilisant ce type de généralisation mais avec ces idées de médiane géométriques régularisées quadratiquement je pense qu'on peut éviter tout cela mais voilà il faut faire l'étude pour être précis et en particulier faire les analyses vraiment de boutons bout pour mesurer à chaque fois l'impact maximal d'un individu et pouvoir le contrôler une autre propriété remarquable de la médiane géométrique c'est sa robustesse ça veut dire quoi ça veut dire que même si on a disons un tiers des contributeurs qui sont en fait extrêmement malveillants et qui sont qui veulent pousser la médiane géométrique aussi loin que possible en fait il y aura un pouvoir limité à ce qui ce qu'ils feront et ça on peut le voir à nouveau avec cette idée de force unitaire essentiellement supposons que la plupart des contributeurs se trouvent par rapporte des vecteurs qui sont dans une région donnée et bien si les attaquants mettent des vecteurs très très loin et bien ils pourront pas déplacer trop loin la médiasiométrique puisque d'un moment lorsqu'on se place très loin et bah on voit que toutes les forces unitaires des contributeurs initiaux vont plus ou moins s'aligner et tirer dans le même sens et comme ils sont plus nombreux ils vont tirer plus fort que la minorité d'utilisateurs malveillants et du coup la médiane géométrique pourra pas aller trop loin en gros savoir les histoires d'angle si vous voyez un peu l'intuition derrière à quel point ça peut aller loin et tout ça est démontré de façon plus formelle dans notre article une dernière chose que j'aimerais signé par pas me dire géométrique c'est qu'on peut démontrer ce qu'elle fait une erreur par rapport à l'estimation de la moyenne mais une erreur qui est forcément borné par quelque chose qui correspond vraiment à cet hétérogénéité parmi les vecteurs bien sûr s'ils sont tous égaux à la même chose la moyenne est égale à médiane géométrique qui est égale à la valeur en commun qu'ils prennent mais s'il y a plus de variances entre les différents vecteurs des électeurs à ce moment-là il y a une erreur mais cette erreur est bornée par mesure de cette variance exactement qui est proportionnelle à racine carrée de la trace de la matrice de covariance entre les différents vecteurs et d'ailleurs cette remarqué et valide exactement telle qu'elle pour la médiane par coordonnées aussi ça permet de faire un lien avec un autre article qu'on a écrit le fameux article que Google a tenté de censurer qui était reporter notamment dans l'université qui lui explique que plus il y a d'hétérogénéité parmi les contributeurs honnêtes plus c'est facile de manipuler en fait dans le cas de la médiane géométrique on voit ça très bien puisque intuitivement si les gens sont éparpillés partout et ben il y a plus de moyens d'action pour les attaquants même s'il représente qu'un tiers des participants ou une fraction plus faible encore des participants c'est pour cela que l'hétérogénéité parmi les contributeurs honnêtes et vraiment une source de vulnérabilité pour la sécurisation d'un algorithme de machine learning typiquement ok c'est prémunère étant terminé maintenant j'aimerais parler un peu plus de la sortie poufs et de l'idée de la preuve et vraiment que ça soit la preuve négative ou positive les deux dans les deux cas en fait on va étudier ce qui se passe de manière à synthétique et ça va vraiment correspondre à étudier ce qui se passe au niveau de la cette loss fonctionne de cette fonction de perte quand il y a un très grand nombre de utilisateurs et pour bien étudier cette façon cet aspect de la stratipowness une première marque que l'on peut faire c'est que on peut isoler le contributeur stratégique donc là je vais lui en donner un indice zéro donc ce Posca V auteur honnête et qui rapporte certains vecteurs voilà qui sont fixés en fait on s'en fout qu'il soit honnête ou pas ce qui compte c'est que leur vecteur se fixer et ce qui va m'intéresser de me poser la question pour le contributeur stratégique du coup avec un indice zéro ou est-ce qu'il peut placer son vecteur pour rapprocher autant que possible la médiane géométrique de son vrai un vrai vecteur qui préfère et donc plus généralement en fait la question qu'on va se poser c'est quels sont les lieux possibles de la médiane géométrique lorsque ce contributeur 0 se déplace et choisit là où enfin le vecteur qu'il rapporte donc ça dans l'article on parle de bows 7 donc c'est à dire l'ensemble des lieux de la médiane géométrique qui sont réalisables par cette individu stratégique et bien l'une des remarques importante pour la preuve qui est assez naturelle qui est assez simple c'est que l'ensemble de ces lieux possibles correspond à l'ensemble des endroits où le gradient de la los fonction par rapport à ce point en question si on regarde uniquement les électeurs qui sont pas le lecteur stratégique l'ensemble des lieux où ce gradient et de Nord inférieur ou égal à 1 bien c'est exactement l'ensemble des points atteignables en effet il suffit à ce moment-là pour l'individu stratégique de rapporter exactement ce point pour garantir que le point en question sur un point d'équilibre puisque d'une certaine manière le gradient qu'il aura à ce moment là contre commencera tous les autres radians de façon plus formelle faudrait parler de sous gradient pour formaliser la preuve et c'est ce qu'on fait dans l'article mais voilà intuitivement si la somme des forces des autres et inférieur à 1 je me plains quelque part et de toute façon je vais tirer avec ma force égale à 1 à ce moment-là je contrôle balance toutes les forces des autres et du coup c'est une position d'équilibre et donc ce qui nous intéresse vraiment c'est d'étudier l'ensemble des points où la somme des forces des autres est inférieure égale à 1 et là l'idée fondamentale c'est quand on se déplace légèrement par rapport à la médiane géométrique des utilisateurs autre que le lecteur 0 à ce moment là le gradient va varier il va prendre une valeur qui va donner par la dérivée seconde donc l'approximation de la dérivée première autour d'un point on obtient comme la dérive seconde fois en gros le déplacement et donc ça reste vrai en dimension supérieure et du coup le gradient prêt du point d'équilibre est donné par H fois la déviation que l'on fait donc si je fais une déviation X par rapport aime bien géométrique alors le gardien que j'obtiens est en première approximation égale à H fois X en particulier la norme de ce gradient et puis je vais même étudier la norme au carré parce que c'est plus facile en terme de calcul l'ensemble des points qui sont atteignables en fait c'est également l'ensemble des points tel que la norme du gradient au carré est un fabricant 1 alors l'ensemble des CP points doivent vérifier que la norme du coup de hache fois X ou H7 dérivée seconde cette matrice sienne donc la norme au carré de HX qui est égal à X transpose hHX ça ça doit être inférieur égal à 1 et donc en premier approximation si vous connaissez un peu ce genre d'équation vous savez que du coup l'ensemble des points atteignables ressemble à une ellipsoïde c'est-à-dire un ensemble de points tels que en gros une forme quadratique et inférieure égal à un nombre et donc cet ensemble de points accessible ça va être du coup une ellipse qui sera très aplatie si intuitivement du coup il y a beaucoup de variations entre les valeurs propres de cette matrice essienne c'est à dire que selon certaines directions la matrice ancienne prend une grande valeur de direction la matrice essienne prend de petites valeurs donc quand je parle de polarisation en fait dans la vidéo principale je parle vraiment de à quel point cette matrice essienne et aplatie sachant que les directions selon lesquelles l'ellipsoïdes et aplaties correspond en fait à des endroits où les gens sont très polarisés puisque ça tire vraiment des deux côtés et du coup c'est difficile de déplacer cette très bien des deux côtés et du coup c'est très difficile de déplacer la médiane géométrique vers le haut vers le bas puisqu'il en gros il y a les forces sont déjà là en présence et sont déjà bien ancrées alors que sur la partie orthogonale lorsque c'est bien aplati correspond plus à des directions où les gens sont un peu éparpillés et du coup il y a moyen d'influencer beaucoup plus en se positionnant à gauche ou à droite ok donc tout ça ça me dit l'ensemble des points Athéniens mais ça ne dit pas vraiment les initiatives de l'utilisateur 0 donc en particulier à quel point il peut gagner en montant sur là où il est on sait qu'il peut réaliser n'importe quel point de l'ensemble dans l'ellipseoïde et a priori il va vouloir prendre le point du coup qui est le plus proche de lui-même et on sait qu'il peut l'atteindre tout simplement en rapportant le point dans cette région de l'ellipsoïde ok mais du coup la question c'est est-ce qu'il y a un point dans cette ellipsoïde qui est beaucoup plus proche de lui que naît le point qu'il obtiendrait s'il était honnête dans sa manière de rapporter sa position donc imaginons que sa position préférée est ici donc j'ai appelé ça téta 0 avant de parler de cette stratégie optimale si on estimait déjà où se trouve la médiane géométrique lorsqu'il le rapporte de manière honnête ça son vrai vecteur à ce moment là on sait que forcément le point qui rapporte devrait être tel que le gradient qu'il rapporte doit annuler le gradient rapporté par les autres vecteurs or le gradient rapporté par les autres vecteurs on sait qu'il est égal à HX et du coup on sait que le gradient qui rapporte à ce moment-là le lecteur 0 sur ce point sera égal à - HX ok maintenant est-ce que c'est sa stratégie optimale bien si la région optimale était cette ellipsoïde qui est un ensemble convexe alors le point le plus proche qui pourra obtenir ça serait nécessairement la projection orthogonale sur cet ensemble convexe en particulier sur ce dessin ça correspondrait à dire que à cet endroit là il doit y avoir un angle droit maintenant supposons que Tata zéro est extrêmement proche de cette ellipsoïde de sorte que cet endroit optimal en fait il est aussi très proche de la médiane géométrique qui sera rapporté lorsqu'il est honnête dans sa révélation des préférences pourquoi pourquoi c'est intéressant de faire ça parce que en fait c'est assez facile de calculer à cet endroit là l'orthogonale la direction normale à l'ellipsoïde puisque l'ellipsoïde étant une ligne de niveau de la fonction qui au vecteur x associe la norme de HX au carré pour connaître la direction du gradient à cet endroit elle suffit de calculer le gradient de la norme de HX au carré et ça il se trouve que c'est le gradient d'une forme quadratique dont on connaît bien la dérivée qui va être égal à deux fois hHX et du coup on se rend compte que la direction entre les médias géométrique et tu es à 0 c'est pas tout à fait la même que la direction entre États zéro et là sa projection orthogonale parce que d'un côté on a HX et de l'autre côté on a hHX et c'est vraiment cette différence de direction qui fait que tetha zéro ici a intérêt à mentir et peut gagner beaucoup en particulier plus HX et différent de HX et même de façon plus précise moins ils sont colinéaires et bien plus il y aura à gagner pour l'utilisateur zéro en montant sur sa préférence et donc dans le PLK on se rend compte que les intérêts à mentir sont particulièrement grands quand la matrice H a tendance à Tordre à tourner comme ça elle est certain vecteurs et en fait à quel point elle tourne ses vecteurs c'est ce qu'on a défini formellement comme étant skinness de cette matrice c'est une terminologie c'est un néologisme c'est un terminologie nouvelle dans l'université à toi en tout cas pourtant qu'on sache donc je sais pas trop comment traduire ce que en français mais voilà à quel point ça tord l'espace tout ça est en fait très haut il y a une histoire d'angle entre les vecteurs en fait c'est un produit scalaire divisé par les normes des différents vecteurs donc c'est vraiment une histoire d'angle et donc c'est vraiment cette screeneuse qui quantifie à quel point il y a un risque qui est beaucoup d'intérêt à mentir pour certains utilisateurs dans article en particulier on relit ça à ratio entre les valeurs absolues extrêmes de la matrice sienne bon malheureusement on n'a pas de formule exact et je suis pas sûr qu'il y a une formule exacte en tout cas à partir des valeurs propres pour obtenir cette mesure de à quel point ça tort l'espace mais nos inégalités montrent en tout cas clairement que plus il y a des différences entre les valeurs propres c'est à dire plus certaines dimensions sont beaucoup plus polarisés que d'autres puis il y a d'intérêt à mentir sur référence et ça ça correspond vraiment aux animations que j'ai fait à la fin de la vidéo précédente les grandes idées de la preuve que nous a guidés ça va marcher mais il faut quand même faire le travail de vérifier que ça va marcher et en fait il y a plusieurs difficultés qui qui viennent et l'une des difficultés par exemple c'est de passer du cas fini à ce cas à sympathique ou les approximations sont vraies en particulier dire que la région de l'espace c'était lipsoïde qui est une approximation et suffisamment bonne approximation du vrai espace atteignable tibles et vraiment l'astuce c'est vraiment d'essayer d'identifier tous les objets vraiment clés à la preuve et de montrer que les valeurs que ces objets prennent quand il y a un très grand nombre de contributeurs vont être extrêmement proches d’œil du cas insectique où on a vraiment une distribution continue des différents contributeurs qui est le cas qui correspond vraiment à l'ellipsoïde exacte donc j'ai parlé précédemment et typiquement pour y arriver on va utiliser beaucoup d'inégalités de holding enfin c'est ce qu'on appelle les inégalités de concentration parfois qui sont un peu des valeurs fortes et vraiment utiles en pratique de du théorème central limite notamment pour des cas d'épication on cherche à prouver que tout se passera bien contrôlez vraiment les garanties donc c'est vraiment des techniques assez classiques pour avoir des résultats avec grande probabilités à partir d'hypothèses probabilités sur un très grand nombre de cas sachant que un certain moment dans la preuve en fait ces inégalités ne suffisait pas parce que il fallait voir des des inégalités uniformes sur un ensemble typiquement de gradients autour du point d'équilibre donc cesignated marche en gros assez bien quand on cherche à contrôler un nombre fini de variables réelles mais quand c'est un nombre continue de c'est plus compliqué et dans ces cas là on a dû faire preuve d'un peu plus d'ingéniosité pour essayer de contrôler le temps que possible toutes les variations par rapport au cas infinies une autre difficulté c'est que dans le cas finit en fait il y a beaucoup de points de critique de points où les dérivés ne sont plus définies puisque le gradient d'un d'une norme EN le point donné ça fait un vecteur enfin ça fait une sous différentielle pour être technique mais du coup aussi les dérives et secondes ne sont plus défin donc il faut essayer d'écarter ces points et du coup en fait l'astuce qu'on a trouvé pour écarter ses points c'est de montrer en fait qui sont assez loin que en fait ce qui se passe surtout en grande dimension en fait nos terrains nous sont valables quand dimension supérieur à 5 en dimension supérieure à 5 en fait les points assez loin les uns des autres généralement et ça ça nous permet vraiment de contrôler tout ce qui se passe et d'ajouter plus de continuité sous nos approximations finies donc en fait le problème des incitatifs asymptotiques de la mania géométrique sont encore ouverts en dimension de 3 et 4 en tout cas le fait de d'avoir une borne supérieure parce que nos exemples montrent déjà qu'en dimension 2 par contre on peut avoir des bornes des stratifs aussi grandes que l'on veut la preuve qui montre l'absence de stratégie pro-nest de Alpha stretchness fonctionne déjà en dimension 2 enfin une troisième difficulté c'était de montrer que la région des points atteignables étaient un ensemble convexe qui est vraiment un argument critique pour pouvoir appliquer l'argument de la projection orthogonale et aussi l'histoire d'angle et donc c'était vraiment critique d'avoir ce résultat et pour l'avoir en fait il fallait vraiment creuser et ce qui est intéressant c'est que ça dépend en fait la dérivée troisième fois que je manipule des dérivés 3e en grande dimension c'était assez perturbant et marrant d'étudier ses objets qui sont du coup des tenseurs qui dépendent de trois variables et en gros en très gros ce qui se passe c'est que cette dérivée troisième en fait elle est de moins en moins gênante plus il y a de contributeurs et dans le moment en fait on peut dire que à partir d'un certain contributeurs voilà ça ça a un effet suffisamment négligeable que on peut conclure que l'ensemble est convexe dernière chose avant de conclure je vais parler du théorème qui généralise un peu nos résultats au cas où les préférences sont non isotropiques et où on peut utiliser des médias géométriques dans ce qu'on appelle déformé Scudo métrique médiane bon pour commencer qu'est-ce que sont des préférences non les autres pics en fait dans toutes nos preuves on suppose que la que les contributeurs ont un point préféré et également ont une préférence entre les positions des médianes géométriques lorsque sont pas leurs lieux préférés en particulier ce qu'on suppose c'est que il préfère que Diane géométrique soit aussi proche que possible de leur points préférés en distance euclidienne et donc ça ça en gros du sens si on considère le problème dans l'espace client physique mais dès qu'on considère que l'espace en fait RD correspond à d'autres choses par exemple ça peut correspondre à répartition des budgets entre différents départements où ça peut correspondre aux paramètres d'un réseau neurones et bien dans ces deux cas il peut avoir certaines direction de l'espace qui sont plus importantes pour utilisateurs que c'est très important pour un électeur que tel entreprise exactement telle budget et puis peut-être que pour tel autre c'est pas grave si ça varie un peu plus de la même façon c'est peut-être très important que l'algorithme recommande vraiment ce genre de contenu et nous recommande pas sueur de contenu et puis pour d'autres contenus et on peut être un peu moins un peu plus lâche et bien ça ça arrive vraiment enfin c'est vraiment des hypothèses extrêmement importantes en pratique très réaliste et bien on peut intégrer sous lors de phénomènes dans notre modèle en disant que ce que les utilisateurs cherchent à minimiser n'est pas la distance entre la médiane géométriques et leurs points préférés mais une autre norme qu'on va définir comme étant la norme de du matrice S qui va donner de plus important à certaines dimensions plutôt qu'à d'autres donc une matrice semi-définie positive avec des valeurs propres qui sont pas forcément toutes égales entre elles donc on suppose que c'était un cherche à minimiser la norme de s fois la médiane géométrique moins leurs points préférés bien dans ce cas nos preuves se généralisent assez naturellement en fait il y a une jolie astuce pour pouvoir les généraliser assez vite c'est ça consiste à se dire que plutôt que d’étudier le problème dans un espace dans l'espace quotidien on va déformer d'abord l'espace de sorte que dans cet espace défaut mais la préférence de l'utilisateur et isotropique et à ce moment-là on va réappliquer les mêmes arguments et en particulier l'avantage de faire ça c'est que la meilleure stratégie pour l'utilisateur stratégique ça reste la projection orthogonale mais cette fois dans l'espace bien sûr déformé pour que ces préférences soient isotropiques enfin une dernière chose qu'on montre c'est que on peut avoir des propriétés similaires si on considère non pas la médiane géométrique mais la médiane géométrique déformée ce que une multiométrique médiane qui consiste simplement à calculer la médiane géométrique mais dans un espace déformé et puis de se revenir dans l'espace normal de le retraduire dans l'espace Norman ça de façon équivalente ça revient à prendre un point qui minimise la Somme des distances mais selon une norme non euclidienne selon une norme que je vais appeler pseudo-éclidienne c'est à dire qui est de la forme norme de une matrice de déformation fois que j'ai appelé ici Sigma fois le vecteur dont on cherche à calculer la norme il a encore en gros des arguments fonctionnant encore en fait il suffit de se rendre compte que on obtiendra l'ensemble des points atteignables sera encore un ellipsoïde mais qui maintenant dépend également de cette matrice déformée petite remarque par rapport à ça c'est qu'en fait le contrôle de la matrice sienne que l'on obtient ainsi lorsqu'on déforme la médiane géométrique ça va pas se calculer facilement en fonction de cette déformation malheureusement notamment la médiane géométrique va potentiellement se déplacer puisque la médiane géométrique n'est pas invariante par ce genre de transformation non euclidienne non métrique de l'espace comme la mutation par une matrice h à la semi-défini positive et du coup en fait on n'arrive pas à avoir un contrôle vraiment comme on aimerait de ce genre de truc et en particulier on n'est pas capable de montrer que pour toute distribution des préférences il existe une matrice de déformation pour laquelle la médiane géométrique avec cette matrice de déformation et à synthétique lit stratégieproof voilà c'est un problème ouvert si cela vous intéresse vous pouvez regarder ce problème je préfère dire que c'est pas facile voilà ça conclut cette vidéo hardcore donc comme vous avez peut-être pu le sentir c'était pas la vidéo la plus préparée comme pas mal de mes vidéos hardcore mais j'espère que ça vous a plu c'était cool de refaire des maths et petit teaser en fait comme en fait on a travaillé sur beaucoup d'articles de recherche motivés par ces idées notamment de sécuriser autant que possible les algorithmes de tournesol on a fait pas mal de maths par rapport à ça et au fur et à mesure que les articles vont être acceptés en espérant qu'il qui le soit assez rapidement dans les venus Academy et bien je serai amené à reparler encore des mathématiques de la sécurisation non seulement des instruments certifiés mais plus généralement des algorithmes qui maîtrisent le flux d'information à travers le monde