les enfants on a parlé de ce qui est souvent considérée comme la forme ultime des sciences à savoir les tests randomisée en double aveugle avec roger d'hypothèses part prévalu ce que je viens de dire est pour vous du charabia je vous invite vivement à aller voir ou revoir les deux vidéos précédentes on a aussi vu en quoi ces approches étaient beaucoup beaucoup beaucoup beaucoup mieux que des approches purement intuitive notamment étant donné les inévitables facteurs de confusion et les omniprésentes fluctuations statistiques si les sciences sont devenus beaucoup plus fiable qu'avant c'est un très très très grande partie grâce aux expériences randomisée et aux statistiques partait value mais le fait que ces méthodes marche mieux que nos cerveaux de primates ne signifie pas qu'elles sont parfaites en fait aujourd'hui on va voir en quoi ces standards ultime de la science d'aujourd'hui sont en fait très loin d'être pleinement satisfaisant et pourquoi il est temps de sérieusement remettre en question ce qui est souvent dit de la méthode scientifique voici cinq arguments contre la science par p vaio travers numéro un toute hypothèse serait sera rejeté une infinité de fois on l'a vu la dernière fois avec un seuil à 1 % une hypothèse vrai à une probabilité de 1% d'être rejeté par la méthode scientifique par p value et à prioris apparaître un taux d'erreur acceptable cependant dit aussi des sciences qu'elles sont censées tester une hypothèse encore et encore et on dit aussi souvent que si une hypothèse n'a pas été rejetée par un test par p value c'est peut-être parce que tu est manquée de ce qu'on appelle la puissance statistique alors je ne veux pas rentrer dans les détails mais il est important de noter que si on teste une hypothèse devrait encore et encore vu qu'à chaque fois elle à 99% de chances de survivre aux tests elle aura une probabilité 99% puissant celle de survivre à un test indépendant or une telle probabilité d croît exponentiellement vite vers zéro après 69 expérience l'hypothèse aura une probabilité de 50% de survivre et après 459 expérience la probabilité de survie sera de seulement 1% et bien sûr à l'infini cette probabilité tend vers zéro alors vous pourriez rétorqué qui semble idiot de répéter encore et encore la même expérience des centaines de fois oui en effet sauf qu'en pratique il ya parfois des centaines de groupes de recherche différents qui bossent sur le même sujet ce qui fait vite des centaines d'expérience mais surtout chaque groupe de recherche pourrait vouloir tester une conséquence différente de la théorie pourvu que quelques centaines de conséquence de la théorie sont testés il faut s'attendre à au moins un rejet voire potentiellement des dizaines de rejet de théories vrai et en particulier à l'infini la méthode scientifique par p va lui garantit que toute hypothèse vrai finira par être rejetée pire encore elle sera rejetée une infinité de fois voilà une propriété épistémologique qui semble pas franchement désirable travers numéro 2 l'invalidité des arrêts prématurés une variante que subtile de ce phénomène et le fait de suivre la valeur de la paix valu au fur et à mesure que les données s'accumulent et de conclure dès que la paix value passe sous le seuil de 1% ça peut paraître innocent mais en choisissant de conclure tech on peut conclure on biaise complètement la validité de la paix value d'une certaine manière on crée un biais de sélection qui augmente fortement la probabilité de rejeter une hypothèse vrai même avec un seuil à 1 % le fait de conclure dès que possible fait passer la probabilité de rejet d'une hypothèse vrai de 1 % à 20 % après quelques milliers de données et bien sûr le phénomène est bien plus catastrophiques avec des seuils à 5 ou 10% et le gros problème c'est que si on publie ensuite un article sans préciser qu'on a choisi le moment d'arrêter la collecte de données parce qu'on avait une paix value publiable alors personne ne pourra se douter de rien les auteurs pourront écrire nous avons appliqué la méthode par p value avec mes seins sans donner sans avoir menti et peut être même sans se rendre compte du billet dans leur analyse l'article semblera alors parfaitement être aux standards de la méthode scientifique par p value pour éviter le biais de sélection du moment d'arrêter l'étude statistique les statisticiens exigé souvent des auteurs des études qu'il fixe a priori la taille de l'échantillon d'études et qu'ils interdisent ensuite tout arrêt prématuré de l'étude cependant on peut alors légitimement se demander si cette décision est éthique par exemple quand j'ai eu la shoah tester sa capacité à implanter des faux souvenirs chez ces sujets les résultats préalable était si impressionnant que pour protéger les sujets l'étude a dû être arrêtée prématurément techniquement donc l'étude du jus à chaud ne réponde a du coup plus hauts standards des statistiques fréquentes east et pourtant le cas du jus la chaux est encore relativement éthiquement acceptable le cas des groupes de contrôle de maladies graves semble par exemple nettement plus problématique oui oui ça va vous savez la wii qui caractérise pour mieux répondre aux considérations éthiques sur les torts potentiellement causer aux patients que ce soit par le choix de leur administrer un traitement potentiellement nuisibles ou par celui de ne pas leur administrer un traitement potentiellement salvateur d'autres statisticiens se sont mis à considérer des cadres différents pour mesurer les effets des traitements et surtout pour décider si un traitement devrait être administré ou non par exemple il ya le cadre du multi armes de ben 10 ce cadre invite à ignorer la question de l'existence d'un effet statistiquement significatifs et de la remplacer par la question de la prise de décisions rapidement quasi optimales de traitement ou non et ce n'est sans doute pas plus mal car au final l'objectif est bien souvent le bien des patients pas de déterminer si le traitement à un effet statistiquement significatifs travers numéro 3 bien des publications on a déjà un peu parlé et on en reparlera plus longuement une prochaine fois mais l'une des raisons importantes pour lesquelles la paix value semble problématique dans le contexte actuel de la recherche c'est le fait que comme nous sommes constamment inondés d'informations il nous est impossible de tout lire pour aider tout le monde à mieux parcourir l'ensemble des résultats des sciences les scientifiques ou donc mise en place des journaux de publication des résultats scientifiques ces journaux publient des articles qui communique les résultats importants des études scientifiques et pour faire le tri ces journaux sont cotées selon leur impact factor chaque article soumis à ces journaux est relu par des pairs qui valide ou non la qualité informationnel de l'article avec une intransigeance d'autant plus grande que le journal a un grand impact factor voilà qui du coup cause inévitablement un biais de publications en effet les résultats les plus relayer et les plus lus par les scientifiques seront alors nécessairement des résultats qui ont été validées par les journaux scientifiques et est important de noter que ce bien est globalement désirable c'est a priori un biais en faveur des informations de qualité cependant malheureusement ce biais est aussi très imparfait il favorise certains résultats plutôt que d'autres et est donc une représentation biaisée de l'ensemble des études scientifiques typiquement ce biais va fortement favorisé les résultats dit statistiquement significatif c'est à dire les rougets d'hypothèses par la méthode scientifique par p valu aux dépens des résultats non statistiquement significatif mais potentiellement aux aussi utile typiquement les résultats statistiquement significatifs vont indiquer l'existence d'un effet un traitement mais il peut être aussi utile de signaler l'absence d'effet un traitement mais ce n'est pas tout parce que les journaux scientifiques vont vouloir publier des articles qui seront cités par la suite et parce que les résultats spectaculaires ou plus de chances d'être citée par la suite ils vont privilégier la publication de tels résultats or ces résultats ont aussi une plus grande probabilité d'être de faux positifs mais ça on en parlera bien plus longuement une prochaine fois travers numéro 4 le p hacking alors c'est tout les scientifiques étaient des bisounours qui appliquaient méticuleusement la méthode scientifique comme on l'a vu il y aurait déjà pas mal de problèmes sauf que en pratique les scientifiques ne sont pas entièrement des bisounours ou du moins à cause de l'explosion du nombre de doctorants et de la diminution des budgets de la recherche les scientifiques sont dans une compétition telle qu'un chercheur bisounours aura bien du mal à survivre à hisser le jeu pas les joueurs tout cela est mise en exergue par la formule publish or perish et malheureusement pour la plupart des doctorants ce sera parish ses doctorants ont beau être la crème de la crème ils sont en compétition avec d'autres doctorants qui eux aussi sont la crème de la crème et dans ce contexte les incentives a publié son énorme or pour publier surtout dans le cadre de la méthode scientifique par p value il faut des résultats spectaculaires qui rejette une hypothèse qui paraissait pourtant vrai voilà qui a conduit certains à employer consciemment ou non des stratégies dites de paix hacking l'idée de ce pea king est incroyablement simpliste effectué un très grand nombre d'expériences et oui si on suppose un seuil à 1 % on sait que les hypothèses vrai ont une probabilité de 1% d'être rejeté par la méthode scientifique part prévalu du coup il suffit d'effectuer environ 100 tests d'hypothèses très crédible pour en avoir une qui sera un rejet spectaculaire d'une hypothèse très crédible le problème bien sûr c'est qu'en ne publiant que ce rejet spectaculaire la publication aura l'air d'être parfaitement aux standards de la paix value elle semblera parfaitement scientifiquement valide elles se sont toutes pour les auteurs même de publications qui ont très bien pu ne pas s'être rendu compte qu'ils avaient déployé là une stratégie de paix hacking oui parce que là j'ai parlé d'un seuil à 1 % mais en pratique c'est souvent davantage un seuil à 5% qui est utilisé auquel cas il suffit d'avoir tenté 20 expérience seulement orvin petite expérience s'est pas beaucoup on peut noter que les initiatives de paix hacking sont toutefois pas spécifique à la paix value il s'agit d'un cas particulier d'un phénomène plus général appelait la loi de good rares dont on a déjà parlé dans l'épisode 37 de la série sur intelligence artificielle cette loi dit qu'un manque une mesure correspondent exactement à ce que l'on cherche à maximiser dès qu'une mesure devient un objectif elle cesse d'être une bonne mesure or dans un climat publish or perish tous critères de publication un parfait de viendra inéluctablement 1 objectif retrouve ainsi le même problème pour d'autres métriques utilisé dans d'autres domaines pour être publiés par exemple en machine learning on a souvent des problèmes bien définis avec un score de performance des algorithmes pour être publié c'est souvent très utile de battre le meilleur score jusque là ce qu'on appelle parfois devenir l'état de l'art sauf que la reproductibilité de ces expériences est en fait très questionnable déjà parce qu effectué l'expérience nécessite parfois des puissances de calcul et donc des dépenses énergétiques faramineuse mais aussi parce que les algorithmes sont souvent randomisée et ne donne donc pas le même résultat d'une itération à l'autre en fait à bien y réfléchir cette rando mise à sion et même utile pour espérer battre le meilleur score exactement comme elle l'est pour avoir parfois une plus-value publiables pour des hypothèses vrai travers numéro 5 malléabilité enfin le cinquième et dernier travers que je vais mentionné aujourd'hui et la malléabilité de la méthode scientifique parp évalue alors qu'est ce que j'entends par malléabilité et bien souvenez vous que j'ai décrit les statistiques comme une boîte à outils pour chaque nouveau problème auquel il est confronté le statisticien va alors regarder le problème et choisir un outil à utiliser pour faire parler les données le truc c'est que si ça ne marche pas par exemple s'il n'obtient pas une paix value publiable alors il peut piocher un autre outil de sa boîte à outils comme par exemple rajouter un hypothétique facteurs de confusion et voir s'il obtient alors une période où publiable et puis il pourra ensuite piocher un autre outil encore et ainsi de suite et ce faisant il multiplie ainsi le nombre de tests qui va effectuer et donc la probabilité d'obtenir une paix value publiables par exemple imaginons que l'on soit une entreprise pharmaceutique et qu'on cherche a validé la vente d'un médicament pour cela il nous faut montrer que ce médicament a un effet on effectue alors des tests cliniques randomisées en double aveugle et là pas de bol notre médicament ne semble pas faire mieux qu'un placebo ou du moins la paix value nette alors pas publiable le truc c'est que vous pouvez maintenant poser d'autres questions avec le même jeu de données peut être que le médicament a un effet pour les plus de 40 ans par exemple ou peut-être juste sur les femmes ou peut-être juste sur une personne en surpoids et petit à petit à force de répéter les questions comme la paix value n'est pas parfaite vous finirez bien par tomber sur une question dont la paix value est publiable en pratique selon le philosophe jacob staking à ce genre de pratique combiné aux très nombreux autres travers de paix value dans les tests cliniques a conduit à la mise en circulation d'un très grand nombre de médicaments qui n'ont fait aucun effet alors là j'ai pris un exemple où la malléabilité est quand même assez évidente cependant en pratique quand on considère des données plus sophistiqué qui ne sont pas issus de tests randomisée en double aveugle la boîte à outils statistiques est tellement énorme que le statisticien lui-même ne seront peut-être pas compte de la liberté dont ils disposent et du bien est inconsciente de raisonnement motivé que cela lui permet par exemple en 2017 mêmes données de football ont été fournies à 29 équipes de recherche différentes on leur a demandé d'effectuer un test statistique pour savoir si les arbitres étaient racistes et en particulier ne donnaient pas plus facilement des cartons rouges un des joueurs de couleur de peau noire voici les conclusions des 29 équipes de recherche de façon stupéfiante les résultats a l'air de aucun effet statistiquement significatifs à trois fois plus probable de données thon rouge est un joueur noir cas un blanc imaginez maintenant que les journaux ne public que les résultats spectaculaires on obtiendrait alors uniquement de résultats publiés concordants sur l'existence d'un racisme très prononcé des arbitres de football il ne serait pas faute de publier en gros titre de tf1 que deux études indépendantes montrent que les arbitres sont trois fois plus sévère avec les noirs qu'avec les blancs il insiste en particulier sur le fait que le 29 équipes de recherche ici n'était ni frauduleuse ni incompétente il s'agissait de statisticiens très compétent et très motivé a vraiment répondre à la question qu'il aurait été posée le truc c'est que la méthode scientifique qu'ils utilisaient tout simplement pas objectives notamment parce qu'elle part entièrement défini elle permet à quiconque les de mettre sa petite touche personnelle entend ainsi subjective toute analyse des données elle est malléable des leurs à cause du biais de publications il faut s'attendre à la publication de résultats très divergents de l'analyse d'un statisticien médian bref c'est donc j'espère vous avoir con todd scientifique par p value ce standard ultime le plus répandu des sciences n'est absolument pas parfait ce standard est même extrêmement problématique et conduit à des publications de résultats très biaisée par rapport à l'ensemble des observations scientifiques la méthode scientifique par p value conduit à de sacrés travers ce qui explique les très nombreux articles de statisticiens qui la dénonce alors bien sûr ça ne veut pas dire qu'il faut enlever les statistiques de la méthode scientifique au contraire tout ceci montre que même avec des statistiques établies par des grands mathématiciens il persiste des billets majeur dans l'analyse des données scientifiques laissant ses statistiques c'est via serait sans doute bien pire encore en fait sans statistiques il n'ya tout simplement pas de méthode scientifique le truc c'est que bien analyser des données statistiques c'est avant tout extrêmement difficile si difficile que même les mathématiciens s'engueule parfois avec virulence sur ce sujet et spoiler alert il est extrêmement difficile d'avoir des raisonnements purement bayésiens en pratique notamment dès lors que les données et les théories sont ultra complexes à décrire et à confronter et surtout lorsqu'on prend également en compte le fait que les puissances de calcul de nos machines et les facultés cognitives de nous autres humains sont très limités faire de la bonne science c'est compliqué néanmoins il me semblerait extrêmement problématique de ne pas au moins sérieusement cherché à faire mieux que ce qui est fait aujourd'hui notamment d'un point de vue méthodologique en fait ça m'exaspère même au plus haut point d'entendre parfois certains dire que la méthode scientifique d'aujourd'hui est la moins pire des méthodes ça me semble être une absence d'autocritique un excès de confiance et un raisonnement motivé indigne d'intellectuels qui prétendent vouloir connaître au mieux du monde qui les entoure d'autant qu'aujourd'hui je n'ai en fait mentionner qu'une partie des travers de la méthode scientifique en fait je n'ai même pas mentionné les travers que je trouve les plus graves oui car pour tout vous dire à la base je comptais faire un top 10 des travers de la méthode scientifique par p value mais comme il ya juste trop de choses à dire je vais laisser cinq autres énormes travers de la méthode scientifique par p value pour la prochaine fois dernière fois j'avais parlé de l'ap évaluer notamment je l'avais introduit dans le cadre d'une distribution gaussienne plus ou moins gaussienne j'avais un petit peu insisté sur le fait que certains des raisonnements que j'avais fait était spécifique à une distribution gaussienne qu'on a cherché à tester et or l hérault a du coup de monde et à juste titre de ce qu'on pouvait faire lorsque la distribution n'était pas à gaussienne mais en fait la notion de paix value ne dépend pas de la gaussienne c'est juste certains aspects que j'ai printanière faut notamment les histoires de 5,6 demain qui correspondent vraiment en tout cas à la base à la notion de social mais la notion de paix valent ou plus rarement s'applique à toutes sortes de distribution qui concerne nous données numériques observé encore une fois la paix value c'est la probabilité des données pire que la donne et qui a été observé et ça on peut la définir pour toutes sortes de distribution et en pratique typiquement celle utilisée pour différentes distributions pour différents tests statistiques utilisées en pratique cependant il est intéressant de noter que pour que ça soit relativement bien défini on a tendance quand même à ceux ramenés à la distribution une loi de distribution concernant une donnée numérique de dimensions 1 or bien souvent en pratiquant et commence à faire beaucoup plus de mesure et du coup avoir des espaces de plus grande dimension et du coup il est intéressant de se poser des questions sur des tests statistiques de plus grande dimension auquel cas la paix value ne s'applique pas toujours très bien en tout cas la paix value de fischer parce qu'après pour des zones est plus général il reste possible de définir des tests sismiques notamment ceux de neyman et personnes dont on reparlera sans doute une prochaine fois mais en gros ça a à voir avec ce qu'on appelle le rapport de vraisemblance où le facteur de bellissen cdc m'anime et tout ça on en parle à une prochaine fois j'espère que vous avez aimé cet épisode et que vous resterez là pour le prochain nous donnerait vraiment les cinq arguments qui me semblent les plus importants contre la méthode scientifique parts évaluer si vous avez aimé cet épisode conseil d'ajka le commentaire de partager pour services de données pour que les futurs épisodes merci un petit peur pour leurs dons et j'espère que vous serez là la prochaine fois la classe