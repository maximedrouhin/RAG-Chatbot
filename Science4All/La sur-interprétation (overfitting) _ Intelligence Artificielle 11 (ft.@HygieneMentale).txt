bonjour les jeux profitent de ta série de vidéos sur l'intelligence artificielle pour te poser une question tu le sais je m'intéresse beaucoup aux biais cognitifs et aux défauts de fonctionnement du cerveau humain qui nous empêche de penser correctement par exemple quand on obtient des données brutes issues d'une étude scientifique par exemple on les interprète souvent de travers les statistiques on peut leur faire dire ce qui nous arrange le plus selon ce qu'on a envie d'entendre pour éviter ces biais certains pensent qu'une solution serait d'utiliser des algorithmes c'est fiable c'est neutre qu'en penses tu à ton avis est ce que un algorithme peut avoir des billets tu peux donner un exemple voici un exemple issu du paranormal parce que c'est ce que je connais bien dans les années 50 il y avait une étude qui montrait un lien entre les performances sportives et la position en quarts et de la planète mars dans le thème astrologique de certains sportifs on appelait ça l'effet mars et sans parler du fait que il choisissait les critères qu'il utilisait pour sélectionner les sportifs qui allait participer à son étude pour maximiser ses résultats il y avait aussi un billet d'interprétation a posteriori des statistiques il y avait effectivement moins de 5% une chance qu'il obtienne ses résultats par hasard avec mars en quart et avec des résultats sportifs mais il avait aussi essayé avec toutes les autres planètes toutes les autres conjonction et avec plein d'autres critères le score handicapées en mathématiques en histoire c'est là un bel exemple de pi hacking à ton avis or il suffit de automatiser les études statistiques avec des algorithmes pour éviter de tels billets alors là clairement non en fait le fait d'utiliser des algorithmes est-ce que forte aggraver les biens dans l'analyse de données et ça c'est parce qu'il ya un biais fondamental dans toute analyse de données qui n'est absolument pas spécifique à l'humain ce biais c'est le biais de la surinterprétation que l'on appelle aussi over fitting dans le langage du machine learning en gros la surinterprétation c'est lorsque l'on cherche trop à expliquer les données et du coup ce faisant on risque de mettre le contexte autour de la collecte de données ainsi que les fluctuations statistiques qui sont présentes dans tout jeu de données or il est très facile de concevoir des algorithmes qui vont automatiquement détecté des irrégularités dans des jeux de données sans tenir compte ni du contexte ni des fluctuations statistiques dans les données utilisées étaient algorithmes c'est aussi et surtout facilité la découverte de corrélation fallacieuses ah oui il y à même ce fameux site qui s'appelle spurs corrélation qui propose de fouiller dans une immense base de données pour y dénicher toutes sortes de corrélation entre des variables qui n'ont aucune raison d'être corrélés on y découvre par exemple que le nombre de films avec nicolas cage est corrélée avec le nombre de personnes noyées en tombant dans une piscine l'importation de pétrole brut aux états unis venant de norvège est corrélée avec le nombre de conducteurs morts par collisions avec des trains ou encore que l'âge de miss américain est corrélée avec le nombre de meurtres par vapeur chaude même corrélation n'est pas causalité et oui surtout dans ce cas parce que là on est typiquement dans un cas de sur interprétations quand on regarde ces graves de corrélation il faut absolument se dire qu'il s'agit d'une poignée de graff intrigant parmi un énorme ensemble de graff étudié par l'algorithme en fait spurs collation à étudier des corrélations entre des milliers de jeux de données ce qui lui a fait des millions d'études de corrélation chaque corrélation est peu probable mais même si les jeux de données était complètement aléatoire la probabilité d'une corrélation significative entre deux jeux de données restent non nul or si cette probabilité elle ne serait ce que de l'ordre de 1% ce qui n'est vraiment pas beaucoup alors une corrélation sur 100 sera significative sur les millions de corrélation étudiée il resterait des dizaines de milliers de corrélation significative et spears corrélation a justement publié 30000 corrélation significative j'ai l'impression que votre cerveau a tendance à imaginer que si un phénomène a très peu de chances de se produire alors ce genre de phénomène devrait se produire très rarement ce qui est une erreur un individu spécifique a très peu de chances de gagner au loto si je gagne au loto cette semaine c'est extraordinaire mais vu qu'il ya énormément de joueurs le fait que l'un d'entre eux gagne au loto ça c'est ordinaire il ya des gagnants toutes les semaines de la même façon on surinterprète ce genre de corrélation on y voit un lien de cause à effet alors que c'est juste du à la taille gigantesque de la base de données le biais de surinterprétation c'est omettre la probabilité que le hasard puisse générer des régularités ou des patterns sauf qu'en fait bien souvent il est très improbable que le hasard ne produisent pas au moins une régularité si vous regardez le hasard avec soin vous finirez pas retrouvé de telle régularité et comme les algorithmes sont capables de regarder les données avec bien plus de soins que nous ils seront capables de trouver bien plus de régularité créneau mais en fait l'erreur n'est pas temps d'observer ces régularités l'erreur du biais de sur interprétations c'est surtout de penser que ces régularités doivent s'expliquer autrement que par le hasard ok même il ya un autre problème avec les études sur le paranormal c'est le biais de confirmation non seulement on cherche des phénomènes surprenants de façon générale mais surtout on cherche on particulier mais phénomène sur lesquels on a envie de croire est-ce que les algorithmes seraient exempts du biais de confirmation l'encore j'ai envie de dire non si on utilise des algorithmes et notamment si on utilise de mauvaises algorithmes alors on risque au contraire d'amplifier le risque de biais de confirmation et il ya un excellent exemple de cela sur le site people y ait de night fever et ses collaborateurs ce site vous demande d'imaginer que vous êtes un terme au crac hooligans vous voulez montrer à tout prix que si les démocrates sont au pouvoir alors l'économie va mieux manque de bol le pib ne semble pas corrélée avec le fait que le président au pouvoir soit démocrate c'est embêtant mais armé de votre puissant biais de confirmation vous vous dites que ce qui compte ce n'est pas tant le pib et oui le chômage c'est important aussi hélas la corrélation augmente yes mais elle n'est pas encore suffisamment grande pour être publiables et convaincre ces idiots du camp opposé qui croient encore qu'on peut sauver l'économie en étant républicain et c'est là que vous vous dites que le président peut avoir les mains liées a minima il faudrait aussi considérer le cas où les gouverneurs sont majoritairement démocrate du coup pour fait l'analyse de données et là bingo cette fois votre coloration est clair net et scientifiquement publiable elle a une paix va lieu inférieure à 1% ce qui est mieux que le standard usuelle des sciences vous venez de démontrer que les démocrates ont un effet bénéfique sur l'économie d'ailleurs pour plus de détails sur la paix value je vous recommande cet excellent épisode de la statistique expliqué à mon chat alors bien sûr démontré dans ce cas c'est un bien grand mot mais si vous écrivez un article qui omet la démarche intellectuelle que vous a conduit à votre corrélation et qui se contentent uniquement de publier le résultat significatif ce qui on va pas se le cacher et souvent le cas des publications scientifiques alors votre article sera parfaitement aux standards de la méthode scientifique - f mais on sent bien qu'il ya quelque chose qui cloche dans ce résultat significatif est en effet imaginons maintenant que je sois al'inverse un républicain hooligans alors je pourra rétorquer qu'en fait le chômage est la vraie plaie de nos sociétés et que c'est ça qu'il faudrait supprimer pour améliorer l'économie du coup je refais l'analyse de données sans prendre en compte le pib est là de façon étonnante j'obtiens un résultat tout aussi significatif qui dit exactement l'opposé de la corrélation précédente avec une paie value inférieure à 1% je conclus que les démocrates sont néfastes à l'économie n'est exactement là dans une situation de sur interprétations quelle que soit la fluence réel des politiques sur l'économie on peut bidouiller l'analyse de données pour conclure une chose et son contraire pire encore on y est arrivé à la main imaginez maintenant que des armes et de militants hooligans lancent chacun de son côté des algorithmes pour collecter et étudier des corrélations significatives qui supportent leur camp alors chaque camp pourra facilement publié des milliers de corrélation significative qui semble prouver que leur camp elle le bon camp en fait le problème dans ce cas c'est qu'une phrase comme les démocrates ont un effet bénéfique sur l'économie est en fait très ambigu on peut l'interpréter de plein de manières différentes est ce qu'on parle d'un président démocrate de gouverneur démocrate d'un sénat démocrate ou d'une combinaison de président et de gouverneurs et comment mesurer l'économie parce que le pays des contes cruels chômage ou l'inflation ou la bourse ou une combinaison de tout ça et quelle combinaison vous voyez que ça fait plein de questions qui sont en fait différentes les unes des autres sauf que n'importe laquelle des très nombreuses reformulation de cette question nous semblera a posteriori conforme avec la phrase les démocrates ont en effet bénéfique sur l'économie est typiquement si on collecte 3 corrélations significatives obtenues via ce genre de questions ça semblera justifier un titre put à cliquer de ce genre dans votre journal votre émission de télé préférées le noeud du problème c'est que le nombre de reformulation compatible avec une phrase de ce genre est énorme du coup même s'il est improbable pour chaque reformulation d'être une corrélation significative il est alors bien plus improbable qu qu'une reformulation n'y parvienne pire encore on peut juste complexifier les reformulations à l'infini jusqu'à aboutir à une conclusion qui va dans notre sens or ça ça ce code très très facilement avec des algorithmes ses algorithmes seront alors bien plus performant que nous pour rationaliser nos intuitions ils seront donc bien plus victimes du biais de confirmation et bien sûr tout ce que je dis là n'est pas du tout spécifique à la politique on retrouve exactement le même problème dans plein de sujets de société par exemple quand on dit que le café est bon pour la santé que le paris saint germain a mérité de gagner ou encore que les ja sont dangereuses pour nos sociétés je ne dis pas que ces princes sont vraies ou fausses ce que je dis c'est qu'il sera très facile pour un algorithme de bidouiller toutes sortes de données pour conclure exactement cela ou son contraire tout ça parce qu'il existe un énorme nombre de reformulation rigoureuse qui a posteriori sonneront parfaitement conforme avec ses phrases ok je comprends mais là tu parles d'algorithmes militants est-ce qu'on aurait encore ce genre de problème de biais de confirmation avec des algorithmes nos militants tout dépend de l'algorithme et en particulier de ceux que le concepteur de l'algorithme veut que l'algorithme face aujourd'hui dans le monde académique comme dans la presse il faut publier des résultats étonnants et intrigant pour survivre publish or perish comme disent certains du coup jean sent-il des chercheurs et des médias c'est de concevoir des algorithmes qui iront pouilles et des jeux de données pour y trouver des corrélations étonnante sur des sujets polarisant donc civiquement si je devais publier un truc qui fasse le buzz je ne cherchera pas nécessairement une corrélation significative qui montre que les démocrates ont un effet bénéfique sur société mais je chercherai une corrélation significative qui dit quelque chose sur l'impact d'un parti politique sur l'économie et dès que j'aurai trouvé une telle corrélation je les publierai et les militants du parti que ça arrange pour ont massivement la partager ainsi même sans un algorithme partisan je favoriserai le hooliganisme politique ben merci les c'est fascinant et puis ça regonfle bien sûr les études sur l'astrologie et l'effet mars il suffit qu'il y ait une étude qui aille dans ce sens et qui soit significative pour qu'elles soient facilement aux publié est largement partagée à travers les médias du coup même si les astres n'avait aucun effet sur nos destinées les lois du hasard font qu'il serait très improbable qu'il n'y ait aucun résultat scientifique qui aille dans ce sens et qu'ils soient publiés de façon plus générale il est indispensable de se demander comment les données ont été collectées pour pouvoir payer les analyser ces données sont plaints d'imprécisions dans leurs mesures pire encore elles ont souvent été sélectionnées parmi un ensemble bien plus grand de données surtout quand il s'agit de données publiée dans une revue scientifique ou dans un article de presse tout humain ou algorithmique qui analysent ces données en supposant qu'il s'agit de données brutes sans fluctuations statistiques ni biais de sélection sera alors en grave danger de sur interprétations j'espère que vous avez aimé cette vidéo un énorme merci à christophe michel de la chaîne hygiène mentale aller voir sa chaîne c'est absolument génial ce qui fait c'est un petit peu le maître à penser de la zététique française et ses vidéos sont vraiment d'une qualité absolument génial se fait vraiment partie de ce qu'il ya de mieux sur youtube pour le coup ce sont vraiment des vidéos d'intérêt public absolument énorme je recommande notamment vivement ces vidéos sur les arguments fallacieux qui est mort un excellent depuis la série de vidéos qu'il a fait en filmant ce qui se passe dans une école où ils apprennent l'esprit critique ce je pense que ce genre de séance est absolument génial et faut vraiment que ça se développe en plus si dernière fois on a vu comment on pouvait toujours bidouiller un enjeu de données pour pouvoir finalement appliqué des méthodes de régression ou de classification linéaire la bidouille non linéaire c'est typiquement un exemple de cas on risque fort le biais de la surinterprétation et hervé le borgne fait leur marque qu on dit parfois plutôt sur un apprentissage que sur interprétation par exemple la page wikipedia s'appelle sur apprentissage et pas sur interprétations je trouve que cette terminologie est horriblement mal choisi pour le coup je déteste cette terminologie est hors de question qu'elle utilise pas ce que sur l'apprentissage conduit facilement un contresens dans l'impression que le sur apprentissage c'est le fait d'avoir trop appris et du coup quand on apprend entre hauts et bas ont fini par comprendre le monde du coup d'aller à l'école alors que la surinterprétation ça correspond avant tout un mauvais apprentissage qui est dû au fait que on a donné trop d'importance aux données est d'ailleurs un des outils indispensables pour éviter ce problème de la surinterprétation consiste justement à apprendre plus de théorie et à s'enfermer un petit peu plus dans la théorie et a accepté en particulier les erreurs que la théorie pourrait faire sur certains jeux de données c'est typiquement la proche qui avait suivi galilée au xviie siècle quand il a découvert notamment la loi de la chute des corps ou le principe de relativité comme on en avait parlé dans les épisodes 200 vols de la série sur la relativité j'insiste encore un peu sur ça parce que j'ai besoin souvent dans la vulgarisation scientifique on va dire que l'empirisme c'est super important il faut absolument coller aux données alors que il ya quand même tout un aspect ultra important dans l'apprentissage qui est l'apprentissage des théories quitte à ce que ces théories ne colle pas parfaitement aux données et d'ailleurs cette tension entre la théorie et l'empirisme c'est quelque chose dont on reparlera dans la prochaine vidéo mathieu aurousseau demande si le nom de loi gaussienne vient pas du fait que cos a calculé le à de l'expression a foi en puissance - bx carrés où il faut choisir le raté que ce fut une intégrale c'est à dire si je calcule la probabilité total d'une valeur de x dont m il faut que ce soit une probabilité de tout l'espace du groupe dassault égal à 1 du coup faut ajuster leur art en fonction du coût calcul ra revient à essayer de déterminer la valeur de l'intégrale de puissance 3 x car et je sais pas si martin on reçoit fait exprès de poser cette question des russes poirier l'organisme l'a placée en moi mais nous aux c'est la place qui a trouvé cette valeur de excusez-moi 16 120 ne fait remarquer que même en maths en fait il ya pas mal de bidouiller des trucs pas beau et alors ces gosses qui disait que ben une fois qu'on a prouvé un théorème on va mettre l'épreuve un petit peu de côté et on voit pas forcément les montrer parce que c'est un petit peu moche on va juste montrer l'élégance du théorème faisait une par une comparaison avec les visent en disant que les échafauds de l'église à la fin ils sont enlevés pour qui juste l'église notamment sur edit il ya eu un commentaire que je trouve assez amusant de phoques terre seven qui part d'un professeur en théorie des nombres analytique qui au moment de commencer des preuves assez dégueu disait alors la preuve que l'on va faire et si on classe et est une c'est un truc qui l'ont fait dans la sphère privée de vos propres chambres bref il ya des trucs absolument élégant merveilleux en mathématiques via aussi il faut le reconnaître des trucs assez dégueu silva refusé à adrien bruno me pose des questions sur la vidéo est utilisée par alpha 0 et alpha 0 c'est un exemple que je trouve fascinant parce que c'est un problème en fait résoudre le jeu d'échecs le jeu de go tous ces jeux de société de façon générale c'est des jeux informations complètes dont on est fascinant capable d'écrire des algorithmes et des algorithmes même très courts qui sont capables de résoudre c'est je le prenne de ces accords et emma c'est uniquement une question de temps de calcul qui ça fait vraiment référence à l'épisode 6 qu'on a bu ou david celli a parlé de structures pour le jeu de la vie qui est pourtant un truc totalement déterministe dont on connaît les règles et les conditions ont finalement c'est qu'à ce que l'on cherche à faire c'est d'approcher un algorithme conseillers déjà optimale mais dont le temps de gars que ya absolument énorme et du coup on cherche à approcher les calculs de cet algorithme optimale avec un algorithme qui est rapide en temps de calcul mais du coup qui va sacrifier un peu on aura qualité de l'approximation et du couffo ajusté pour que c'est la vaccination soit suffisamment bonne tout en ayant tu vois une approximation qui soit facile à calculer en temps réel via ce moment est ce que fait alpha 0 c'est absolument génial ça correspond vraiment à l'intuition concours espèrent quand on observe le jeu de la vie c'est de se dire bon bah au lieu de regarder tous les détails des calculs qu on doit faire on va essayer d'avoir une vision intuitive approximative une fonction approximative qui essaie de dire qu'est ce qui se passe notamment cette fonctionnel dans le cas de alpha 0 ou d'alpha go c'est une fonction en fait qui est un réseau de neurones qui apprend de données qu'on lui donne un peu comme dans le jeu la vie on voit des données mais c'est d'inférer des règles approximative du à partir des données exactes qui ont été calculés on cherche des règles approximative et rien que ça c'est un problème c'est pas résoudre autrement que via diverses artificielle et le machine learning aujourd'hui un autre truc que je tiens à dire sur alpha 0 qui a un truc assez ahurissant quand vous y réfléchissez c'est que alpha 0 c'est un truc qui est techniquement voilà c'est un algorithme qu'on aura peut-être pu avoir conçu il ya dix vingt ans parce qu'au final pour sa puissance de calcul et quand même est assez énorme peut-être pas 20 ans mais finalement elle a réussi à faire tous ces calculs en 24 heures il a réussi à apprendre à jouer aux échecs mieux que n'importe quel autre cargo étaient des échecs en seulement quatre heures donc ça laisse penser que termes d'apprentissage algorithmique interne d'algorithmes d'apprentissage en terme de leurs dix machines zurich mais on est encore très très mauvais on est très très loin des algorithmes d'apprentissage aussi bon que le cerveau des vivants ou loin de trucs optimaux en un certain sens et parfois j'entends dire que ça ça montre que l'intelligence artificielle on en est très très loin en effet ça veut dire n'est pas du tout mais ça veut aussi et surtout dire qu'il ya énormément de progrès qui sont pas forcément si difficile à faire dans la conception d'intelligence artificielle ans directeur de tasiast mets typiquement raconté que quand un industriel venait le voir lui disais voilà qu'est ce que vous êtes capable de faire en optimisation par rapport à notre système est aujourd'hui mon directeur de thèse répondait bas ça dépend à quel point vous êtes mauvais je suis pas sûr que le disait exactement comme ça mais c'était un peu ça l'idée si on est mauvais en quelque chose qu'on peut beaucoup progresser alors que si on est déjà très très très bon proche des limites de la physique de ce qui peut se faire là et progrès sont beaucoup plus difficiles et en termes d'intelligence artificielle notamment d'algorithmes d'apprentissage exemple d'alpha 0 montre justement à quel point on est encore mauvais on tu en es tu es mauvais avant alpha 0 et je pense qu'il ya énormément de progrès à faire en intelligence artificielle en machine learning dans le développement de ces notamment aux algorithmes d'apprentissage et ça ça laisse vraiment à penser qu'il y aura encore énormément de progrès dans les années à venir une intelligence artificielle et sans doute que le progrès va être encore assez spectaculaire enfin je vais finir avec sébastien pas le coup qui recommande une vidéo notamment de à l'inconnu ou qui donnent un séminaire et à la fin de son séminaire haricots ne tape un petit peu sur la machine learning et l'intelligence artificielle en disant notamment que ces machine learning n'arrive pas à porter le même niveau de compréhension des choses que ceux dont les humains sont capables je pense qu'aujourd'hui c'est assez vrai pas toutes en grève mais c'est à ses bras souvent les algorithmes apprentissage qui utilisés notamment pour résoudre des problèmes en mathématiques c'est des trucs qui vont faire des grosses exploration cette idée des grosses bidouille et l'épreuve qui en ressortent damman pas dans le cas du théorème du carreleur que j'avais présenté sur science au final ce sont pas forcément des preuves qui sont aussi intéressantes pour des mathématiciens ceci étant dit c'est aussi parce que les algorithmes d'aujourd'hui l'intérieur sera signé aujourd'hui est très loin du niveau humain et surtout il 13 incapable se mettre à un autre niveau des nous expliquer la manière dont il faut penser à différents problèmes gros les intelligences artificielles aujourd'hui donc aucune compréhension de la pédagogique est nécessaire pour comprendre et du vin cependant je pense que à long terme plus marquants du tout mais je pense qu'à long terme les intelligences artificielles comprendront mieux la pédagogie pour les humains que les humains prennent eux mêmes à ce moment là en fait c'est intelligent certes i7 devra être capable bien mieux que nous de nous expliquer les choses intéressantes à comprendre en mathématiques et si jamais elle n'y arrive pas j'ai envie de dire que finalement l'intelligence artificielle c'est comme un mathématicien un mathématicien aujourd'hui si on prend pendant que la conjecture a b c ou d une conjecture à laquelle il ya une preuve depuis 2012 quelque chose comme ça proposé par mochizuki un mathématicien japonais la preuve fait 500 pages est bon je crois qu'aujourd'hui a peut-être deux ou trois personnes qui ont lu la preuve en quoi est-ce que mouche isu qui est vraiment différente d'une intelligence artificielle qui aurait écrit une preuve de 500 pages j'ai envie de dire que dans les deux cas malheureusement pas ce qu'ils ont fait est tellement compliqué que nous autres pauvres humains qui ne sommes pas pu choquer ou l'intelligence artificielle prend pas ce qu'ils ont fait forcément elle espère qu'ils avaient une et cet épisode que vous allez faire attention apport à la surinterprétation d'ailleurs le prochain épisode de parlera encore du problème de la surinterprétation multi de laxou d'interprétation aux particules devraient se poser la question imaginez une pièce dont huit fois de suite surface est-ce qu'elle va encore tomber surface au prochain en selle après l'autre vous avez aimé cet épisode penser à le lit qu'elle augmente à le partager pensez vous la prochaine fois demandé leur avis aux gens qui sont le plus impliquées je pense que c'est la pire des méthodes ceux qui sont au coeur de l'activité sans justement les personnes qui ont la vision la plus biaisée par exemple un journaliste qui voudraient savoir s'il ya beaucoup de criminalité dans sa ville il y aura probablement tendre un micro aux policiers qui prend la déposition à l'accueil du commissariat à votre avis qu'est-ce qui va répondre bah oui c'est clair vous imaginez pas tout ce qu'on voit ici tient pas plus tard que hier ben ya un type qui bla bla bla ce type là toute la journée il ne voit que des gens qui ont justement des problèmes il a le nez dedans ce qu'il faut c'est au contraire avoir du recul il faut comparer les statistiques de la criminalité avec la moyenne nationale en gardant bien à l'esprit tous les biais de déclarations qui peuvent venir fausser les comparaisons c'est un travail de sociologie et donc notre journaliste ferait mieux d'aller à l'université pour interviewer des chercheurs qui travaillent sur la criminalité