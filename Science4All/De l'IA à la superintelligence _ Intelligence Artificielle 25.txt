la dernière fois on a parlé de l'émergence d'une intelligence artificielle de niveau humain pour fixer les idées on va être un peu plus précis et considérer le cas d'une ya capable de passer une version forte du test de turing le test de turing rappelez vous on en a déjà parlé dans l'épisode 3 on l'appelle aussi le jeu de limitation il s'agit d'un test d'intelligence proposé par turing en 1950 où une intelligence artificielle doit parvenir à se faire passer pour un humain lorsque l'on 4 avec lui disons sur twitter si on parle longuement un compte twitter y compris en cherchant le piéger pour tester si s'agit d'un humain et cie ont conclu que notre interlocuteur est un humain alors qu'il s'agissait d'une machine alors la machine aux commandes du compte twitter aura passé le test de turing comme on en a déjà parlé le test de turing est vraiment un problème très difficile pour les ir puisqu'elles doivent être capables de comprendre toutes les subtilités de la langue et réagir un nombre exponentiel de contexte imaginables pour ce faire elles devront absolument extraire une sémantique de nos discussions c'est à dire disposer d'une façon de compresser l'information à ce qu'elle a de plus essentiel et elle devrait être capable de manipuler la sémantique pour ensuite répondre de manière intelligente bref tout ça pour dire qu'une ya qui saura vraiment passé le test de turing le paiement se faisant passer pour un humain brillant plutôt que prend en ukrainien de 13 ans qui parle mal l'anglais une telle loi pourrait bien n'être en tout point au moins aussi intelligente que l'homme et on a vu dans l'épisode précédent que selon les chercheurs on y a une telle vie à deux niveaux humain pourrait voir le jour dans un avenir pas si lointain en particulier une bonne proportion des chercheurs en ya en ce que cette ia existera avant 2050 selon ces chercheurs ou non en fait des chances d'êtres vivants quand saisir perd 11 jours et ce n'est pas de ça dont je veux parler aujourd'hui ce dont j'aimerais vous parler n'est pas d'une intelligence artificielle de niveau humain ce dont j'aimerais vous parler ces deux super intelligence et par son intense à penser que l'ia restera deux niveaux demain sauf que l'intelligence humaine n'a aucune raison d'être une borne supérieure sur l'intelligence physiquement possible pour s'en convaincre on peut regarder les autres intelligence qui existe sur terre le fossé entre les intelligence humaine et celle disons des dauphins est monumentale par exemple il me semble mais je me trompe peut-être que les dauphins ou non seulement aucune notion de logique formelle mais il semble même impossible leur faire comprendre dans le truc comme le moule du spawn ans et remplacer dauphin par grenouille ou parce qu'arabes et je serai encore un peu plus confiant leurs limites cognitives en fait si on met les intelligences des animaux sur un axe il me suffit l'a pas dit qu'il fallait pas faire ça ok si on met les facultés des animaux a effectué des raisonnements bayésiens on se rend vite compte que le dernier des abrutis humain est en fait sur cette échelle juste à côté du plus grand des gènes humains qui est peut-être john von neumann si vous ne connaissez pas vos neurones lisez sa page wikipédia anglophone si l'intelligence artificielle progresse à un rythme constant le long de cet axe sachant tout le chemin qu'elle aura dû parcourir pour arriver jusqu'à nous en quelques décennies il paraît difficile d'imaginer qu'elle s'arrêtera à nous pendant plusieurs décennies au contraire il semble probable qu'en l'espace de quelques années voire peut-être de quelques mois son intelligence sera passé de celle du plus six milliards d humains aux plus grands cerveaux parmi nous c'est ce qui marche cette illustration de white way on y voit des humains à une station de train cette station est la station de l'intelligence de niveau humain et regardez là arrivent dit quelqu'un elle arrive vite se rajoute un autre et le train passa sans s'arrêter à la station de l'intelligence de niveau humain li a pourrait ainsi nous surpasser sans nous avoir vraiment égalé d'ailleurs on a déjà un exemple d'une telle remontada des intelligences artificielles ainsi en 1997 deep blue fut la première machine à vaincre d'un champion de l'échec lors d'un match épique contre garry kasparov cependant on peut dire que deep blue n'avait atteint qu'un niveau humain puisque le match était très serré cette bataille entre machines et humains y aura alors des années puisque autour de 2003 trois matches finir à égalité les à partir de 2006 n'y eut plus photo la machine avait atteint un niveau surhumain aux échecs ainsi dans le cas de diplômes il aura fallu près d'une décennie pour passer de l'intelligence de niveau humain a une super intelligence des échecs cependant cet exemple est trompeur notamment parce que les successeurs de deepblue reposait sur des technologies hardware moins sophistiquée que deep blue qui tu es vraiment un super calculateur qui plus est c'était il ya vingt ans à une époque où la vitesse de progression désir n'était pas ce qu'elle est aujourd'hui et n'était pas ce qu'elle sera dans quelques décennies signa général atteint le niveau humain or quand on regarde la vitesse d'adoption des technologies par la population on se rend compte que la transition entre technologie prometteuse et technologies contournable et de plus en plus rapide en passant de quelques siècles à quelques années quand il s'agit de remonter à des machines un exemple plus pertinent est sans doute celui du jeu de go tout d'abord peu de gens avaient vu venir alpha go il y adeux deep mind qui triomphe eu ras du joueur humain lice idole ainsi avant octobre 2015 les i à 2go devait laisser des handicaps importants à leurs adversaires pour espérer rendre le jeu intéressant à ce moment là les experts en ia avait prédit qu'il faudra encore 12 ans pour que les surpasse l'humain au jeu de go mais tout à coup alpha go surpris tout le monde en battant un joueur raisonnablement bon puis en mai 2016 alpha yago gagna contre l'une des pointures mondiales et son était déjà finie et joueurs humains un an plus tard alpha go se débarrassa à plat de couture du numéro un mondial et de quelques autres joueurs et en octobre 2010 cet alphabet aux héros fut introduit et détruisit alpha go par 100 victoires à zéro plus stupéfiant encore en décembre 2017 unia qui partait de rien alpha 0 s'entraîna pendant seulement 9 heures pour atteindre un niveau supérieur à tout moment et à tout autre iya et cette même il devint aussi numéro 1 mondial aux échecs et eau chaude ou un autre jeu de plateau cette fois la transition entre intelligence ou humaines au jeu de go et intelligence surhumaine avait eu lieu en l'espace de quelques mois et la transition de suremain super intelligent sogo en moins de deux ans et selon nick votre home il ya de bonnes chances qu'il en soit de même pour le problème de l'intelligence général à un moment où les expert persisteront à prédire qu'il faudrait au moins une décennie pour construire une intelligence général de niveau humain on pourra tout à coup trouver une façon d'améliorer nos dires pour qu'elle atteigne soudainement un niveau surhumain et puis quelques années voire quelques mois plus tard cette ya deux niveaux sur humain pourrait elle même être très largement surpassé par une super intelligence et en particulier tout à coup il y aurait une entité tous les facultés surpasserait peut-être même la réunion d intelligence humaine d'ailleurs à bostrom n'est pas le seul à être de cet avis voici un extrait d'une conférence à ce sujet kobe est bien y réfléchir il me semble très difficile d'imaginer une alternative un tel scénario de décollage rapide de la super intelligence surtout si cette liga a accès à internet et de base aujourd'hui les ja comme celle de youtube google ou facebook ont accès à internet en effet unia qui tout à coup résoudrait le test de turing sera alors capable d'écouter et de comprendre la sémantique du langage main elle pourra alors se précipiter sur wikipédia et posséder toute la connaissance basique mène elle pourra regarder les vidéos de sign for all et comprendre l'essence des mathématiques et de sa propre intelligence elle pourra lire les dernières publications des chercheurs en intelligence artificielle et comprendre mieux que n'importe quel humain comment améliorer sa propre intelligence elle pourra rapidement programmé un code qui correspond à une intelligence artificielle supérieure à elle même et l'exécuter sur les centres de données de google mieux encore cette nouvelle il pourra alors mieux comprendre intelligence que l'ia qui l'a construite ce qui lui permettra de programmer des liens encore plus intelligente initiant ainsi une boucle de rétroaction extrêmement rapide qui n'a que peu de chances de s'arrêter bref il semble alors qu'un petit déclic dont l'intelligence désir conduirait probablement à un énorme boum dans les facultés cognitives désir ce qui conduira alors à l'apparition soudaine d'une unique super intelligence à côté de laquelle tout autre ir semblera ridiculement stupide c'est ce qui est arrivé avec alpha 0 et il me semble difficile de ne pas croire que ce soit ce qui se passera pour la première super intelligence cette super intelligente ne sera peut-être pas le résultat d'un long progrès minutieux planifier et prévisible elle pourrait bien plus être le résultat d'une soudaine explosion de l'intelligence des machines puis ça fait analyser et vous avez sans doute envie de rejeter cette conclusion stupéfiante souvenez vous que je ne parle pas là de est-ce que la super intelligence va bientôt apparaître je pense qu'on a encore quelques décennies devant nous même si je ne suis absolument pas sûr de ce que je dis en revanche ce qui me semble assez probable c'est que lorsqu'une ya général apparaîtra celle ci restera assez longtemps à un niveau humain uniquement non à en croire le raisonnement que soutiennent notamment et les hauts lieux de cause ce qui est inique post rome et que vous l'aurez compris je trouve vraiment convaincant lie à general passerai rapidement ne pas futé est largement supérieur à toute l'humanité combiné est super intelligent ce serait alors une sorte de bombe à retardement qu'on risque forte ne pas voir venir pendant longtemps cette bombe semblera très inoffensive mais une fois qu'elle aura explosé en risque fort de ne pas pouvoir faire marche arrière et de ne pas comprendre ce qui nous arrive c'est pour cela que selon lui de kossi et post rom ce serait une grossière erreur que d'attendre l'instant où l'ia générale s'apprête à exploser pour anticiper les conséquences de cette explosion en particulier si cette première super intelligent c'est une morale qui diverge fortement de la morale des humains on risque fort d'assister à une triste fin de l'humanité reste alors à s'assurer que la morale de la super intelligent ce sera au moins approximativement aligné avec ce qu'on voudrait qu'elle fasse sauf que l'un des gros problème c'est qu'aujourd'hui on ne sait pas ce qu'on veut que cette super intelligent ce passe notamment parce qu'on a tendance à négliger la probabilité d'une explosion de l'intelligence or même si votre créé dans son ce scénario explosif est faible même si elle est de 1 pour cent disent non il vaut mieux anticiper parce que là on parle vraiment de risque existentiel quand la première super intelligence accédera au pouvoir on pourra vraiment s'attendre au pire ou omeyer on pourrait assister à la destruction de l'humanité ou au contraire à l'éradication de la faim dans le monde et des maladies une surabondance des biens combinée à une préservation des ressources voire à l'allongement traces tic de la vie en bonne santé comme l'expliquent monsieur fille ne super intelligence est avant tout fondamentalement imprévisible par nos cerveaux fini et si vraiment d'imaginer qu'est ce qui se passe dans la tête comme on parlerait comment penserez comment quelqu'un qui a vécu cinq siècles analysera une situation extraordinairement difficile une dotation d'essayer de se rendre compte à quel point c'est fissiles c'est de renverser la perspective de se dire j'ai essayé d'imaginer situation symétrique dans cette situation pour parler de ce problème là ça serait imaginé une situation où un enfant de 7 8 ans et sert et décrira histoire à propos de notre personnage qui aurait vécu plusieurs décennies que rêver qu 50 60 ans peut-être pas fou oui avec ceci de particulier que ce sera un enfant de 7 8 ans qui n'auraient jamais qui vivraient dans une communauté d'enfants au fait qu'il n'aurait jamais rencontré l'adulte qui y vécut entre juste entre enfance j'ai imaginé ce serait une sorte de tribut dans cette voie là d'enfants qui auraient le même genre de cerveau kling et simplement physiologiquement sera appelée différence se développerait beaucoup plus vite et mon gré vers l'âge de 10-11 ans maximum vous imaginez un enfant 7 8 ans qui serait d'imaginer ce que serait la société de dom qui vivrait plusieurs décennies sort par exemple fou parce qu'on oublie pas plusieurs décennies pour on sent bien que mal pour essayer de raconter une histoire autour de tout ça mais quelque part ce sera un peu à côté de la plaque ce qui racontera propos c est ce que marc sens bien déjà qu'il écrirait pas très bien voilà et que oeuvrer à ce qu'il explique et surtout au sujet des adultes de 50 60 ans ce sera vraiment ridicule et finalement quand brahms aucun essaye d'écrire dracula il est dans la même situation il essaye d'écrire les pensées et le comportement de l'être qui aurait vécu comme ça qu'ils avaient traversé plusieurs siècles et quand on lit quand lee bram stocker et de façon générale comme lille dans la science fiction dans le fantastique des personnages pour ce genre de caractéristiques là et c'est assez fréquent c'est toujours un peu raté c'est toujours un peu mauvais et c'est normal parce qu'en fait ça peut pas être beau de tout simplement parce que pour savoir exactement qu'est ce qui se passera dans la tête de quelqu'un qui aurait vécu cinq siècles bah il faudrait il faudrait faudra 20 vécu cinq siècles connaître des gens qui auraient vécu ça on n'en sait rien comment réussir à décrire analyser une intelligence qui serait très supérieure à la nôtre ça semble poser un problème radical qui est qu' on essaie de le faire avec notre intelligence d'une sortie jans 18 fondamentalement notre capacité à décrire des intelligences [Musique] personnellement quand j'ai pris conscience de l'ampleur de l'enjeu de la morale de la super intelligence je me suis rapidement mis à reconsidérer mes priorités moral à côté de ce risque existentiel tous nos débats et nos divisions politiques habituels ne semble être qu'une infime goutte d'eau or déterminer la morale de la super intelligence est un problème incroyablement difficile et après avoir beaucoup lu beauce trône beaucoup écouté yeux de cause qui est beaucoup regardé roberte miles je peux vous garantir une chose ne résoudrait pas ce problème en réfléchissant 30 secondes l'imam en infléchissant 30 heures ou 30 jours selon bostrom résoudre le problème de programmer la morale désir est un défi de recherche digne des plus grands talents mathématiques de la prochaine génération et c'est de ça dont on va parler dans les prochaines vidéos dernière fois en est à parler de l'émergence de la singularité ou plus exactement de ce moment où l'intelligence artificielle deviendra en tout point supérieur aion et j'avais fait un sondage notamment avec google forme ou s'est demandé de donner vous avez eu 500 réponses et voici les résultats compilés bresse et ses courbes montre ce que vous pensez de la probabilité qu'il y ait une indigence de niveau humain alors qu'il a ses différentes dates dont classés entre 2000 et aujourd'hui et alors 3000 et c'est ce que j'ai appelé dans le formulaire avant la nuit des temps voilà je pense que trop mais c'est extrêmement éloignée de nous former la vitesse de pro à des technologies si ça a fallu avant 3 mais j'ai envie de dire que ça va très probablement jamais lieu bref ce graphique montre un peu un peu différente prédiction donc par exemple la courbe bleue donne les prédictions moyenne probabilité moyenne que vous attribuez l'émergence d'une ihm c'est la singularité ces différentes dates alors que la courbe rouge donne la note médiane avec meziane a l'avantagé d'être beaucoup plus robuste est beaucoup moins sensible à quelques prédictions à ces extrêmes par exemple là si on regarde sur la nuit des temps et bah ouais en fait la grande majorité d'entre vous pensent que c'est quelque chose qui te dis à ces câbles qui va finir par arriver et mais comme il y en a parmi vous qui pensent que la singularité n'arrivera jamais ça fait que la moyenne n'est pas du tout proche de 100 elle proche même à 80 6 et 1 90% quelque chose comme ça mais pas exactement 100 % la courbe orange correspond aux quand il de 10 % c'est-à-dire que les 10% les moins optimistes par rapport à lire d'entre vous c'est ceux qui prédisent du pur 100e d'entre vous d'humour le plus pessimiste c'est ce qu'il faut a dit alors que la courbe verte c'est le 90% c'est celle inverse donc là sur scène comme on voit pas forcément ce qui se passe dans un avenir proche de vous montrer notre courbe ces différentes courbes ce sont vos prédictions sur la franche entre aujourd'hui et 2100 et finalement je n'ai pas trop de raison de me sentir mal à l'aise puisque en fait les prédictions correspondent grosso modo à moyenne ou la médiane d'entre vous je pas du tout quelqu'un d' extrémistes et il ya quand même pas mal par milou 10 % qui pensent qu'en fait la singularité et a de bonnes chances d'être finalement assez bientôt est en moyenne 10% dans le permis vous qui pensent que la singularité pourrait être arrivé en 2025 ce qui est quand même vachement très bientôt et sachant ce que j'ai dit dans cette vidéo est ce que selon thomas parler dans des vidéos à venir ça fait flipper ça donne envie de faire beaucoup de recherches sur comment bien programmé la morale désir et quels sont les dangers potentiels à différentes versions de cette morale or voici les détails de vos prédictions par rapport à différentes dates donc ça c'est vos prédictions pour 2025 donc vous êtes quand même pas mal à trouver très peu de probabilités à ce qu'est une super intelligent il n'ya de niveau humain en 2025 mais vous restez tout de même une majorité à dire que ça reste possible et qu'une majorité d'entre vous attribue une priorité non nul à ce qui se passe un truc assez spectaculaire en 2025 ça fait vraiment vraiment réfléchir et par contre pour 2035 les choses deviennent vraiment vraiment sérieuse puisque si on croit ce que vous en dites et la finance on croit aussi avait cherché à retenir est quand même une probabilité très nombreux ni diable très très supérieures à un pour mille une bonne probabilité pour que il se passe quelque chose d'ici 2035 ce qui fait vraiment flipper et si on regarde les 1050 là on a plus d'une chance sur deux d'après vous quels y atteignent le niveau d'intelligence humaine et ça ça veut dire que tous les boulots sont automatisables on a tous les boulots qui consiste à expliquer transmettre des données à gérer des papiers tous ces bobos pris en 2005 en titre ont disparu avec une chance sur deux d'après vous et si on avance dans le temps de 1500 tu dis ça par contre ça devient même concept une majorité écrasante au d'entre vous qui pensent qu'il ya quand même de très bonnes chances que les désirs de niveau humain à ces moments là en fait il ya vraiment pas besoin d'attendre la fin du siècle si on vous en croix pour être très très très concerné par le danger d'une super intelligence et de tout ce que cela peut impliquer et du changement de société qui va falloir préparer dès aujourd'hui en fait si on prend aux prédictions ont typiquement un exemple prendre ça un peu plus concret parce que quand on parle de tout ça a tendance à laisser des trucs assez abstrait de façon assez concrète celui que vous dites c'est que va pour les jeunes pour les moins de quarante moins de 50 ans repensez à la retraite sahara est aujourd'hui puisqu'il risque qui se passera vraiment quelque chose d'assez important d'ici quelques décennies et du coup à personne de 50 ans lorsqu elles partiront à la retraite bah il faut peut-être 130 qui aura même plus de job est de toute façon à ce moment là il faudra avoir complètement repensé la société jan hein fois que j'avais aussi parlé de la loi de moore de cette fois progression exponentielle des technologies et à izaguirre a fait remarquer qu'en fait il ya pas mal de discussions sur le fait que la loi de moore pourrait arriver à sa fin pour être déjà à être arrivé à sa fin notamment parce que les microprocesseurs atteigne des limites physiques que ce soit en terme de limites quantique puisqu'on a un proche au des limites quantique et du fait que l' on peut pas mettre des écrans trop proches au sein qui se passe des trucs quantique à ce niveau là et que du coup toute la technologie classique du microprocesseur ne marche plus on peut plus à miniaturiser en tout cas donc ça c'est en effet un autre point important c'est que l'essai pu en fait chauffe énormément et c'est pour ça que pendant longtemps et vitesse de calcul des cpu début que ces milliards d'esprit aujourd'hui regardez vous offre votre ordinateur est souvent giguère tout moment et ça fait longtemps fait qu'on en giga hertz qu'on n'a pas augmenté la vitesse que des procédés microprocesseurs une bonne raison à cela c'est que beaucoup plus grande fréquence correspond plus d'énergie et plus d'énergie ça veut dire que ça chauffe et quand ça chauffe pas une limite qui à la limite de l'évacuation de la chaleur et ça c'est une limite physique aussi une force on atteint les limites physiques ça veut bien dire qu'on peut pas faire mieux et en effet les lois de la mode humour en tout cas on sait les termes là on atteint les limites physiques du coup on dit en train de plafonner ceci étant dit la recherche aujourd'hui notamment en iran ne nécessite plus vraiment les cpu est plutôt que miser sur essai puis aujourd'hui beaucoup d'architecturé dire repose plus sur les gpu c'est à dire les cartes graphiques ou le calcul est très très très paralléliser en fait lié à ccc naturellement adapté à faire des calculs très très paralléliser à cause des limites de la loi de moore notamment et du coup aujourd'hui on n'a pas besoin de miniaturiser puisque ça a surtout besoin de mieux par à l'elysée le calcul est là par contre on est ultra un an loin encore des musiques et en cartes de calcul distribué je pense qu'avoir beaucoup d'améliorations à venir une autre grosse amélioration notamment en termes hardware puisque je pense qu'ils en ont l'air doit encore beaucoup progresser si on n'y a eu ni bruit dont une à une des grosses difficultés du rappeur c'est que aujourd'hui souvent les quelques soins encore assez centralisée et même dans un j'ai pu le calcul est encore assez centralisée et c'est qu'on veut tendance si on veut faire un truc comme le cerveau humain s'est décentralisé un maximum tous ces calculs avoir des calculs plus en plus pas réaliser et si possible avoir des données qui sont disponibles tout de suite à côté des unités de calcul parce qu'aujourd'hui souvent la ram nullité de mémoire et unités de calcul qui sont séparés en fait si on essaie de ne plus manger les deux d'avoir non seulement un calcul distribué mais aussi un représentation des données était décentralisée à ce moment là on pourra beaucoup plus accéléré lesquels il ya beaucoup de recharge ce dans ce domaine il vous renvoie maintenant vers la présentation des élites saclay de julich grolier qui est voici qui parle rarement de ce travail hardware qui a été bon maintenant nécessaire pour pouvoir faire des quelques beaucoup plus performant et si on regarde maintenant c'est que ce genre de les progrès dans l'ordre architecture en gros la loi de moore consiste à continuer à perdurer j'en veux dire on a toujours une croissance exponentielle des puissances de calcul telle mention ramène ça à l'énergie nécessaire pour faire ses calculs puissance de calcul par joule voix dire vraiment des progrès qui sont impressionnants est vraiment vraiment exponentielle encore dans tous ces domaines à le dire lui pose la question de s qu'il pourrait y avoir un effondrement des civilisations notamment pour des raisons environnementales avant sa singularité justement c'est intéressant parce que je n'ai pas mal parlé avec rodolphe de la chaîne lors éveilleurs tellement je vous conseille cette vidéo part sur le pic pétrolier où il parlera de ce risque qui peut être énorme qui serait un pic pétrolier il ya plus de pétrole montre beaucoup moins de pétrole et peut avoir beaucoup de tension notamment réseau politique à ce moment là et c'est pose vraiment la question de crise comment est ce que l'on pourra réagir à une chute de la production de pétrole et voilà qu'après sa vidéo il dit que ça pourrait arriver entre 2020 et 2050 que ça pourrait typiquement est trop de rechange avant la sécurité potentiellement donc bien sûr c'est très difficile à exclure et en parlant avec rodolphe voilà c'est celui qui comprend mieux ses enjeux et puis moi parce que j'avais tendance à pas mal sous-estimer ces risques-là par rapport à haut risque de deux il ya une super intelligence notamment mais c'est vrai que c'est les enjeux et des risques assez préoccupant après voilà c'est ce que je dis aussi c'est que je ne sais pas dans quelle mesure qu'est ce qu'on peut faire pour éviter ces risques aujourd'hui il me semble que encore l'une des meilleures choses à faire c'est vraiment investir énormément dans la recherche sur des énergies alternatives sur le stockage des denrées sur plein de solutions pour pouvoir avoir un truc pour produire plus d'énergie plus vert plus plus durables et moins dépendante des tensions géopolitiques tout pas mais c'est très compliqué bien sûr l'avenir est très difficile à prédire surtout dans ces domaines mais j'aurais tendance à dire qu'il faut vraiment parce que il ya danger là faut vraiment continuer à faire pas mal de recherches et peut-être que lille i hate rouvre à la recherche on y trouvera des solutions pour rendre bon jeu pour vraiment faire un percées technologiques et permettent peut-être de capturer une fraction beaucoup plus grande de l'énergie solaire pour qu'elle puisse remplacer un petite fraction de l'énergie qui est aujourd'hui extraite du pétrole s'est énormément dangereux le futur est peint de d'incertitude et ça peut aller très bien tout ça peut être assez catastrophique elle espère que j'avais mais cet épisode la prochaine fois on va parler justement de scénario catastrophe on va pas faire un truc un peu plus tard écrit voilà je fais des vidéos assez difficile dans ces deux faits sur la sueur sur scène paul et du coup il ya vraiment des gens qui ont arrêté de regarder un peu les vidéos et voilà la semaine prochaine je peux vraiment me dit nos biens acquis mais certaines intéressantes qui il a fait huit c'est vraiment de faire réfléchir malgré tout rapide technique et histoire de dire aux gens qu'ils sont abonnés que voilà 500 euros devient beaucoup plus simple à comprendre vous parlez de truies que deux sociétés en plus qui peut concerner tout le monde et qui sont très intéressante à mon sens mathématique donc c'est ce qu'on va faire la semaine prochaine si vous avez aimé c'est l'épisode penser à la ligue et à le commenter à nous partager pour ça vous abonner pour enfin sur ces épisodes verscio ti par paulhan et j'espère que vous serez là [Applaudissements]