dans les trois dernières vidéos en compagnie d'invités trop cool on a posé le problème de la surinterprétation surinterpréter s'est expliqué ce qui n'est en fait que le fruit du hasard ceci correspond typiquement à donner trop d'importance aux données plutôt qu'aux modèles ce qui a la fâcheuse tendance d'augmenter le risque d'apprendre des règles non généralisable on a aussi vu comme pratique pour lutter contre assure interprétation on pouvait utiliser des méthodes statistiques comme la validation croisé qui consiste à ajuster le niveau d'interprétation adéquat en voyant comment une règle déterminé par un training 7 se généralise à d'autres données que l'on appelle le test 7 mai pour un théoricien comme moi il ya quelque chose d'assez frustrant avec la validation croisé on voit intuitivement pourquoi ça marche mais il est difficile de dire qu'il s'agit vraiment de la bonne façon de faire c'est comme si on utilisait une fourchette pour touiller le sucre dans le café ça marche qu'on sent que c'est pas idéal aujourd'hui j'aimerais vous parler de l' approche de l'informatique théorique pour comprendre le problème de la surinterprétation cette approche consiste à prouver un théorème qu'il garantit que sous certaines conditions tout ira bien et le théorème en question dit la chose suivante si la complexité des explications est une petite fraction du nombre de données alors on sera garanti d'éviter le piège de surinterprétation est le corollaire de cela c'est que nous autres humains sommes très souvent en excès de sur interprétations alors ça peut vous surprendre qu'il ait beaucoup de mots flou dans la formulation de ce théorème d'ailleurs tel qu'il est écrit là ce théorème est faux mais il est presque vrai le truc c'est qu'à l'école on apprend des définitions et des théorèmes méticuleusement fignoler qui sont souvent le fruit de siècle de recherches mathématiques et on vous demande ensuite d'appliquer ces définitions une théorème dans des exercices mathématiques sauf que comme j'en ai parlé la dernière fois ce genre de pratique peut donner l'impression que les mathématiques sont un ensemble de connaissances figé et immuable elles conduisent les bons élèves en mathématiques à se comporter en dr john alors que non mais non non non j'ai bien peur que cette impression de rigidité des mathématiques conduisent beaucoup d'élèves a constamment faire de la surinterprétation c'est-à-dire à sacraliser la rigidité des définitions qu'ils ont apprises voire même le choix des notations qui ont été utilisés en cours et oui ça existe il y a des g un nazi des notations mathématiques ça existe sauf qu'en fait les mathématiques surtout au niveau de la recherche c'est tout sauf rigide on l'a vu le concept de nombre n'a cessé d'être défini et redéfini dans l'histoire des mathématiques aujourd'hui j'aimerais vous faire sentir la vraie façon de penser des chercheurs en mathématiques appliquées en informatique théorique ou du moins ma façon de structurer mes réflexions mathématiques celle ci consiste justement à partir de notions intuitive assez floue et à chercher une jolie reformulation mathématiques de ses idées bien sûr va essayer de rester fidèle à l'intuition original mais on hésite généralement pas à changer la définition des mots d'une part pour lever les ambiguïtés du langage naturel mais aussi voire surtout pour que la définition mathématiques rigoureuse rente nos jolies théorème vrai et pour les docteurs john psychorigide parmi vous qui douteraient de cette flexibilité des mathématiques je vous recommande ses excellentes vidéo de number five et mick matt bidouiller les définitions des mots c'est un peu la solution mathématique pour lutter contre la sous un terreau prestations et écrire des théorèmes élégant bref revenons donc au théorème que l'on voulait prouver ce théorème dit que si la complexité des explications est une petite fraction du nombre de données alors on sera garanti d'éviter le piège de la surinterprétation est le premier concept à redéfinir va être le concept de complexité oui parce que par exemple le concept de complexité de solomonoff est inadéquat pour rendre ce joli théorème vrai dans les années 70 ce sont les informaticiens vladimir weiss nique et alexei shirov jeunes qui ce qu'ils sont parvenus à trouver la bonne définition pour ce faire intuitivement l'idée de va'a punique et sharon ankis c'est de compter le nombre maximal d'explication haddock autorisé et pour mesurer ce nombre d'explications haddock il faut imaginer qu'on dispose est originalement d'une sorte de chapeau d'où on pouvait tirer des explications haddock voilà qui nous amène à mesure et non pas la complexité des explications mais plutôt la complexité du chapeau à explications haddock et intuitivement la dimension wc va être une certaine mesure de la taille du chapeau à explications haddock et ça c'est important à garder en tête au delà de notre cadre aux mathématiques à chaque fois que l'on tire une conclusion ou la tire d'un ensemble de conclusions possibles il y a donc une sélection de la conclusion retenue alors bien sûr cette sélection à l'eba arbitraire elle est motivée par les données mais qui dit sélection des biais de sélection surtout quand il ya de la lea dans les données et de façon cruciale comme on l'a vu dans l'épisode 11 plus on sélectionne parmi un grand ensemble de conclusions possibles plus ce biais de sélection sera élevé et bien d'une certaine manière la dimension wc mesure ce biais de sélection en fonction de la taille de l'ensemble des conclusions en mise à g formalisons encore un peu plus sa notion de dimension wc pour cela prenons par exemple trois points dans l'espace des feature avec des les balls qui sont des like ou des dislike et supposons que l'on découvre les walls des trois points au fur et à mesure 6 quel que soit le les vols du premier point il existe une hypothèse du chapeau qui explique ce les bols alors le nombre d'explications haddock autorisé par le chapeau formellement appelé la dimension wc du chapeau est supérieur ou égal à 1 prenons maintenant un deuxième point 6 quel que soit le lait bol de ce second point on peut encore expliquer les les vols avec deux points à l'aide d'une explication du chapeau alors la dimension wc du chapeau sera supérieure ou égale à 2 j'espère que vous commencez à sentir là où je veux en venir prenons un troisième point si on peut expliquer toutes les valeurs des les vols des trois ponts à l'aide d'explication du chapeau alors la dimension wc du chapeau sera supérieure ou égale à 3 dans le jargon on dit que le chapeau pulvérise l'ensemble des trois ponts alors pour le coup le mot pulvérisé vient pas de moi en anglais andy shatter et seulement que je connaissais et puis en préparant cette vidéo j'ai découvert cette traduction est pas mal de façon plus générale un chapeau à une dimension wc au moins des s'il existe un ensemble de des points dans l'espace des features tels que toutes les configurations de livebox 2 cd points peuvent être expliquées par une explication du chapeau de façon équivalente ceci revient à dire qu'il existe des points que le chapeau pulvérise la dimension wc du chapeau sera alors le nombre maximal de points dans l'espace défectueuse que le chapeau parvient à pulvériser intuitivement c'est bien le nombre maximal d'explication haddock autorisé par le chapeau à explication puisque alors si je prends n'importe quel autre point il existera un les vols pour ce point qui ne pourra pas être expliquées par une nouvelle explication haddock du chapeau alors là pour simplifier je me suis passé dans le cadre de l'apprentissage superviser ou les labels sont uniquement des likes des dix lacs mais bien sûr pour des cadres plus généraux il faudrait encore modifié à la notion de complexité en fonction du cadre que l'on considère on peut utiliser la dimension de nataraja la complexité de rades marqueurs ou encore la pseudo dimension de polars mais revenons-en à la dimension wc et illustre on l'a avec un exemple supposons que l'espace des fidjiens aux soins un plan de dimension 2 et considérons un chapeau contenant tous les classes if your linéaire du plan alors avec un peu de patience et de réflexion on peut voir qu'un ensemble de trois points non alignés et pulvérisé par le chapeau déclassifiant linéaire du plan en effet quelles que soient les les vols des trois points je peux trouver une droite qui séparent les like des dislike le chapeau déclassifiés leurs linéaires blanc a donc une dimension bc supérieur ou égal à 3 en fait on peut montrer qu'elle est égal à trois quarts pour toutes ensemble de quatre points il existe des labels pour ces quatre points qu'une classification linéaire ne pourra pas expliqué typiquement peut avoir une configuration hawks or et on n'a vu qu'une classification linéaire seul ne peut pas expliquer louxor les classifiant linéaire ne pulvérise aucun ensemble de quatre points leur dimension pc est donc strictement inférieure à 4 or on a vu qu'elle était supérieure ou égale à 3 elle est donc égale à 3 de façon générale si les explications du chapeau sont paramétrés par un nombre prédéfini de paramètres alors la dimension wc du chabot sera plus ou moins ce nombre de paramètres oui presque intuitivement pour chaque nouvelle donne et on peut ajuster un des paramètres pour coller à cette donnée sans toutefois perdre notre pouvoir explicatif des autres données déjà observé bon ça ses intuitions n'en faites le calcul la dimension wc est souvent plus compliqué que cela bref vous voyez qu'on a pas mal bidouiller la définition du mot complexité mais j'imagine que vous sentez peut-être que notre définition formalisé qui correspond donc à ce concept de dimension b c est quand même assez proche d'une définition intuitive de ce que pourra être la complexité d'une explication mais juge de paix pour savoir si cette définition intuitive et punk ça reste de savoir si elle rend notre théorème frais ok donc changement un petit peu notre théorème pour inclure cette notion de dimension wc le théorème en version un poil plus formel dit maintenant si la dimension wc du chapeau d'explication est une petite fraction du nombre de données alors on sera garanti d'éviter le piège de la surinterprétation on y est presque mais il nous reste encore à définir mathématiquement le concept de sur interprétations est ce que je vous propose c'est de nous inspirer de l'épisode précédent avec cette histoire de training 7 et est 7 souvenez vous n'avez divisé aléatoirement nous donner en deux ensembles d'un côté le training 7 et de l'autre le test 7 et on avait vu que la surinterprétation c'était quand l'explication sélectionnés via le training 7 se généralise mal aux tests 7 c'est à dire quand le taux d'erreur août et 7 est beaucoup plus grand que le taux d'erreur au training 7 eh bien on peut incorporer toutes ces notions dans notre théorème intuitive ça nous donne le théorème suivant si la dimension wc est une petite fraction du nombre de données du training 7 alors le taux d'erreur hôtesses 7 ne sera pas beaucoup plus grand que celui au training 7,1 et presque il reste un dernier petit problème qui est le fait que ce théorème qui est maintenant formelle est faux je vous invite à mettre pause 30 secondes pour deviner pourquoi aller vite et pose le problème c'est qu'il y aura toujours des cas où le training 7 et le test 7 seront d échantillon non représentatif des données typiquement si on met tous les chocolats suisses dans le training 7 alors c'est un petit peu compliqué d'apprendre une règle pertinente le hasard fait qu'il existera toujours des cas où la surinterprétation sera inévitable du coup ce théorème est faux ce qui est un petit peu embêtant cependant on peut espérer que ces cas d'échantillons représentatifs sont rares et en effet en statistiques on observe que plus on est championnes aléatoirement de taux n'est plus on est quasi sûr d'obtenir un échantillon aléatoire représentatif et c'est justement ça la clé pour rendre notre théorème vrai on obtient alors le théorème suivant si la dimension wc du chapeau d'explication est une petite fraction du nombre de données du training 7 alors avec grande probabilité le taux d'erreur au test 7 ne sera pas beaucoup plus grand que le taux d'erreur au training 7 il ne reste plus qu'à être un petit peu plus quantitatif ce qui nous donne si la dimension vaisselle du chapeau d'explication est égal à baisser si la taille du trading sa a été égal à n et si on appelle paix la probabilité d'échantillonnage très non représentatifs alors avec grande probabilité 1 - p le taux d'erreur au test 7 sera opus le taux d'erreur au training 7 plus cette quantité là qui fait intervenir bcn ep ça c'est le théorème de vanik alors pour que ce théorème deviennent vraiment thuram il faut aussi et surtout une démonstration du théorème est d'ailleurs pour que la démonstration soit valide faut encore ajouter quelques hypothèses mais j'aimerais attirer votre attention sur le fait que la démonstration du théorème n'est pas toujours la partie la plus difficile n'y a plus intéressante et c'est peut-être dommage qu'elle colle dont tu parle généralement que des théorèmes et des démonstrations des théorèmes alors que formaliser un théorème intuitif en un théorème rigoureux est vrai en choisissant les bonnes définition des termes du théorème intuitif c'est en fait une très grosse partie de la recherche en mathématiques cliquez et en informatique théorique d'ailleurs on a là un joli t om mais c'est peut-être pas cette version du théorème qui le plus intéressante il reste souvent souhaitable de chercher à simplifier le théorème à le vulgariser en pratique ça va correspondre à une petite discussion dans l'article de recherche ainsi qu'à des remarques informelle à l'oral en séminaire ou à la pause-café entre les chercheurs ou encore au moment de la vulgarisation du théorème par votre serviteur si présent en particulier dans notre cas les quantités logarithmique ce sont en fait négligeable du coup même s'il est techniquement pas juste de le dire j'ai tendance à ne pas trop hésité à vous dire que le théorème de créer un unique prouve en gros oui généralement la sisqa même sur le fait que je suis approximative quand je le dis que l'erreur additionnel de généralisation est au plus de racine carrée de wc / n voici qui me conduit à la version vulgariser du théorème de vagues nick qui dit qu'avec grande probabilité l'erreur de surinterprétation est égale à la racine carrée de la dimension wc du chapeau d'explication divisé par la taille du training 7 ou de façon encore plus vulgarisée en pratique il est raisonnable de s'autoriser une nouvelle explication haddock que toutes les 100 nouvelles données sachant qu'un article de journal sur l'actualité n'a généralement qu'une poignée de nouvelles données et en plus sachant que les journaux ont tendance à répéter cette même nouvelle donnée voilà qui donne une idée à quel point quand il s'agit d'actualité nous sommes sans doute constamment en graves excès de sur interprétations j'espère que vous avez aimé cet épisode donc eu pas mal de collaboration récemment sur scène forum il voulait vraiment encore une fois remercier tous ses collaborateurs qui ont été a toujours géniaux et je remercie aussi leur type heures puisque indirectement c'est grâce à eux que j'ai pu avoir de telles collaborateurs sur les vidéos sensor aujourd'hui une poignée de vulgarisateur scientifique sur youtube qui a commencé à arriver à vivre des dons grâce à vous des cons et puis ça leur permet de produire leurs vidéos mais savoir permet aussi de façon un peu égoïste personnel de collaborer avec moi et je remercie énormément dé type her2 ses chaînes et s'ils voulaient faire une bonne action va aller type et tous ces gens formidables joueurs profitent aussi pour passer une annonce puisque après demain je serai au panthéon à paris pour parler de condorcet dans le cadre de la semaine des mathématiques au panthéon et y aura une présentation de 30 minutes mercredi soir l'entrée est gratuite donc si vous voulez venir n'hésitez pas toujours avec plaisir d'aller enfin à parler de validation de croiser et 42 nous demande aussi je me paraît vraiment de veillées sont croisés de vanités sont simples alors il faut savoir que le concept de validation croisés en tout cas d'après wikipedia est assez floue et assez mal défini et en effet il ya pas mal de variantes complet l'imaginer je pense que l'idée vraiment importantes et centrales cédées d'avoir un échantillon d'entraînement qui va nous permettre d'essayer de trouver des règles et surtout de tester la généralisation de ces règles à d'autres données qui n'étaient pas parmi les données d'entraînement on parle parfois de donner in saint paul à l'intérieur de l'échantillon d'entraînement et de donner à 900 volts et je pense que c'est assez fière importants y compris en pratique pour nous autres humains j'envoie précédente 8 et des règles à partir de choses qu'on observe est souvent très utile d'essayer de tester si ces règles vont bel et bien se généraliser et pour cela il faut absolument les communautés à des données qui sont 1 920 tonnes qui fera ne fait la remarque que même s'il comprend l'explication de pourquoi est-ce que le sophisme du parieur est un parieur il a du mal à se convaincre un petit moment que en effet ce 9e lancé en tout cas si les essais sont parfaitement indépendant ne sera pas influencée par les huit précédents et je pense que c'est absolument génial de se rendre compte que notre intuition ne fonctionne pas en cohérence entre nos traditions et la théorie mathématique ça permet de se rendre compte des limites de notre intuition et du fait que notre intuition est victime de beaucoup d'illusions ils vous envoient notamment vers la vidéo de monsieur fillon qui explique pourquoi est-ce que penser que le mois existe c'est quelque chose monfort intuitivement et du coup c'est quelque chose d'extrêmement dur a rejeté quand bien même il pourrait en fait ne s'agir que d'une illusion ne serait pas très différente des illusions d'optique façon plus générale je pense que ce genre d'exemple permet de se rendre compte que notre intuition vraiment à délimiter de se rendre compte surtout des limites de notre intrusion ça permet d' un peu de mieux comprendre l'étendue de notre ignorance et l'étendue de l'ignorance de l'autre intuition ce qui peut permettre notamment de se dire que ben finalement l'intuition on peut pas tant ils faire confiance que la vie notamment des modèles mathématiques ou la vie d'une personne plus informés que nous et peut être beaucoup plus fiable que notre intuition à charge nous propose un protocole pour que sachant qu'une pièce est tombée 8 x 2 faces estimer la probabilité qui avait tombé encore sur place il propose la chose suivante faut attirer un nombre au hasard entre 0 et qui va être la pro a et épais d'avoir un face et ensuite à partir de cette probabilité p on va simuler huit lancers et 6 et 8 ans et donne face alors on va mettre la pro btp qu'on avait tiré en mémoire et on répète cette expérience de pensée encore et encore donc petit à petit notre ensemble de valeurs paix qui ont été retenus va augmenter et quand il y en a suffisamment on peut à ce moment-là prendre la moyenne des valeurs peut calculer car on obtient l'or 0,9 comme la connexion de la place est en effet ses calculs la sont exactement les calculs de la place pour cinq ans n'ont pas tout à fait à l'aise logique en tout cas la philosophie du bannissement fait c'en est très très proche pour en savoir plus sur le baiser isme d'ailleurs je vous recommande les excès en vidéo de ce qui suppose sujet kresic la dernière vidéo d'hygiène mentale qui explique très bien les rudiments de la philosophie parisienne même si comme vous vous en doutez encore beaucoup plus à dire et quelque chose me dit que christophe est d'ailleurs en train de préparer toute une série de vidéos pour aller plus loin monsieur maxime demande s'il est possible de sauvegarder les règles déduites d'un premier training et peut-être qu'on peut les affirmer ensuite avec un second training alors en fait bien souvent le cadre classique du machine learning pro pas forcément exactement ça rend compte mais des évolutions un peu plus modernes notamment à l'algorithme la décence de gradient stochastique dont on reparlera sur cette toile permet une certaine forme de progression de praticiens déjà au fur et à mesure mais pour un bail gyan la bonne façon de faire cela correspond vraiment fait la sq est au coeur de la philosophie parisienne et je vous renvoie notamment vers vidéo de christophe pour avoir une intuition de ce que ça veut dire c'est que la protéger cumulatif et qu'on affine en fait à tout instant en fonction des nouvelles données qu'on observe nos croyances qui font honte était typiquement bref tout ça pour dire que cette idée d'apprentissage cumulatif en fait c'est exactement le cadre de l'apprentissage real se dire et c'est aussi le cadre fondamental de dubai et dieni gr kickoff pose de questions qui n'ont rien à voir je vais arrêter sur la deuxième question qui demande d'eau s'il est possible de déduire en gros les beaux axium des mathématiques à partir d'espèces de big data des dix futurs king toi alors je pense que la question de la plupart des mathématiciens cette question c'est clairement non mais en tant que base est inquiétant c'est à dire que finalement avec ce big data on va être facilement capable de voir quels sont les meilleurs algorithmes d'apprentissage et d'une certaine manière les algorithmes d'apprentissage sont peut-être les bons fondements du savoir et du coup une certaine manière les bons axiome des mathématiques voilà c'est une réflexion un peu philosophique que je fais là et c'est absolument pas juste mais je pense que c'est une réflexion qui est loin d'être stupide et j'aurais tendance à parier que c'est une réflexion qui finira par donner largement raison aux belges à nice mme faye a comparé l'intelligence des intelligences artificielles et des humains et faire remarquer que contrairement aux artisans savent bien il semble qu lui ment et besoin de beaucoup moins d'exemple en fait on peut quantifier la quantité d'informations de data auquel l'humain a eu accès au cours de toute sa vie et cette quantité d'informations et en fait absolument énorme imaginez qu'à chaque seconde tous mes sens en fait tu m'envoies de l'information alors qu' a priori pas vraiment sous la forme de 0 et de 1 en fait la première théorie de l'information elle est équivalente une série d 0 et 2 1 et donc d'une certaine manière le corps mais en fait en constant apprentissage de tout son environnement et il fait vraiment de l'analyse de big data autrement dit comme le fait remarquer psycho gore énormément de données pour une machine correspond à dire beaucoup d'expérience pour un être humain et ça ça correspond exactement raisonnement de turing 1950 dans son fameux article je vous renvoie vers les vidéos précédentes pour en savoir plus et ça veut aussi dire que pau kuni advienne intelligente il faut absolument qu'elle arrive d'une certaine manière à tirer le meilleur de toute son expérience autrement dit ça suggère encore une fois qu'il faudra un apprentissage cumulatif au hasard comme le bail zanis oui je vous avais dit qu'on ne parle pas de paysagisme dans cette série mais en fait c'est très difficile de parler tous ces sujets sans au moins mentionné le terme bézian j'espère que j'avais mais cette vidéo que ça nous a permis de comprendre un peu plus comment fonctionne en fait la recherche notamment en mathématiques appliquées et en informatique théorique voire de façon plus générale quelle est la nature des mathématiques et en quoi l'apprentissage mathématiques est très différent de la recherche en mathématiques d'ailleurs pour cette vidéo j'ai été inspiré par une excellente vidéo de gigot et cole parlent d logarithme parce que typiquement quand on apprend les logarithmes à l'école on a l'impression que ça a toujours existé accepte toujours été comme ça alors que la notion de logarithmes a émis beaucoup de temps à être inventées notamment son nom résonne d'un point de vue arithmétique on va vous dire des définitions du mot logarithme qui sont pas à la définition classique et que l'école et à ce moment il est intéressant de voir comment que bidouiller la définition du mot logarithme pour prendre l'avis des finitions qui convient le mieux de les servir et c'est ce qui explique le très bien écrits directs dans cette compression priant quoi l'enseignement du fait qu'on a le droit de bidouiller été finition des mots mathématiques et quelque chose en fait extrêmement important d'un point de vue pédagogique qu'elle joue et ans la prochaine fois on va parler d'un autre concept important de l'informatique théorique qui est l'apprentissage probablement approximativement correct ou apprentissage pack tricorps qui est un petit peu le cadre d'un petit sage qui a un peu gagné les crédences des ferchaux informatique urique vous payer beaucoup de gens qui allaient me raisonner par rapport au concept d'apprentissage vous avez aimez cette vidéo pensez à laquelle a commenté à la partager pensez à vous abonner pour une économie culture épisodes de mercy est hyper important et j'espère que vous serez là la prochaine fois je rallie mais ça serait quand même beaucoup plus super six le hyaric de la fois baisse était toujours le rythme de la course le logarithme de bay est émise et oui mais en fait c'est pas le diable l'idée que la première des lois et plus harmonieuse de la deuxième était déjà pas quelque chose d'évident des guides entoure et donc ça c'est ça c'est quelque chose peut-être un peu peut-être les gens qui jamais ne verront que c'est plus beau c'est plus lisse c'est plus d'avoir la somme de logarithmes le gall du produit qu'il a sablé le gars est plutôt que d'avoir à -1 le boulet que jamais au pied quand j'étais avec les maths en jean c'est qu'ils avaient quelques élèves de terminale qui avait déjà vu le vrai logarithme et qui était complètement perturbé par l'idée qu' un faux logarithme la deuxième le gars il est alors quand même après qu'ils avaient accepté de jouer le jeu et de se dire ben voilà il ya ce logo rythme bizarre avec le moins d'un là le moment on leur a dit maintenant il faudrait revenir qu'il faudra essayer d'inventer mieux alors là il était complètement perdu 7 donc c'est une des difficultés c'est que c'est plus facile de parler bagarre il ya des gens dont jamais entendu parler de bright cas des gens qui se croient savons pas ce qu'ils connaissent le logar et or à l équilibre du mal à jouer devant des règles un peu google via une clé space age of touch of class i find it is only one