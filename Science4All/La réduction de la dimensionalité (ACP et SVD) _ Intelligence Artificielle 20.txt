la dernière fois on a parlé des espaces de très grandes dimensions et on a vu que ces espaces étaient hyper bizarre et en pratique ça fait que le machine learning a de bonnes chances d'échouer quand il s'agit d'analyser des données de très grandes dimensions comme du texte du son ou des images on parle de la malédiction de la dimensionnalité pour lutter contre la malédiction de la dimensionnalité il est utile de chercher à résumer la complexité des données brutes en une représentation de moindre dimension on parle de réduction de la dimension une alitée ou encore même s'il ya pas vraiment un consensus là dessus d'apprentissage de la sémantique la sémantique en ce sens c'est un vecteur de petites dimensions qui résume bien l'information contenue dans une donnée brute dont la dimension est très grande à prendre la sémantique des données brutes ça correspond donc à transformer tout vecteur de grande dimension en un vecteur de dimensions plus petites et on verra dans le prochain épisode qui étrangement la sémantique apprise par des intelligences artificielles n'est pas si distincte du sens intuitif qu'on attribue habituellement à la sémantique et oui ça veut aussi dire que via le machine learning on est en train de donner un sens à la sémantique c'est énorme inception aujourd'hui on va parler de deux approches classiques de cet apprentissage des scènes antiques appelé analyse par composante principale ou à cp ainsi que cindy leur value des compositions ou svd alors attention une fois de plus notamment pour ceux qui n'ont jamais fait d'algèbre linéaire ça va piquer un petit peu et vous n'allez sans doute pas tout comprendre mais je pense qu'il ya moyen de retenir les grandes idées et puis c'est peut-être là un moyen de trouver la motivation pour vous attaquer à l'algèbre linéaire bref commençons par la cp imaginons donc un espace de figure de grande dimension et plein de points dans cet espace l'aspect consiste à identifier les bonnes façons de tourner cet espace pour y voir les principales variations du nuage points voilà qui permet d'ignorer direction selon lesquelles les variations sont en fait négligeable plus concrètement imaginons que nuages de points à la forme d'une assiette alors il sera en fait essentiellement un espace de dimension 2 quand bien même il vit dans un espace de dimension 3 la cp va alors identifié cet espace est projeté tous les poids du nuage sur le plan du disque dès lors quand on représente la projection du nuage de points dans le plan du disque on voit les principales variations du nuage de points en particulier nommé ainsi celles qui sont négligeables alors bien sûr là je donne le cas d'une projet on d'un nuage de points de dimension 3 sur un plan de dimension deux parce que c'est plus facile à visualiser mais les utilisations dacp qui sont vraiment incontournable c'est davantage quand l'espace des features et de dimensions 1 millions et qu'on projette sur un hyper plan de dimension beaucoup plus petit disons 100 ou plus généralement ça permet de passer d'un espace de dimension t à un espace de dimension c'est beaucoup plus petit et l'astuce est alors en gros la même elle consiste à identifier les directions de plus grandes variations du nuage de points les composantes principales et ensuite effectuer une projection orthogonale sur l'hyper plan engendrés par ces composantes principales pour ceux qui veulent plus de détails techniques sachez qu'il s'agit d'une projection sur la base orthonormé des vecteurs propre de la matrice de covariance qui a le bon goût d'être symétrique et je vous renvoie vers une vidéo de we need a pour plus de détails en particulier d'un point de vue âgés briques effectuer une prédiction orthogonale revient à garder en mémoire seulement les ses composantes principales parmi toutes les directions des voix là on vient de réussir à résumer toute la complexité d'un nuage de points pour apprendre une représentation sémantique des données et de façon cruciale cette représentation sémantique n'est que deux dimensions c'est ça ce qu'on appelle la réduction de la dimensionnalité et ça permet d'éviter la malédiction de la dimensionnalité ainsi que le fléau de la surinterprétation dont on a déjà longuement parlé dans les vidéos précédentes dès lors ce lord astuce il consiste à tourner les données albi lui et de sorte à avoir des composantes principales et des composantes négligeable qu'on va ensuite est négligée c'est quelque chose que l'on retrouve dans beaucoup de problèmes notamment dans la compression de données que sont les formats jpeg mp3 ou autres h 264 c'est pour la vidéo et je vous renvoie notamment vers l'excellence vidéo des logiques qui parle des séries de fourier pour en savoir plus aujourd'hui la cp est devenu un outil incontournable utilisé partout dans l'industrie pour analyser mais aussi pour représenter visuellement les données oui parce que c'est plus facile de représenter sur 1 pol pot est une représentation graphique des données de dimension 2 que des données brutes et de dimensions 1 million en particulier la cp permet ainsi d'identifier les caractéristiques distinctives d'un jeu de données alors il y aurait quelques bémols à mettre à la cp notamment le fait que la cp n'a de sens que si les dimensions sont comparables en termes d'unités il faut en particulier éviter de comparer des pommes et des bananes ou encore les nombres d'années d'existence d'une chaîne youtube et leur nombre de vues bref si je résume la cpc prendre un nuage de points dans un espace de grande dimension d et le projeter dans un seul espace de plus petites dimensions c'est dans lequel on verra néanmoins très bien les variations entre les ponts du nuage de points peut maintenant passer à sbds vd où cindy leur value 10 composition fut l'un des algorithmes clé pour remporter le prix netflix dont on apparaître dans l'épisode 17 le problème en question était le suivant on a tout plein d'utilisateurs et tout plein de films et certains films ont été notés par certains utilisateurs par exemple monsieur fille a adoré black mirror ljg à apprécier cube et eurêka regarde religieusement de big short tous les soirs avant de se coucher le problème du prix netflix consiste alors à masquer certaines de ses notes et à deviner les notes masqué à partir de celles qui ont été révélées pour résoudre ce problème l'astuce de sgd consiste à imaginer que chaque utilisateur est une nouvelle direction dans un espace de grande dimension du coup si on a un million d'utilisateurs l'espace des utilisateurs sera de dimension un million dès lors chaque film pourra être localisés dans cet espace en considérant que la note qu'un utilisateur accorde un film elle a coordonné du film dans l'espace des utilisateurs en traitant tous les films de la sorte on obtient un nuage de points représentant les films dans l'espace des utilisateurs svd consiste alors à appliquer la cp à ce nuage de points autrement dit svd va chercher la bonne façon de regarder l'ensemble des films dans l'espace des utilisateurs de sorte à détecter les principales variations d'appréciation des films par les utilisateurs une remarque que l'on peut faire c'est que la direction selon laquelle le nuage de points des films varie particulièrement beaucoup correspond à des variations importantes des types d'utilisateurs et cette variation des types d'utilisateurs correspond d'ailleurs aussi à une variation des types de films en particulier cette direction de plus grandes variations n'est pas complètement déconnecté de ce que l'on pourrait penser intuitivement typiquement ça pourrait correspondre à la violence des films et à l'appréciation de la violence par les utilisateurs l'intensité des variations de l'appréciation de la violence par les différents utilisateurs est alors appelée valeur singulière de là violence on peut ensuite identifier d'autres directions orthogonale de grandes variations d'appréciation des films qui pourra correspondre à d'autres notions intuitives comme par exemple à ce que le film est un film romantique un film de super héros ou une comédie svd va ensuite chercher à caractériser un nombre restreint ses deux composantes principales du nuage de points de films dans l'espace des utilisateurs en ignorant ainsi les autres directions selon lesquelles les variations d'appréciation des films sont faibles ce qui revient géométriquement à projeter les films dans un seul espace de composantes principales des films on obtient alors une importante réduction de la dimensionnalité ce sous espace de projection c'est ce qu'on pourrait être appelée l'espace et sémantique film utilisateurs et alors que la dimension de l'espace des utilisateurs est typiquement deux dimensions un million c'est à dire le nombre d'utilisateurs l'espace des sémantique lui pourraient être des dimensions beaucoup plus faible disons c'est égal sens et ça c'est super cool parce que ça permet de combattre le problème de lover fitting alors je parle bien des espaces de sémantique film utilisateurs parce que non seulement tout filmer quelque part dans cet espace de sémantique mais c'est aussi le cas de tout utilisateur en effet souvenez vous l'espace des sémantique est un sou espace de l'espace des utilisateurs et chaque utilisateur est une direction de cet espace des utilisateurs en projetant orthogonale mans le vecteur unitaire qui représente un utilisateur temps le sou espace d sémantique on obtient une représentation sémantique de l'utilisateur dans l'espace filmé utilisateurs ainsi chaque film mais aussi chaque utilisateur est quelque part dans l'espace de sémantique et la note d'un utilisateur pour un film données sera égal au produit scalaires entre le vecteur qui représente l'utilisateur est le vecteur qui représente le film mais surtout cela pour effectuer des prédictions pour les notes que recevra un nouveau film disons le film est ta gueule letters en effet le fait d'avoir identifié un espace de ces antiques de dimensions sans seulement fait que seulement 100 données sont nécessaires pour localiser le film en question dans l'espace et sémantique en particulier c'est un utilisateur 10 on les attribue une note de 3 étoiles au film et aegon letters alors on saura que dans l'espace des sémantique ou léa est représenté par un vecteur le film nine network correspond un déplacement de trois unités selon la direction les a il sera donc quelque part orthogonale à trois unités selon l'air vous pouvez alors imaginez que plus on dispose de notes de films plus on pourra préciser les positions possibles du film dans l'espace des sémantique et quand on aura autant de notes que la dimension de l'espace des sémantique on sera où exactement se trouvent être à gauche l'intérieur dans l'espace de sémantique film utilisateurs une fois ce film localiser on pourra ensuite prédire la note qu'un autre utilisateur va probablement attribué au film tout simplement en prenant le produit scalaires entre le vecteur du film est le vecteur de l'utilisateur pour tous ceux qui ne sont pas super à l'aise avec ces notions de points de vecteurs et de produits scolaires je vous renvoie vers les vidéos - dida il espère que vous êtes motivés pour les voir bref grâce à svd on a réussi à construire un espace de sémantique film utilisateurs et à exploiter cet espace pour effectuer des prédictions et le plus fou c'est que ça marche ces manipulations des espaces de grandes dimensions sont au fondement de l'un des meilleurs algorithmes de machine learning d'aujourd'hui à tel point qu'ils ont contribué à résoudre le challenge netflix et qui font désormais sans doute partie des algorithmes que nous utilisons quotidiennement sur netflix sur youtube avant de revenir à vos commentaires de la vidéo présente une petite annonce je serai à vulgarisateur le samedi prochain le samedi 28 avril et je serai en très bonne compagnie puisque il y aura aussi blake tabasse eureka ma nombril et lanternes cosmique et en particulier moi ce dont je vous parlerai c'est d'un truc un petit peu malaisien parce que vous parlerait d'un mouton noir d'un cygne noir et d'un corbeau noir mais parfois on a parlé de l'espace de très grande dimension avec ali j ai radio nous demande si l'intuition géométrique est vraiment utile à développer dans ce genre de cas finalement très vite perdu en pratique quand on fait des calculs par rapport à tout ça en un an la tendance à ramener très rapidement tout ça à des manipulations purement algébrique avoir des équations et des manipulations de nombre alors très clairement si vous voulez vraiment être à l'aise avec tout ça au bon moment faudra passer par ces manipulations algébrique parce que c'est avec ça qu'on touche vraiment la rigueur de ces espaces de très grandes dimensions et qu'on est vraiment capable de savoir si ce que j'ai dit dans la vidéo présente par exemple est vrai ou pas mais je pense néanmoins qu'il est extrêmement utile du que personnellement il m'a été extrêmement utiles même au niveau de la recherche de chercher à constamment avoir une intuition géométriques autant que possible de ses espaces de très grandes dimensions de ces différents objets de très grande dimension typiquement un truc important sur lequel j'ai pas vraiment cité dans vidéos précédentes parce que c'est pas forcément un truc vraiment mais c'est un truc pour moi qu'il faut retenir c'est qu'en fait un hypercube une hypercube de très grande dimension c'est quelque chose de très grands notamment la grande diagonale de hypercube a une taille qui est égale racine carrée 2d et du coup toutes les dimensions typique à l'intérieur du cube sont de l'ordre de racine carrée de deuil c'est pour ça qu'un hyper cubes de côté 1 en fait très très grand on dimensions 1 milliard en fait ça correspond à un objet dont à distance typique entre deux points est de l'ordre de racine carrée de 1 milliard c'est ce genre d'intuition qui est quand même l je pense en fait extrêmement utile à voir dans les espaces de grandes dimensions et un autre truc que je trouve très important c'est qu'il ya certaines intuitions qu'on a pour les espaces de petite dimension parce qu'on est habitués et en a certaines qui se généralise pas du tout du coup c'est important de les oublier quand on passe au camp dimension mais on a d'autres qui se généralise à ses biens notamment pendant que le théorème de pythagore qui en fait est un théorème j'en ai parlé dans une vidéo - didot et ça se trouve très facilement présence de très grandes dimensions et mais c'est aussi très pertinent par exemple pour parler de la cpu ou dvd puisque la notion d' orthogonale it et en particulier est fondamentale et de projections orthogonale est fondamental pour tous tous ces raisonnements et ce qui est assez fou c'est que cette intuition géométriques que l'on a peut permettre de raisonner plus vite d'aller plus rapidement dans certains raisonnements et d'avoir une intuition assez rapide sur la bonne manière de procéder pour résoudre un problème est ensuite faut quand même formaliser sa essayer de se ramener à l'algèbre à chaque fois pour pouvoir effectivement résoudre le problème mais par opposition si on commence directement avec l'âge est vrai qu'on essaie de manipuler purement notation et givry pour en arriver à un résultat bah finalement c'est souvent assez difficile d'en arriver au but puisque on n'a pas une vision d'ensemble c'est un peu difficile d'anticiper verrou ça va aller c'est pour ça que je pense que l'intuition géométrique est en fête importante à développer pour raisonner sur ces espaces de très grandes dimensions n'a été une drague nous devons du coup comment est-ce qu'on peut visualiser c est pire qu et ses espaces et hyper ce faire ces objets de très grande dimension mais à la fin c'est que c'est pas facile c'est tout d'abord on va pas avoir une vision purement complète de ces objets je pense que la bonne façon de penser le truc c'est qu'on va essayer de voir certains bouts on va avoir une intuition de certains morceaux de ces différentes structures géométriques de très grande dimension on ne voit pas les voir dans leur entièreté mais c'est d'ailleurs le cas également quand on pense à des objets de dimension 3 si vous y réfléchissez il ya plein de structures 10 mois sont trois qui sont en fait affreusement complexe et qui nous est impossible de penser dans leur globalité et puis même en dimensions de deuil à dire des trucs à faire et c'est troublant et on a tendance à voir juste certains morceaux et puis a essayé de recoller un petit peu les morceaux je pense que c'est un petit peu comme ça qu'il faut qu'on sait les espaces de très grands dimensionnement et les objets de ces espaces de très grande dimension voilà on essaie de comprendre certains morceaux et puis voir une compréhension partielle de différents partis de ces objets extrêmement complexe bon mais clairement on peut pas espérer les visualiser dans leur entièreté en particulier à sur ip refaire il y à des vidéos d'alain bernard que je vous recommande vivement donc aller les voir ça permet de se faire une petite idée de ces espaces de dimensions 4 je suis pas si parmi dimension 5 après ça reste à la dimension 4 ou 5 pour les espaces de dimension un million c'est encore quelque chose de très très différents que l'on compte par des espaces de grandes dimensions vacances et 4 ou 5 mais les objets d'étude d'une machine learning c'est des objets de dimensions 1 millions voire en milliards et c'est souvent des trucs encore un peu plus bizarres sur lequel on va voir des intuitions encore beaucoup plus partielle mais même les intuitions partiel sont souvent extrêmement utile enfin qui regarde me demande si avec d'autres normes ne peut pas avoir des trucs plus intuitif alors pour comprendre cette question déchire il faut comprendre un peu la notion de norme qui avait un petit peu mentionné dans l'épisode 18 de façon purement algébrique la norme en fait c'est pour mesurer la taille en fait un vecteur qui a des coordonnées à la manière de tout mesure la taille de cet objet une façon de faire donc a énormément ce qu'il y de faire dans ce cas c'est de prendre la somme des valeurs absolues des coordonnées effectivement un grand vecteur c'est qu'un vecteur qui va voir des coordonnées très grande du coup c'est une bonne façon de mesurer la taille du vecteur la norme 2 c'est ce qu'on appelle la norme euclidienne aussi parce qu'elle est conforme avec l'inventeur de pythagore c'est celle qu'on a utilisées en fait pour parler des perceurs je parlais de distance en fait c'est intuitif mans cette notion de pain c'est la notion de norme 2 c'est à dire que la norme 2 d'un vecteur des dimensions 2d ça va être la racine carrée du de la somme des carrés de ses coordonnées ensuite on peut peut-être parlé d'un énorme infinie énorme infinie c'est la norme qui mesure à plus grande des coordonnées en valeur absolue c'est le maximum des valeurs absolues des coordonnées et puis à d'autres normes notamment les normes paix pour payer en toi et l'infini ah oui aussi la norme zéro dont j'ai parlé dans l'épisode 18 mai à norme zéro en fait c'est pas une norme au sens où elles mesurent pas vraiment spagnou peut elle pas toutes les bonnes propriétés qu'on aimerait que les normes est du coup on parle parfois de semis norme n'est ce pas vraiment énorme on peut l'oublier pour aujourd'hui en tout cas bref tous ces objets sont des façons de mesurer les tailles d'une flèche toutes les tailles d'un vecteur et on peut aussi mesurer la distance entre deux points de l'espace regardant la norme du vecteur qui lie de la flèche qui va d'un point à l'autre ici on choisit chacune de ces définitions on obtient du coup une définition différente de la distance et du coup d hyper sphères différentes en gros du père se faire et ne soit ni perceur dépend de la norme que vous considère dans vidéos précédentes j'ai prié du coup il perd son père qui correspondait à la norme 2 est en fait ce qui se passe c'est que si on prend l'hyper serre qui correspond à la norme 1 on obtient un espèce de hyper oct à l ess est hyper aux cadres en fait il va être plus petit que l'hyper sphère de norme 2 mais alors si vous ne trompe pas lâcher en train d'utiliser mon intuition géométriques l'ajustement si je me trompe pas il va pas être énormément plus petit que l'hyper serre qu'ils y perdent particulier l'intérieur va pas être avare rhume qui va être énormément plus petit que l'hyper boulot ce cas la comparaison sera pas comparable à celle entre l'hyper bull et hypercube l'hyper suaire de la norme infinie ça va être hyper kummer en l'occurrence donc hyper se faire pour un énorme infinie est quelque chose qui a un grand volume oui parce que dans la vidéo présente si j'ai parlé de volume et à la notion de volume et pas aliénation des normes jusqu'aux la notion de volume on peut la ramener ça son essai de découper les pièces est-ce qu'on peut les faire rentrer dans une autre et je vous renvoie vers une vidéo d'hadji pour en savoir plus pour le cas de la dimension 2 et 3 donc voilà en fonction de la norme que choisissez vous obtenez une des finales différentes pour l'hyper bull après la norme 2 est assez naturel et pour une autre raison c'est que en fait elle correspond à des symétries 2 nos rotations j'ai pas mal parlé notamment c'est l'épisode sur la cps vd le fait de tourner l'espace en fait le fait de tourner l'espèce ça se définit mathématiquement par fait d'avoir sont pas des matrices orthogonale qui sont capables de tourner espace une certaine symétrie en fait qui corresponde à ses ces mouvements de rotation en hausse ans est en gros quand on tourne l'espace comme ça les notions de nos mains et de normes infinie vont complètement changer c'est à dire que si je prends un vecteur et que je le tourne alors sa norme va changer ce qui peut paraître assez bizarre la norme qui est cohérente avec cette histoire de rotation c'est en fait la norme de la norme euclidienne pour ça que c'est un peu la norme naturelle pour en tout cas parler de pas mal de structures de géométrique de de toutes dimensions c'était une énorme digressions tout ça pour vous dire que ces espaces de caen dimension c'est rentrer pour la classe et pour les apprendre il faut faire de ce qu'on appelle de la gr en lumière et j'ai une série de vidéos sur un dida qui partagent line up vous invite si vous êtes motivés s'ils voulaient vraiment apprendre les maths et pas juste être exposé à la vulgarisation comme sur scène ce soir je vous invite à essayer de suivre cette série sur bandido et j'espère que vous avez aimé cet épisode et qu'il avait à peu près réussi à suivre si vous voulez en savoir plus allez vraiment voir l'algérie linéaire comment les vidéos que j'ai fait sur wii c'est un petit peu difficile en forcément c'est des matchs de niveau supérieur typiquement il faut une au niveau - bac + 1 à bac + 2 pour vraiment être à l'aise avec ces notions ou en tout cas le détail de ces notions je pense que l'idée vraiment fascinante est fondamental c'est surtout l'idée qui est cette espèce de sémantique que l'on peut construire et dans lequel en fait on voit très bien les liens entre utilisateurs et films et surtout on peut utiliser cet espace pour effectuer des prédictions et c'est quelque chose dont on parlera plus au moins est ce que ça va être un petit peu le thème d'une ces mini série de trois vidéos notamment la semaine prochaine on va parler de la représentation vectorielle des mots comment est-ce qu'on peut créer un espace de sémantique pour représenter le sens des mots c'est un truc à la fois très récent et très fascinant si vous avez aimé cet épisode pensait le lac et à le commenter à le partager pensez à vous abonner pour planquer futur d'épisodes merci aux tipper cordon et j'espère que vous serez là la prochaine fois or trouver la bonne façon d'orienter lé espace vectoriel pour bien séparer les points ça revient en gros à tourner l'espace pour l'aligner selon des directions des plus intéressants et ses directions et plus intéressante ce sont en fait les vecteurs propre de la matrice dit de covariance c'est à dire la matrice qui étudie comment les points sa ligne varie les uns par rapport aux autres