nous vivons une période exceptionnelle de pandémie covit 19 une maladie virale extrêmement contagieuse qui a déjà fait des dizaines de milliers de morts à l'heure actuelle il semble qu'il faille encore envisager le risque que qu'ovide 19 face des millions de nord d'ici la fin de l'année dans ce contexte il semble urgent d'accélérer les recherches cliniques pour trouver les traitements efficaces contre qu'ovide 19 sauf que pour vraiment tester ces traitements il va falloir les administré à des patients atteints de colite 10,9 alors même qu'on sera encore dans l'incertitude sur l'efficacité de ces traitements il ya en fait même un vrai risque que le traitement en question soit en fait néfaste et que la recherche de traitements efficaces qu en fait des dégradations des conditions des patients en fait pour chaque patients actuellement atteints de colite 19 ans plus de l'horrible dilemme éthique d'accepter vous refusez sa prise en charge faute de ressources humaines et matérielles il y à un dilemme éthique additionnel auquel on est confronté à savoir faut-il faire de notre mieux pour le bien de chaque patient en l'état de nos connaissances ou faut-il prendre le risque d' expérimenter des nouveaux traitements dont l'efficacité est encore très incertaine dans l'espoir que si ces traitements fonctionnent on puisse ainsi le découvrir et l'utiliser pour sauver une fraction importante des patients futur faut-il prendre le risque de mettre en danger était centaines ou des milliers de patients actuels ou du moins de ne pas leur administrer le meilleur traitement connu à ce jour pour le bien de millions de patients futur ce dilemme éthique c'est un dilemme bien connue des informaticiens des mathématiciens on l'appelle le dilemme exploration et exploitation intuitivement quand on est encore très ignorants il est important de tenter des choses et de prendre des risques pour en apprendre davantage puis une fois qu'on en sait davantage on peut exploiter nos connaissances par exemple pour sauver des vies alors dit comme ça ça peut paraître simple mais la mise en pratique de ce principe simple est un sacré des filles comment peut-on savoir si à un moment donné il faut davantage explorer et tenter de nouveaux traitements quitte à mettre en danger des vies et ne pas offrir le meilleur traitement identifié jusque là à partir de quand peut-on se dire qu'on en sait suffisamment pour arrêter l'expérimentation et se contenter de ce conseil de mieux jusque là habituellement pour les traitements médicaux on procède d'abord avec une phase d'exploration celle ci consiste en une série d'essais cliniques qui sont divisés en phase pré clinique phase 1 pour vérifier l'absence d'effets secondaires indésirables phase ii pour ajuster les doses à prescrire et estimer l'efficacité du traitement et phase iii pour affiner cette estimation et la comparer à l'efficacité de traitement alternatif et du placebo puis on a une phase de déploiement ou le médicament est autorisé à la vente est prescrit par les médecins c'est ce qu'on appelle la phase 4 c'est la phase d'exploitation des connaissances acquises pendant les essais cliniques notez que cette procédure est aussi la plus commune en machine learning jusque là où les algorithmes sont d'abord conçus peaufiner entraîné et tester avant d'être ensuite déployée cependant est ce vraiment là la meilleure façon de procéder et surtout comment optimiser au mieux la transition entre exploration et exploitation quel calcul pourra être effectuée pour mieux comprendre le moment optimal pour effectuer cette transition alors bien sûr en pratique il y a énormément plus de considération extrêmement difficile à prendre en compte comme le bien-être des patients leur consentement à prendre un risque pour avancer notre connaissance et plein d'autres aspects que je ne maîtrise absolument pas bien conduire des tests cliniques c'est compliqué néanmoins en cours des dernières décennies en s'appuyant notamment sur vent sur le belize à nice mme un très grand nombre d'études ont proposé de nombreuses astuces pour accélérer les essais cliniques on parle typiquement de tests contrôle et adaptatif par opposition aux tests contrôlé randomisé dont on a parlé dans l'épisode 8 c'est est contrôlé adaptatif ou de bien meilleures propriétés mathématiques qui suggèrent qu'il pourrait permettre d'arriver plus rapidement à des conclusions plus robuste sur l'efficacité de différents traitements avec même déjà de nombreuses mises en pratique et des résultats encourageants en tout cas ça semble avoir convaincu la food and drug administration aux états unis la f10 est qui s'est mise à encourager la recherche et la mise en pratique de ces tests contrôle et adaptatif malheureusement ces tests semblent encore peu appliqués en pratique mais il ya une bonne raison à cela cette étude en particulier rapportent des mises en pratique bancale des tests contrôler adha natif ces tests étant un peu plus complexe il est important de prendre soin qu'on les applique dans des cas d'applications adaptées et avec une rigueur adéquat ce qui va m'intéresser en particulier aujourd'hui c'est de vous présenter les motivations des tests control adaptatif les aspects critiques de ces approches et l'ordre de grandeur du nombre de vies qui pourraient ainsi être sauvées en s'appuyant dessus et pour cela je vais m'appuyer sur le modèle le plus simple des tests contrôle et adaptatif appelé modèle du bandit à plusieurs bras ou multi arts de bain dit en anglais le nom vient des casinos mais nous nous étalons pas sur les détails parlons du modèle imaginé qu'à chaque instant un nouveau patient arrive et vous avez plusieurs traitements à votre disposition disons que vous pouvez lui administrer des pilules bleues rouges vertes magenta ou jaune parmi ces traitements il y a généralement un placebo même si techniquement on pourrait vouloir juste comparer différentes pilules dont on sait déjà qu'elles sont toutes plus efficace qu'un placebo en pratique dans le cas de co vide 19 l'organisation mondiale de la santé a lancé un plan d'essais cliniques de solidarité appelé solidarity triumph qui consiste à tester quatre traitements à base de mélange adéquat de rennes dvir de lopinavir de ritonavir d'interféron bêta et de chloroquine est à comparer les performances de ces traitements au traitement standard actuel c'est donc finalement un peu comme si on disposait effectivement de cinq pilules différentes dont les performances curative sont encore très méconnu on est donc là dans un cas pratique qui ressemble finalement pas mal ok à théorique que je suis en train de présenter quoi qu'il en soit la grosse difficulté c'est que a priori vous ne connaissez pas les efficacité de ces différentes pilule autrement dit vous ne connaissez pas la probabilité qu'un patients survivent si vous lui donnez telle ou telle pilule pour mieux soigner les patients futur il nous faut mieux estimer les probabilités de survie suite aux différents traitements et pour cela il nous faut faire de l'exploration alors pour aujourd'hui je vais me concentrer en particulier sur les essais cliniques en phase iii et en particulier ça correspond à faire de l'exploration en phase iii des essais cliniques l' approche actuelle la plus standards des essais cliniques 3 en gros c'est d'administrer aléatoirement l'une des cinq pilules à tout nouveau patient pendant une longue phase d'exploration et au bout d'un moment on fait le bilan et on estime les probabilités paix bleus pérouges pévère paix magenta et paix jaune en fonction de la fréquence de survie des patients jusque là puis on passe en mode exploitation on administre à tous les passions futur la pilule avec la meilleure fréquence de survie empirique jusque là bien sûr ce que je décris là c'est une simplification extrême de la manière dont fonctionne effectivement les essais cliniques en pratique encore une fois c'est bien plus compliqué que cela il ya notamment toute sorte de procédure pour prendre en charge des patients traités qui présenteraient des effets secondaires inquiétants suit un traitement nouveau et a également un suivi de toutes sortes de metric autre que la survie des patients ceci dit ça reste grosso modo vu de loin au moins la logique globale qui est suivi par la plupart des tests cliniques quoi qu'il en soit maintenant qu'on a formalisé le problème on peut se demander si cette stratégie est une bonne stratégie en particulier est ce une stratégie qui maximise le nombre de vies sauvées imaginons que la meilleure pilule et la pilule bleue le problème c'est qu'à cause des fluctuations statistiques il ya une probabilité non nul que pendant la phase d'exploration la pilule rouge correspondent à une meilleure fréquence empirique de survie des patients que la pilule bleue mais alors pendant tout le reste du temps n'administre à une pilule sous-optimale et ça ça peut être en fait catastrophique en effet imaginons que la pilule rouge paraît prometteuse et que tout le monde se jette dessus imaginons que les états imposent de son administration à tout patient malade du coc vie de 19 et que très vite trop vite tout le monde se met à croire que la pilule rouge elle le traitement miracle mais imaginons qu'en fait la pilule bleue est légèrement meilleure imaginons que sur 100 patients en état critique la pilule bleue sauve une vie de plus en moyenne que la pilule rouge le fait d'avoir conclu trop vite à l'efficacité de la pilule rouge serait alors catastrophique sur 10 millions de patients en état critique cent mille patients vont alors mourir alors qu'ils auraient été sauvées si la pilule le avait été adopté le fait d'avoir échoué à détecter une très légère supériorité de la pilule bleue sur la pilule rouge aurait ainsi causer cent mille morts additionnel mais alors comment éviter cela quelle doit être la taille de l'échantillon testé pour maximiser le nombre de vies sauvées sur combien de patients doit-on alors se permettre d'effectuer des expérimentations comment déterminer le moment où l'on peut passer à l'exploitation bien dans notre modèle mathématique on peut fournir une réponse à ces questions pour maximiser le nombre de vies sauvées ou plutôt l'espérance du nombre de vies sauvées car il faut raisonner avec l'incertitude le nombre de patients sur lesquels on effectue les tests doit être de l'ordre de 2 fois le log de grands à une fois delta carré diviser par deux le tout divisé par delta carré ou quand est né le nombre total de patients à traiter passé présent et futur et delta est la différence d'efficacité entre le meilleur traitement est le second meilleur traitement dans l'exemple que j'ai donné on avait une différence d'environ 1 mort tous les sens qu'à ce qui correspond à delta à peu près égale à 0 01 imaginons maintenant que à cause de covit 19 10 millions de patients seront un état critique pour minimiser l'espérance du nombre de vies sauvées le nombre de tests doit être de l'ordre de 120 milles dans toute honnêteté quand j'ai fait les calculs j'ai été très surpris par ce résultat qui est bien plus grand que ce à quoi je m'attendais en particulier de façon préoccupante ce nombre est bien supérieur à celui des essais cliniques en phase iii usuels ou des milliers de sujets sont habituellement tester d'où l'urgence à prendre le temps de bien réfléchir et de choisir adéquatement la taille des échantillons des essais cliniques prendre des échantillons trop petit et conclure trop tôt c'est indirectement potentiellement sacrifier des centaines de milliers de vies bien sûr en pratique encore une fois n'est pas uniquement question de sauver des vies le bien-être des patients peut et doit aussi être prise en compte dans l'analyse mais au moins les ordres de grandeur est similaire bien mesurer des petites variations de l'effet d'un changement de traitement et critique lorsque le traitement est déployé à très grande échelle mais mesurée robustement ces petites variations nécessite des tests sur un très très grand nombre de patients donc non il ne s'agit pas de se précipiter de court circuiter un minimum de rigueur statistiques et de conclure après avoir effectué des tests sur 100 patients seulement d'autant que en pratique il y à une multitude d'autres facteurs à prendre en compte comme les particularités physiologiques des différents patients l'évolution de leur pathologie au cours du temps et l'incertitude sur le nombre total de cas qu'il pourrait y avoir et prendre en compte tout cela ça nécessite encore plus de rigueur et de réflexion pire encore d'un point de vue statistique en pratique il n'ya pas que cela il se pose aussi la question de la fiabilité des données en particulier pour que l'analyse que l'on vient de faire soit valide il faut que pendant la phase de traitement le choix du traitement aux patients soient choisis de manière randomisée sont ceux là on est vouée à subir toutes sortes de facteurs de confusion et de tomber dans l'horrible piège du paradoxe de simpson si vous ne savez pas de quoi je parle mettez pose est allé voir cette vidéo où cette vidéo je suis sérieux si vous voulez être capable de faire des bonnes analyses de données il faut absolument que vous connaissiez ce paradoxe sur le bout des doigts car sinon vous êtes vous et à faire énormément d'erreurs dans vos analyses de données que ces années y soit faite sur vos ordinateurs ou dans votre cerveau alors il ya une limite toutefois au raisonnement convient de faire ou on a supposé que la différence d'efficacité entre le meilleur traitement est le second meilleur traitement et est de 0,01 en pratique on ne connaît pas à ce nombre ce qui nous empêche de déterminer la taille adéquate de la population sur laquelle on effectue les tests pour résoudre ce problème les mathématiciens ont trouvé une astuce adapter la taille de l'échantillon en fonction de la différence entre les fréquences empirique plus précisément l'idée est ici de poursuivre les tests jusqu'à ce que les différences entre les fréquences empirique de survie pour le meilleur et le second traitement est supérieur à deux fois la racine carrée de lob de grands et / p tit n le tout divisé par petite trentaine encore une fois est le nombre total de patients passé présent futur qu'il faut traiter et petites haines et le nombre de patients qui ont été traités jusque là et sur lequel on a fait en particulier de l'expérimentation ainsi après petit n est égale à dix mille expérimentation si on s'attend à grand peine de l'ordre de 10 millions de cas à traiter alors le seuil deux fois racine carrée de l'ocs deux grands thèmes / br / p tit n elle lui de l'ordre de 0,05 et donc si à ce moment là l'écart empirique entre les deux traitements et de l'ordre de 0,01 alors cette analyse nous encourage à poursuivre les expérimentations en fait pour un tel écart empirique il faudra poursuivre jusqu'à environ 180 milles expérimentation ce qui est cohérent avec l'ordre de grandeur de 120000 qu'on a établi plus tôt mais l avantage c'est que cette fois on pourra décider d'arrêter l'expérimentation des traitements après seulement deux mille patients si on se rend compte que à ce moment là la différence entre le meilleur est le second meilleur traitement est supérieur à 0,13 autrement dit si sur 2000 patients traités de manière randomisée le meilleur traitement sauf 130 vie de plus que le second meilleur traitement alors on pourra stopper l'exploration est passé à l'exploitation de cette information en administrant le meilleur traitement identifié jusque-là au reste de la population voilà qui permettrait ainsi d'accélérer le déploiement d'un traitement très largement supérieure à toute autre traitement connu jusque là et alors oui si vous êtes habitué au protocole classique d'essais cliniques et à la paix valu ce que je viens de dire peut peut être vous choquer profondément je suis en train de vous présenter une façon de tester et de sélectionner des traitements qui autorise l'arrêt prématuré des expériences ce qui invalide l'erreur de type 1 et je n'ai absolument pas fait appel à la notion de preuve d'efficacité ou des effets statistiquement significative bien il se trouve que comme on en a beaucoup parlé dans cette série pour bien raisonner ces notions ne semble pas si fondamental voir pas si utile en tout cas à en croire le bail à nice mme ou encore en croire le consensus des statisticiens dont on a parlé dans l'épisode 13 donc s'il vous plaît je sais que ce n'est pas facile mais s'il vous plaît essayez d'éviter d'utiliser ces expressions très trompeuse et essayer d'adopter un langage beaucoup plus probabiliste après tout la question qui importe peut-être davantage c'est si en l'état actuel de nos connaissances et de nos incertitudes la taille des effets probables du traitement le plus prometteur est suffisamment supérieure à toute autre taille des faits probable de tout autre traitement potentiel de sorte que cette différence justifie une prescription systématique de ce traitement à des centaines de milliers de patients voire à la dizaine de millions de cas critiques à venir en fait pour sauver davantage de vies on peut faire bien mieux encore en tout cas sur le plan théorique au lieu d'avoir une phase d'exploration pur suivie d'une phase d'exploitation pur les mathématiciens ont proposé d'autres approches où il ya une transition continue ou l'exploration diminue progressivement au profit de l'exploitation par exemple certains ont proposé un algorithme appelé ucb pour eux peur confie dance pas honte là encore malheureusement je ne vais pas m'attarder sur la terminologie pourtant intéressante de cet algorithme à chaque instant cet algorithme ucb mélange l'exploration et l'exploitation en choisissant d'administrer le traitement qui maximise une quantité égale un terme d'exploitation + 1 termes d'exploration le terme d'exploitation correspond à l'efficacité empirique du traitement sur les données passées alors que l'exploration intègre l'incertitude sur l'efficacité de ce traitement qui est d'autant plus grande que peu de tests ont été effectués avec ce traitement x un terme qui croît très lentement avec le temps de façon très intéressante l'algorithme ucb al avantage de ne pas nécessiter d'estimation au préalable du nombre de cas grand aisne qu'il faudra traiter nous encore les mathématiciens ou même prouvé que des variantes un poil plus sophistiqué de cet algorithme notamment qu'à elle ucb développer en 2013 sont en fait en un sens optimale il existe même des variantes bayésienne encore plus prometteuse en tout cas à mon sens notamment à base d'échantillonnage de thomson mais je ne vais malheureusement pas avoir le temps de vous en parler et croyez moi je suis premier déçu dans le cas de kevin 19 ce pourrait être des milliers peut-être même des dizaines de milliers de vies qui serait ainsi sauvées si on appliquer qu à l ucb plutôt que l' approche exploration pu leur exploitation pur qu'on a présenté plus tôt mais bien sûr encore une fois sa mise en oeuvre pratique est bien plus complexe notamment d'un point de vue administratif ceci dit de façon très intéressante les outils d'urgence qu'a proposé l'om est notamment dans le cadre du solidari titre ailleurs le temps de pouvoir permettre une implémentation au moins partielle de ces idées qu'à tout ça ce sera sans doute très intéressant à analyser d'un point de vue méthodologique alors bien sûr en pratique tout est plus compliqué que ceux dont on vient de parler tant d'un point de vue mathématique que d'un point de vue clinique ne s'agit absolument pas d'appliquer les algorithmes qu'on a présenté tel quel d'ailleurs les procédures d essais cliniques sont horriblement plus complexe que ce que j'ai présenté dans cette vidéo l'objectif de cette vidéo et de vous présenter les grandes idées suggérées paris mathématiques du dilemme exploitation exploration pour mieux guider les décisions pratiques mais même au sujet de ses mathématiques il ya plein de bémol à mettre en premier lieu les modèles que j'ai présentées manque souvent de base à nice mme en particulier et n'inclut pas l'état actuel des connaissances des virologues des infectiologues et des médecins en incluant adéquatement ses connaissances il devrait être possible d'optimiser encore un peu plus ses algorithmes pour sauver encore plus de vie mais ceci demandera une collaboration étroite entre des mathématiciens et des experts en santé en particulier la probabilité de survie d'un patient donné surtout si on connaît son état physiologique au moment du traitement n'est pas la même que la probabilité pour un autre patient prend en compte ceux ci complexifie beaucoup l'analyse et nécessité des modèles beaucoup plus complexe en second lieu et de façon cruciale toute cette analyse échoue à considérer les effets à long terme des traitements et ça ça vient d'un problème encore plus fondamentale qui est le fait que les effets à long terme ne sont observables que sur le long terme et ça a malheureusement c'est assez incompatible avec l'urgence de la situation actuelle en fait la plus encore il va falloir être bayésiens et intégrer les connaissances biologiques pour estimer les probabilités d'effets à long terme grave pour différents traitements possibles de covile 19 y compris les effets à long terme de l'absence de traitement troisième lieu dans cette vidéo j'ai supposé que l'ensemble des traitements candidats étaient connus mais en pratique c'est bien sûr plus compliqué que cela au fur et à mesure que la recherche progresse de nouveaux traitements surgissent de façon intéressante la proche du cv semble parfaitement adaptés à cela et peut être appliquée informellement après déploiement pourvu qu'on récupère bien les données des patients ainsi traités de façon générale intégrer efficacement des nouvelles propositions de traitement son but problématique intéressante à garder en tête un excès d'investissement sur une solution imparfaite aujourd'hui pour est malencontreusement freiner déçu sion qui pourraient être découvertes dans un futur proche bref il ya plein de défis à relever dans l'urgence pour que qu'ovide 19 soit traitée aussi bien que possible mais l'urgence ne justifie absolument pas de faire n'importe quoi et de précipiter n'importe comment les essais cliniques en s'appuyant sur la rigueur des travaux de longue haleine des statisticiens et des informaticiens en particulier on peut sauver beaucoup plus de vies mais pour cela il faut prendre le temps de bien comprendre expliquer et adapter ses travaux et d'ailleurs sur cela j'aimerais finir avec une situation d'un article de 2011 de civils chevret je cite depuis le début du 21e siècle il y a eu une croissance étonnante de l'intérêt pour les conceptions adaptative d'essais cliniques malgré les avancées méthodologiques les avantages éthique et les alternatives data dépendante aux tests randomisé contrôlé les essais cliniques adaptatif bayésiens n'ont pas été très adopté en pratique à part en début de phase 1 des essais cliniques pour le cancer le besoin évident de collaboration entre statisticiens et cliniciens doit être souligné enfin des efforts de promotion des approches bayésienne auprès des statisticiens et des cliniciens devrait être fait fin de citation dans le contexte actuel cela semble être devenu une urgence j'espère que vous avez aimé cette vidéo merci beaucoup à tous ceux qui ont contribué à l'écriture notamment du script de cette vidéo qui a été particulièrement difficile à écrire notamment parce que nos en temps de crise et du coup c'était super difficile de faire attention à comment formuler différentes 3 je tiens à remercier en particulier emilie kaufmann qui est chercheuse à l'inra à lille si je me trompe pas et qui a donné une conférence à l'institut henri poincaré que je m en lien à la fin de cette vidéo sur laquelle je me suis beaucoup appuyé et par ailleurs j'ai découvert offert mesure après avoir créé le premier jet du script tout le travail qui a été fait par l' oms et l'inserm pour mettre en place ces odeurs et titre wireless et sa version européenne laissée discovery quand j'ai compris tout le dispositif qui avait été mise en place j'ai été vraiment absolument impressionné je sens qu'il ya un travail absolument immense est vraiment fantastique qui a été fait notamment dans tout ce qui va être gestion des données collecte des données auprès des hôpitaux et tout ça c'est vraiment vraiment fantastique d'avoir mis ça en place ont si peu de temps et du coup de permettre des essais cliniques adaptatif qui vous rend plus sans doute joué sur non seulement les quatre molécules dont on a parlé mais possiblement sur d'autres molécules et voir modifier les doses aussi en temps réel vraiment je suis je suis absolument impressionné 20 ans fixation pour ce travail merveilleux fantastique et incroyablement utile à l'heure actuelle j'espère que vous avez aimé cet épisode qui n'avait pas été prévu d'insérer sur bèze mais étant donné l'actualité je pensais que c'était important de parler de ce sujet il y aurait énormément plus de choses à dire et pour cela je recommande entendant tous toutes les sources que j'ai mise en descriptions que vous êtes vraiment motivé vous en quoi le vivement à aller voir le bouquin que j'ai cités dans cet épisode et que je n'ai pu avoir le temps que de survoler mais qui a l'air très très intéressant visiblement c'est un sujet très très chaud comment avec l'actualité je pense que c'est très très important de faire preuve de beaucoup plus de prudence de tous les côtés parce que encore une fois les chiffres suggèrent que il faudrait faire beaucoup beaucoup beaucoup plus l'expérimentation pour en tirer des conclusions sur ce qu'il faudra administrer au plus grand nombre et avant cela je pense que c'est très important de s'habituer à raisonner en termes probabiliste nom particulier sont préparés à devoir changer d'avis le raisonnement se d'incertitude heureusement parisien est devenu plus important que jamais vous avez d'autres idées de sujets que je pourrai aborder qui pourrait aider à sauver beaucoup plus de vies parce que là je pense que les biens vidéo c'est vraiment des questions de au moins de milliers de vies n'hésitez pas à me les proposer à priori j'ai prévu dans deux semaines de revenir sur les vidéos un peu plus classique mais s'il ya bonne idée de sujet je suis prêt à travailler un peu plus encore sur mes heures perdues pour essayer de vous offrir des informations de qualité sur des meilleures manières peu réfléchir surtout plein de sujets qui souillaient avec lise du court aux navires us et sans doute des conséquences économiques assez grave qui vont être conséquente de tout cela tu faisais mais savez vous de penser le lac et à le commenter elle partage et pensez à vous abonner pour deux épisodes merci aux timbers power nom et j'espère que vous serez là la prochaine fois on est en capacité de développer des essais des stratégies des essais cliniques et des stratégies thérapeutiques test des stratégies thérapeutiques dont le but est de pouvoir sélectionner les meilleurs molécules pour les mettre à disposition des patients le plus rapidement possible l'idée c'est que cette c'est cette recherche doit être bien sûr pragmatique parfaitement rationnel et qu'on doit garder la rigueur scientifique qui nous permet de discriminer parmi un nombre un certain nombre de molécules les molécules qui allie la compétence d'être à la fois efficace et d'être bien toléré et donc c'est tout l'objet de ce qu'on appelle la recherche antonio en temps réel actuellement qui est un concept un peu nouveau et effectivement adaptatif qu'est-ce à dire ça veut dire tout simplement que cet essai a la capacité de s'adapter à la situation dans la mesure où pour l'instant nous sommes nous partons avec cinq bras mais au fur et à mesure des résultats que nous allons accumuler c'est toute la force de cet essai on à mobiliser énormément de moyens de façon à ce que nous puissions implémenter les résultats quasiment en temps réel avec un recueil extrêmement exhaustive des données au jour le jour qui ressemble basculer et analysés qui nous permettent de savoir précisément où on en est précisément sur ses études on va prouva on va s'adapter c'est à dire quand une molécule va démontrer une une absence d'efficacité ou trop peu d'efficacité on pourra arrêter ce bras et basculer potentiellement sur d'autres molécules candidates pour faire évoluer et accompagner le protocole vers des molécules candidates qui seraient des molécules d'intérêt ce que j'appelle en aldrin de bandits bayésiens c'est un hâle doré tout qui pour choisir le bras suivant il va prendre déçu de la décision en fonction de l'observation des lois a posteriori le tout premier article scientifique qui parlait plus ou moins de modèles de bandits et ben c'est un article de thomson en 1933 dans le contexte des des essais cliniques et il avait proposé cette algue aurait alors l'algorithme il est très simple pour chaque bras vous allez choix vous allez tirer une réalisation de la loi a posteriori et ensuite vous allez choisir le bras qui vous a donné l'échantillon le plus grand donc ça c'est ce qui est écrit là où donc en quelque sorte ce que vous faites c'est que vous et championne est un modèle possible selon votre a posteriori et puis vous agissez optimalement dans ce modèle