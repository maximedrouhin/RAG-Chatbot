le bally's à nice mais l'induction de solomonoff sont d épistémologie c'est à dire des façons de transformer des données en savoir plus tôt d'une meilleure description possible de notre savoir et de notre ignorance sachons ces données on a vu dans les épisodes précédents et en particulier dans l'épisode 36 que c'est épistémologie avait des propriétés absolument remarquable est essentiellement unique et encore je ne vous ai pas parlé du théorème d'admissibilité du théorème de la classe complète du théorème du livre de contes néerlandais ou du théorème de james cox bref ces propriétés ont amené le génialissime rei solomonoff à conclure que le bail à nice mme ça marche et surtout que au final c'est bien ça qui compte à en croire les épisodes précédents pour savoir il faut il suffit d'appliquer les lois des probabilités et en particulier la formule du savoir ok mais à quoi bon de savoir à quoi ça peut servir de dépenser autant de tant d'attention et d'énergie à mieux comprendre l'étendue de notre connaissance et de notre ignorance quelle est la valeur de ce travail épistémique alors je dois bien dire que à titre personnel j'attribue énormément de valeur en soi à mieux estimer mes connaissances et mon ignorance il ya quelque chose d'incroyablement satisfaisant à mes yeux à me rendre compte des erreurs du lait du passé ou pas pour me moquer de lui mais parce que je sens alors que je progresse épistémique mans et je ressens même quelque chose de jouissif dans le fait de réussir à me méfier des pulsions de mon intuition ou de mon raisonnement motivé et a effectué au lieu de cela un raisonnement aussi proche que possible de celui recommandé par des génies comme david frum père simon laplace la place et rei solomonoff mais même à mes yeux ce n'est pas là la plus grande valeur du raisonnement bayésiens notamment lorsque l'incertitude est grande comme ça a été le cas au hasard au cours de l'année 2020 et comme c'est le cas aujourd'hui raisonner avec les lois des probabilités c'est surtout critique pour prendre de meilleures décisions justement en 2000 il ya donc 20 ans l'informaticien markus ritter a eu la brillante idée de combiner l'induction de solomonoff la théorie de la prise de décisions pour formaliser un algorithme de prise de décisions optimales en présence d' incertitudes l'algorithme ainsi conçu par peter fut nommé à xi pour artificial intelligence cross tweed in d'auxonne depuis cet algorithme est souvent décrit comme la forme ultime d'intelligence pour comprendre haïti il falloir d'abord posé un cadre d'applications qui est le cadre très général de l'apprentissage par renforcement à chaque instant l'algorithme acsi doit prendre une décision en choisissant une action parmi un ensemble fini à d'actions potentielles en pratique pour les algorithmes d'aujourd'hui ceux ci corresponde à un message envoyé que ce soit une recommandation de vidéos la publication d'un texte générés par l'algorithme ou un signal qui dit de tourner le volant d'une voiture après avoir entrepris l'action en question l'algorithme maxi reçoit ensuite des données observationnelles que lui permettront d'affiner sa compréhension du monde comme dans le cadre de solomonoff on va supposer que ces données sont numérisés ainsi à chaque instant d'observation appartient à un ensemble fini au d'observation possible à cet instant qui va correspondre typiquement un ensemble de données que peut recevoir l'algorithme comme la dernière vidéo mise en ligne par flos copie le dernier tweet de jules haag et leffe ou le signal envoyé par le capteur l'ida de la voiture en plus de ces données observationnelles d'algorithmics y va aussi recevoir une récompense air qui peut par exemple correspondre au nombre de vue d'une vidéo où nombre de like they do 28 ou au feedback et d'un humain qui dit aac si si l'algorithme à xi a fait quelque chose de bien ou quelque chose de dangereux dans le cas de jeu comme les échecs ou legault cette récompense air d'un terrien qu'à la fin de la partie est typiquement égal à 1 6i à gagner et à moins-16 non noté que ce cadre est extrêmement général on peut exprimer le problème de la recommandation de vidéo par youtube ou celui de la conception d'un chat bottes censé être bienveillant dans ce cas alors on peut également formulé l'expérience de vie des humains dans ce cadre où les actions sont souvent ce qu'on va dire où les mouvements qu'on va demander à nos muscles de faire les observations sont les signaux envoyés par nos différents sens comme la vue l'ouïe et l'odorat et où les récompenses sont entre autres les décharges de dopamine relâché par notre cerveau enfin on peut aussi décrire le fonctionnement des entreprises des partis politiques et de nombreuses associations comme étant un problème d'apprentissage pas renforcement toutes ces organisations prennent des décisions par exemple sur les positions publiques qu'elles vont prendre observe le monde notamment en lisant des articles sur internet et reçoivent des espèces de récompense si leurs profits augmentent si leur influence politique grandit ou si leur cause avance en particulier faire du bien dans le monde peut aussi parfaitement s'exprimer dans le cadre de l'apprentissage par renforcement en supposant que les récompenses reçues seront d'autant plus grandes que le monde va mieux si telle car on dit que les récompenses sont alors aligné et on reviendra plus tard dans cette vidéo sur cette nation l'algorithme haïti est alors conçu pour résoudre le problème de l'apprentissage pas renforcement plus précisément haïti est conçu pour maximiser les récompenses qui seront reçus et intuitivement pour cela l'algorithme active à appliquer les calculs de l'induction de solomonoff puis inférées les lois et les états probable de son environnement puis l'algorithme va imaginer les conséquences probables des différentes actions qui pourraient entreprendre enfin l'algorithme va choisir de prendre la décision qui maximise les récompenses reçues alors en fait ce ne sont pas les récompenses reçues que l'algorithme maxi maximise il ya quelques subtilités qu'il est utile de garder en tête pour comprendre le fonctionnement daksi et en particulier pour mieux anticiper le type de décision que l'algorithme maxi peut prendre le premier point est que l'algorithme xxi maximis uniquement la récompense futur après tout les récompenses passé elles ont déjà été reçues et rex il ne peut plus rien y faire alors pourra se dire que ces récompenses passé pourrait être amenée à être corrigé dans le futur mais alors ce qui intéresse alexis ce ne sont pas les récompenses passé reçu ce qui intéressera alexis davantage dans ce cas ce sont les corrections futur des récompenses passé que l'algorithme subira et ça ça revient bien à part les deux récompenses futur pas du passé en particulier ça ça veut dire que ce n'est pas parce que l'algorithme à xi a reçu la récompense maximale dans le passé que l'algorithme va s'en satisfaire accès est programmé pour maximiser les récompenses futur il n'y a pas de phénomène temporal de compensation qui est programmée dans alexis l'algorithme axes y va alors constamment regarder prospectivement vers le futur mais bien entendu et de façon cruciale l'algorithme à xxi ne connaît pas sa récompense futur cet algorithme a nécessairement une incertitude épistémique vis-à-vis des récompenses futur du coup il est techniquement erroné de dire qu'à xxi maximise ses récompenses futur ce que cet algorithme maximise ça va être en fait l'expérience de ces récompenses futur c'est à dire la moyenne des récompenses qu'elle recevra dans tous les scénarios futurs qu'elle envisage pondérée par les probabilités de ces différents futurs on a toutefois alors un dernier problème à régler techniquement la somme de toutes les récompenses futur espérer pourrait être infinie notamment si l'algorithme maxxi n'est pas conçu avec un horizon futur limites mais surtout n'est pas clair que le futur dans un milliard de milliards de milliards de siècle est vraiment aussi important que le futur dans un an en tout cas pour la plupart de nous autres humains ou plus précisément n'est pas clair que ce qui se passera entre 1 milliard et 2 milliards de siècle dont le futur soit un milliard de fois plus important que ce qui se passera dans le siècle à venir la solution la plus courante pour modéliser cela consiste à introduire un facteur d ce compte qui va typiquement dire que ce qu'il se passera entre 2051 et 2052 et peut-être dix ont deux fois moins important que ce qu'il se passera en 2021 si c'est le cas on dira que l'on a un temps caractéristiques des ce conte de l'or autour de 30 ans et ça ça impliquera que ce qu'il se passera dans un siècle est dix fois moins importante que ce qui se passe aujourd'hui alors bien sûr on a toutefois des désaccords entre nous sur quel est le temps caractéristiques des comptes adéquat à considérer ceux qui ont une vision plus court-termiste diront peut-être que ce temps des comptes est de l'ordre de 12 ans peut-être alors que des visions plus long termiste défendront détendent escompte de l'ordre du millénaire voire peut-être de l'ordre du milliard de milliards de milliards de milliards de siècle ou quelque chose comme ça en fait on peut même envisager le fait que chacun d'entre nous un temps d'escompté différents pour des considérations différentes typiquement je trouve ça important que le monde aille encore bien dans un siècle mais j'ai tendance à trouver ça important également que j'ai de quoi manger dans les 24 heures à venir quoi qu'il en soit l'algorithme haïti est généralement conceptualiser avec un temps des comptes donnés dès lors à tout moment maxime maximisera l'espérance de la somme des récompenses futurs escomptés or en fait plus précisément que l'algorithme active à maximiser c'est une suite de décisions à prendre qui peuvent réagir à des données futurs pourraient être ainsi parlé d' optimisation de stratégie mais dans le jargon on parle plutôt d'optimisation de politiques policiers en anglais ce qui est intéressant de voir c'est qu'une politique n'est pas un plan prédéterminé au sens du formalisme taxi une politique peut très bien être de la forme alors on va tester un peu ceux ci et si ça a l'air de marcher on investira encore plus dans les tests et si vraiment ça marche alors on va redéployer sa à grande échelle comme on en a parlé d'ailleurs dans les épisodes sur les essais adaptatifs appliquées notamment aux tests cliniques des traitements contre 8,19 un autre aspect important est de noter que le choix de la politique à adopter par alexis résulte d'un calcul contrat factuel autrement dit l'algorithme maxi va imaginer l'adoption d'une politique et calculer l'espérance de récompenses futurs escomptés qui en résulte elle va ensuite imaginé l'adoption d'une autre politique est calculé à nouveau l'espérance de récompenses futurs escomptés qui s'ensuit elle va ensuite continuer ses calculs avec toutes sortes de politiques en fait l'algorithme à xi va considérer l'ensemble de toutes les politiques calculable alexis maximise ainsi contrat actuellement le choix de la politique à adopter enfin une dernière remarque à faire et que la décision de l'algorithme ike ci correspond simplement à des messages envoyés et alors on pourrait croire que envoyé un message à travers internet ça doit pas être si l'ange re imaginez un algorithme haïti par exemple qu'ils enverraient des milliards de messages par seconde si ce n'est beaucoup plus en personnalisant chacun de ces messages à chacun des humains cible l'algorithme aqsiq pourrait influencer quotidiennement des milliards d'humains les amener ainsi petit à petit a davantage croire x ou à davantage faire y à l'instar d'un sobre et dit un tel rythme pour être ainsi manipuler les cours de la bourse et se faire énormément d'argent il pourrait aussi découvrir des secrets de dirigeants influents payer des salariés faire du lobbying voire menacer des individus finalement un peu comme le font déjà certaines grandes organisations intel algorithmes serait alors extrêmement dangereux mais bon je ne vais pas affirmer que des algorithmes capables d'envoyer des messages des milliards d'humains ça existe déjà du coup je vais simplement vivement le suggérer alors il existe tout taxi et en particulier de cette maximisation contrat factuel en particulier il ya quelques mois un article sur le paradoxe de newcombe paix tant que ce paradoxe révèle une faille dans la conception taxi et cet article c'est moi qui ai écrit alors je ne vais pas rentrer dans trop de détails c'est un mériterait une vidéo à part entière mais en bref l'argument de cet article c'est que le formalisme d'haïti échoue anticipé la capacité d'entités extérieures à alexis à prédire ce cas ci fera ou plus précisément par conception axis restreint un ensemble de théories trop restreint est en gros ça ça ouvre la porte à une dévastatrice diagonale de kantor et plus précisément à des cas où il est impossible de faire de la maximisation contractuels bref à en croire cet article ou sélection de vidéos de monsieur fille le problème de prise de décision ça semble en fait encore plus complexe que ce qu'on pourrait croire il reste toutefois un aspect important de la conception taxi a précisé à savoir quels sont ces récompenses qui motive ses prises de décision comment sont calculées les récompenses taxi et surtout qu'est ce que ces récompenses vont impliquer sur la décision effective prise par ike 6 et bien selon beaucoup en particulier selon les deux auteurs du livre le fabuleux chantier cette question est au coeur de l'éthique des algorithmes et de l'information et il est donc urgent de davantage l'investissement en particulier d'après ce livre il semble urgent dès à présent de faire en sorte que les récompenses de tout algorithmes d'apprentissage déployé à très grande échelle soit aligné autant que possible avec ce que nous autres humains voudrions vraiment maximiser si nous réfléchissions davantage et si nous informions davantage sur nos préférences sur ce qui est désirable et sur comment y parvenir quel est le problème dit de l'alignement des algorithmes et à titre personnel je pense qu'il est urgent qu'on trouve des solutions pour le résoudre de manière robuste il me semble plus important que jamais que des algorithmes ne déployait à très grande échelle sache ce que l'ensemble de l'humanité désir aura vraiment au plus profond d'elle-même et que ses algorithmes aide l'humanité à atteindre ses objectifs alors malheureusement concevoir un tel algorithmes n'est absolument pas il s'agit là d'un énorme chantier et pour finir cette vidéo j'aimerais insister surtout sur le fait qu'il s'agisse d'un fabuleux chantier un fabuleux chantier il est devenu urgent d' accomplir