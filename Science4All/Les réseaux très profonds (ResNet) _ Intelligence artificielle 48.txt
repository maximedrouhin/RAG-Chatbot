après son succès retentissant 2012 l'apprentissage profond aussi appelé deep learning a commencé à envahir les laboratoires de recherche en intelligence artificielle les années qui suivirent nécessaire de le confirmer plus un réseau de neurones et profond meilleures sont ses performances voilà qui pousse à de nombreux chercheurs a entraîné des réseaux de neurones avec de plus en plus de couches pour aller du dip leur nîmes vers le very deep learning et pendant longtemps à condition d'avoir suffisamment de données il semblait que plus les réseaux étaient profonds plus il était en effet performant cependant il semblait y avoir une limite à 7 déraisonnable efficacité de la profondeur en effet à partir d'un certain moment le dip learning sais c'est de bien fonctionner à cause d'un phénomène dont on a déjà parlé dans un épisode précédent à savoir l'évanescence du gradient ou vanishing louis dionne en anglais oui parce que lorsqu'on applique algorithmes de rétro propagation pour ajuster les paramètres de nos modèles l'intensité du gradient et x lespwa synaptique des synapses entre les coaches voilà qui fait que cette intensité est démultipliée encore et encore ce qui correspond à une croissance ou de décroissance exponentielle les gradients alors a tendance à exploser dans un sens ou dans l'autre plus précisément si les pois synaptique sont légèrement supérieurs à 1 alors on va avoir une explosion exponentielle des gradients et s'ils sont légèrement inférieures à 1 alors on va avoir une évanescence exponentielle des gradients et ça ça fait que même si en principe la descente de gradient stochastiques pour des raisons très profond devrait fonctionner en pratique ça ne marche vraiment pas les arrondis dénombrer les limites de puissance de calcul font que la descente de gradient ne mène nulle part et pourtant il semble bien que la profondeur devrait permettre d'améliorer les performances dès lors il s'agit surtout de trouver des manières astucieuse d'entraîner un réseau très profond à apprendre des données malgré sa profondeur comment faire une façon de faire consiste à compiler des modules avec des feedbacks intermédiaire typiquement si on veut entraîner une machine à prendre un livre et à comprendre le texte qu'elle lit on peut d'abord entraîné son cortex visuel à reconnaître un livre ses marques et à identifier les zones de texte typiquement avec un réseau de neurones de convolution puis on peut entraîner des modules plus profond qui récupère les images des zones de texte et font de la reconnaissance de caractères ensuite on peut utiliser les caractères pour les combinés en mots puis utiliser quelque chose comme world check pour calculer des représentations sémantique des mots enfin on peut travailler avec les représentations sémantique des mots pour en inférer une sémantique des phrases par exemple avec un réseau récurrents elle estime comme ceux dont on a parlé dans un épisode précédent et on peut peut-être ensuite combinés les phrases avec un autre réseau récurrents et lestienne pour un ferrer la sémantique de tout le texte de façon cruciale on peut entraîner chacun des modules de manière indépendante en introduisant des feedbacks intermédiaire potentiellement guidé par de l'apprentissage superviser un peu le cadre facile du machine learning dont on a parlé dans l'épisode 8 ce faisant on n'a pas besoin de rétro propager les gradients depuis le fond du match les réseaux de neurones vers les premières couches crie on évite ainsi l'évanescence du gradient et l'analogie semble d'ailleurs se tenir avec l'apprentissage général il est ainsi souvent utile de séquences et l'apprentissage en plusieurs phases et de travailler chacune des phases de façon aussi indépendante que possible et pour juger nos performances à chaque phase il est alors utile d'avoir des feedbacks pour chacune des phases de l'apprentissage est donc l inverse si vous êtes une personne en charge de donner ce genre de feedback il est peut-être préférable de mettre en valeur un petit nombre de points précis plutôt que de faire un long discours sur l'intégralité des performances de la personne que vous encadrez et peut-être même que travailler un seul point précis en oubliant tout le reste peut être encore plus utile pour l'apprentissage cependant parfois il est difficile d'accéder à ces feedbacks intermédiaires notamment qu'on l'apprentissage est entièrement non supervisées ou lorsque le superviseur ne comprend pas lui-même les étapes intermédiaires pour vous fournir des feedbacks pour adresser ce cas les chercheurs en intelligence artificielle se sont appuyés encore une fois sur l'analogie avec la biologie en particulier se trouve que le cortex visuel en plus de posséder des coupes vers 1 avait cinq comme déjà parlé dans l'épisode précédent ce cortex visuel possède aussi quelques neurones centraux appelées cellules pyramidale dont certains axones permettent d'envoyer des signaux qui sauteront plein d'étapes intermédiaires et maxi axones sont des sortes d'autoroute des réseaux de neurones biologique ok mais quelle peut bien être l'intérêt des autoroutes et bien comme vous le voyez là ça crée des chemins le long desquelles le gradient n'aura pas le temps de disparaître ce sera d'ailleurs particulièrement le cas si en plus on force ces autoroutes à avoir des poids synaptique quasiment égaux à 1 et outre l'analogie avec un biologie c'est un peu ça la motivation des autoroutes les autoroutes permettent de remonter les gradients sans les détruire de sorte que même les premières couches puisse déterminer des façons de contribuer à l'amélioration globale du réseau de neurones et réseaux de neurones très profond avec de tels autoroutes sont appelés des réseaux de neurones résiduelles ou rays net pour les intimes et si on considère que la profondeur de tels réseaux et celle du plus long chemin de l'entrée vers la sortie alors de nos jours il existe des réseaux résiduelles qui continue à gagner en performance en augmentant le nombre de couches jusqu'aux alentours de 1000 cet article de 2016 explique même aller au delà de 1200 couche avec encore des progrès dans les performances dans le problème classique de machine learning de reconnaissance d'image à plessis par dix et depuis ces réseaux de neurones résiduelles trouve de nombreuses applications surtout en santé mais aussi dans d'autres domaines comme la sismologie l'idée de ces autoroutes me donne d'ailleurs envie de faire une autre halte au logis encore avec l'écriture de preuves mathématiques notamment l'écriture de l'ong preuves mathématiques dans un premier temps il est utile d'identifier un petit nombre de points de passage utile dans le jargon ceci revient et identifié d'hellemmes s'il ya des espèces de théorèmes intermédiaires qui sont plus faciles à démontrer que le théorème globale et sur lesquels on pourra s'appuyer pour démontrer le théorème global est souvent la première étape de l'écriture du nom preuve après une petite réflexion sur est-ce que ce théorème est vrai c'est vraiment la recharge que celle m et idéalement il faut que celle m e est vraiment l'air vrai ensuite il vient un moment où si l'on a de la chance on parvient à séquencer la preuve en un certain nombre de lem et de sorte que le passager jiten l'aiment à l'autre semble faisable voire facile on obtient alors une pseudo autoroute qui vont de l'hypothèse par la conclusion du théorème il ne reste plus qu'à tracer la route et pour cela il suffit de construire chaque tronçon en espérant qu'aucun ne pose problème de la même manière il semble que notre cortex visuel soit capable de ce genre de prouesse il identifie d'abord une façon globale d'interpréter des images visuelles puis et capables d'affiner les détails de son âne elle pour une plus grande précision et de façon plus générale il semble qu'il s'agisse là d'une bonne façon d'apprendre des successions de notions très difficile il est utile d'avoir d'abord une vue d'ensemble avec quelques pointes et puis il est utile de se concentrer sur chacun des points clés pour s'assurer qu'aucun ne soit un sophisme fallacieux bon après c'est plus facile à dire qu'à faire la nymphe en a déjà parlé du cortex visuel en parlant notamment des réseaux de convolution et raphaël guillaume de demande si de tels cortex visuel sont également susceptibles aux illusions d'optique il pense notamment à cette fameuse image que je vais là où on voit à la fois un canard et un lapin mais jamais les deux en même temps en fonction de l'avenir regarde cette image alors si on prend la notion d'illusions d'optiques de façon assez générale en disant qu illusion d'optique c'est quand on a une image qui représente quelque chose mais on voit autre chose eh bien ça sur les réseaux de neurones font ça c'est bien trop souvent on va dire ça correspond à ce qu'on appellerait aussi des erreurs de classification donc il arrive très souvent que montre une image un réseau de neurones et qu'il appelle sa autre chose est bon en général c'est assez loufoque mais parfois ça peut être assez assez problématique comme par exemple ce cas d'une intelligence artificielle qui lorsqu'on lui donner des images du vin dont la couleur de peau était noir disait qu'il voyait des gorilles bon après on peut se dire que ce genre d'erreur n'est pas vraiment le genre d'erreur que font les humains or on voit que du coup on peut se demander est-ce que les illusions d'optique classique des humains sont des illusions d'optique que les intelligences artificielles sont susceptibles d'avoir également et là la réponse est sans doute oui notamment si on en croit le cours de ce 1 et ce 2 e du collège de france sur le cerveau statisticiens qui explique que beaucoup de ses illusions d'optique sont en fait totalement expliquée dans un cadre bien en supposant que le cerveau à des a priori sur ce qui s'attend à observer et qu'il n'interprète ceux qui voient en fonction de ses a priori si on suppose que cela est bien on a des certaine façon d'interpréter certaines six mariages qui correspond souvent à la manière dont on les interprète aurait si on les voyait dans une savane africaine dans un paysage assez naturel et pas créés en laboratoire et à cause de cette âpre et veiller sur ce qu'on s'attend à avoir on risque de deviner des choses qui ne correspondent pas à ce qui est véritablement donc typiquement l'exemple classique de ça c'est le fait que nous autres humains sommes optimisé pour vivre dans des prix tribus primitives notamment avec d'autres individus du coup nous avons un a priori sur ce qu'une voyante qui est généralement des visages habitude d'interagir avec des humains quand on voit une image on s'attend à ce qu'ils aient une image de visages l'intérieur sauf que bien sûr quand on prend des photos d'image de cailloux sur mars par exemple a priori il n'y a pas de visage mais on a cet a priori qui est que d'habitude quand on regarde les images il y à des visages et à cause de cet a priori a posteriori quand on voit une image et surtout si on sait pas que son image dans le caillou à mars et qu'on contextualise pas assez l'image est bien à ce moment là notre cortex visuel fait qu'on pourra voir un visage bref c'est l'occasion pour moi de mentionner un proverbe bayésiens dit que sans conteste sans contexte c'est la mauvaise probabilité conteste et bien souvent les illusions d'optique correspondent à raisonner avec le mauvais contexte ne pouvait faire demande aussi les intelligences artificielles pour avoir des personnalités multiples et une certaine manière j'ai envie de dire oui très probablement parce que au fur et à mesure qu'elles sont déployés les intelligences artificielles sont répliquées copier coller est modifié souvent localement nous par exemple l'intelligence artificielle d'auto complétion des mots est pas la même sur mon téléphone que sur votre téléphone sans doute et d'une certaine manière c'est un rôle la même intelligence artificielle initial qui a du coup créer différentes versions d'elle même et qui du coup a une certaine manière de différentes personnalités ok c'est une façon je pense d'interpréter ce que ça pourrait vouloir dire de façon plus générale en fait ce qui se passe c'est que on veut absolument décentraliser ses intelligences artificielles pour les mettre au plus proche de nombreux utilisateurs aussi d'autres raisons de vouloir décentraliser les intelligences artificielles et ça ça fait qui peut avoir des copies différentes mutuellement incompatibles en fait des mêmes intelligence artificielle qui font que du coup deux intelligences artistique initialement les mêmes peuvent se retrouver à être différente de façon plus générale je pense qu'il est utile de ne pas parler de l'intelligence artificielle au singulier il est utile de garder en tête qu'en fait dans le futur est déjà dans le présent il y a plusieurs intelligence artificielle et il faudra plus fait parler d intelligence artificielle plutôt que de l'intelligence artificielle le banc par abus de langage savait pas trop gênant de dire l'intelligence artificielle de façon générale tout cas c'est un truc que j'ai beaucoup fait dans cette série et j'espère que vous avez aimé cette vidéo la production verra le dernier épisode sur les architectures de réseaux de neurones on parlera des réseaux de neurones adversaire yeux qui est cette architecture particulièrement génial qui a conduit à des performances extrêmement spectaculaires dans les performances des intelligences artificielles et qui s'explique que très très bien avec défilement bayésiens donc c'est un truc beaucoup pour voir la prochaine fois si vous avez aimez cette vidéo pensez à liker à la commenter à la partager pensez à vous abonner pour l'épisode merci un petit peu à peu leurs dents et j'espère que vous serez là la prochaine fois pourquoi cette méthode à laquelle personne ne croyait il ya encore quelques années s'est mise à marcher soudainement et bien comme souvent il ya plusieurs raisons d'abord les algorithmes ont progressé 1 comme toujours notamment contrairement à ce que je peux laisser penser on n'utilise pas n'importe quel réseau profond - ce n'est pas juste un tas de neurones empilés et on a d architecture particulière qui fonctionne bien mais qu elle fasse pour moi est avant tout un grand crac